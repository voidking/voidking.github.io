<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>好好学习的郝</title>
  
  <subtitle>好好学习，天天向上！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.voidking.com/"/>
  <updated>2023-02-07T17:00:00.000Z</updated>
  <id>https://www.voidking.com/</id>
  
  <author>
    <name>好好学习的郝</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CentOS8更换软件安装源</title>
    <link href="https://www.voidking.com/dev-centos8-change-repo/"/>
    <id>https://www.voidking.com/dev-centos8-change-repo/</id>
    <published>2023-02-07T17:00:00.000Z</published>
    <updated>2023-02-07T17:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>CentOS8已于2021年12月31日停止维护，在2022年1月31日，CentOS团队终于从官方镜像中移除CentOS8的所有包。</p><p>如果仍然需要运行CentOS8，我们可以在/etc/yum.repos.d中更新安装源。</p><a id="more"></a><h1 id="更换方法"><a href="#更换方法" class="headerlink" title="更换方法"></a>更换方法</h1><p>1、备份原安装源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp -r /etc/yum.repos.d&#123;,.bak&#125;</span><br></pre></td></tr></table></figure><p>2、替换安装源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rm /etc/yum.repos.d/*.repo -rf</span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo</span><br><span class="line"><span class="comment">#curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo</span></span><br></pre></td></tr></table></figure><p>3、更新安装源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;CentOS8已于2021年12月31日停止维护，在2022年1月31日，CentOS团队终于从官方镜像中移除CentOS8的所有包。&lt;/p&gt;
&lt;p&gt;如果仍然需要运行CentOS8，我们可以在/etc/yum.repos.d中更新安装源。&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
    
      <category term="linux" scheme="https://www.voidking.com/tags/linux/"/>
    
      <category term="centos" scheme="https://www.voidking.com/tags/centos/"/>
    
  </entry>
  
  <entry>
    <title>GitLab CI问题记录</title>
    <link href="https://www.voidking.com/dev-gitlab-ci-problems/"/>
    <id>https://www.voidking.com/dev-gitlab-ci-problems/</id>
    <published>2022-11-11T14:00:00.000Z</published>
    <updated>2023-02-13T17:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Job-is-stuck"><a href="#Job-is-stuck" class="headerlink" title="Job is stuck"></a>Job is stuck</h2><p>Shell Runner跑CI任务，报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Job is stuck. Check runners. allowed to fail</span><br></pre></td></tr></table></figure><p>解决办法：<br>经查是因为gitlab-runner版本比较高（15.5.0），新版本的runner，要求<code>.gitlab-ci.yml</code>必须要配置tags，指定runner。</p><a id="more"></a><h2 id="setting-GIT-CLONE-PATH-is-not-allowed"><a href="#setting-GIT-CLONE-PATH-is-not-allowed" class="headerlink" title="setting GIT_CLONE_PATH is not allowed"></a>setting GIT_CLONE_PATH is not allowed</h2><p>Shell Runner跑CI任务，报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR: Job failed: setting GIT_CLONE_PATH is not allowed, enable &#96;custom_build_dir&#96; feature</span><br></pre></td></tr></table></figure><p>解决办法：启用custom_build_dir</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/gitlab-runner/config.toml</span><br></pre></td></tr></table></figure><p>添加custom_build_dir配置</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[[runners]]</span></span><br><span class="line">  <span class="section">[runners.custom_build_dir]</span></span><br><span class="line">    enabled = true</span><br></pre></td></tr></table></figure><p>重启gitlab-runner</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitlab-runner restart</span><br></pre></td></tr></table></figure><h2 id="fatal-git-fetch-pack"><a href="#fatal-git-fetch-pack" class="headerlink" title="fatal: git fetch-pack"></a>fatal: git fetch-pack</h2><p>Shell Runner跑CI任务，报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fatal: git fetch-pack: expected shallow list</span><br><span class="line">fatal: The remote end hung up unexpectedly</span><br></pre></td></tr></table></figure><p>解决办法：<br>git版本问题，升级git</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh http://opensource.wandisco.com/centos/7/git/x86_64/wandisco-git-release-7-1.noarch.rpm</span><br><span class="line">yum install -y git</span><br></pre></td></tr></table></figure><h2 id="不能锁定配置文件"><a href="#不能锁定配置文件" class="headerlink" title="不能锁定配置文件"></a>不能锁定配置文件</h2><p>Shell Runner跑CI任务，报错：<br>error: 不能锁定配置文件 /home/gitlab-runner/builds/builds/xxx/main.tmp/git-template/config: 没有那个文件或目录</p><p>解决办法：<br>没有检索到找到解决办法，尝试降级到<code>14.5.0</code>，问题解决。降级方法参考【Linux环境安装runner】一节。</p><h2 id="No-such-file-or-directory"><a href="#No-such-file-or-directory" class="headerlink" title="No such file or directory"></a>No such file or directory</h2><p>Shell Runner跑CI任务，报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Skipping Git checkout</span><br><span class="line">Skipping Git submodules setup</span><br><span class="line">...</span><br><span class="line">$ pip3 install -r requirements.txt</span><br><span class="line">ERROR: Could not open requirements file: [Errno 2] No such file or directory: &#39;requirements.txt&#39;</span><br></pre></td></tr></table></figure><p>解决办法：<code>.gitlab-ci.yml</code>文件中添加GIT_CHECKOUT变量</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">variables:</span></span><br><span class="line">  <span class="attr">GIT_CHECKOUT:</span> <span class="string">"true"</span></span><br></pre></td></tr></table></figure><h2 id="下载镜像报错"><a href="#下载镜像报错" class="headerlink" title="下载镜像报错"></a>下载镜像报错</h2><p>Docker Machine Runner跑CI任务，一直正常。<br>Docker Machine Runner没有任何变动，突然有一天，执行docker build的时候，下载基础镜像报错：<br>ERROR: failed to do request: Head <a href="https://192.168.56.101:5000/v2/library/python/manifests/3.8" target="_blank" rel="noopener">https://192.168.56.101:5000/v2/library/python/manifests/3.8</a>: http: server gave HTTP response to HTTPS client</p><p>重启gitlab-runner问题依旧，重启机器问题依旧。</p><p>解决办法：runner配置里，指定docker image的版本为<code>docker:19.03</code>，而不要使用<code>docker</code>，否则一直会拉取最新版的docker，而最新版的docker不支持发送http请求镜像仓库。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Job-is-stuck&quot;&gt;&lt;a href=&quot;#Job-is-stuck&quot; class=&quot;headerlink&quot; title=&quot;Job is stuck&quot;&gt;&lt;/a&gt;Job is stuck&lt;/h2&gt;&lt;p&gt;Shell Runner跑CI任务，报错：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Job is stuck. Check runners. allowed to fail&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;解决办法：&lt;br&gt;经查是因为gitlab-runner版本比较高（15.5.0），新版本的runner，要求&lt;code&gt;.gitlab-ci.yml&lt;/code&gt;必须要配置tags，指定runner。&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
      <category term="troubleshooting" scheme="https://www.voidking.com/categories/engineering/troubleshooting/"/>
    
      <category term="git" scheme="https://www.voidking.com/categories/engineering/git/"/>
    
    
      <category term="问题排查" scheme="https://www.voidking.com/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
      <category term="cicd" scheme="https://www.voidking.com/tags/cicd/"/>
    
      <category term="git" scheme="https://www.voidking.com/tags/git/"/>
    
      <category term="gitlab" scheme="https://www.voidking.com/tags/gitlab/"/>
    
  </entry>
  
  <entry>
    <title>GitLab Runner入门篇</title>
    <link href="https://www.voidking.com/dev-gitlab-runner-start/"/>
    <id>https://www.voidking.com/dev-gitlab-runner-start/</id>
    <published>2022-11-11T14:00:00.000Z</published>
    <updated>2023-02-13T15:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GitLab-Runner简介"><a href="#GitLab-Runner简介" class="headerlink" title="GitLab Runner简介"></a>GitLab Runner简介</h1><p>GitLab Runner 是一个开源软件，它与 GitLab CI/CD 配合，在管道流中运行作业。<br>GitLab Runner 是用Go编写，几乎可以直接运行在任何操作系统（个别系统需要自行编译）。<br>GitLab Runner 也可以在 Docker 容器内运行或部署到 Kubernetes 集群中。</p><p>GitLab Runner能不能替换成其他的Runner？可以，但是没有必要，毕竟Gitlab Runner是开源的，有什么个性化需求就自己改一改。而且，也没有找到合适的替代产品。</p><p>参考文档：</p><ul><li><a href="https://docs.gitlab.com/runner/" target="_blank" rel="noopener">GitLab Runner</a> </li><li><a href="https://docs.gitlab.cn/jh/ci/" target="_blank" rel="noopener">GitLab CI/CD中文文档</a></li><li><a href="https://docs.gitlab.com/ee/ci/" target="_blank" rel="noopener">GitLab CI/CD文档</a></li><li><a href="https://docs.gitlab.com/runner/" target="_blank" rel="noopener">GitLab Runner</a></li><li><a href="https://docs.gitlab.com/runner/executors/" target="_blank" rel="noopener">Executors</a></li><li><a href="https://docs.gitlab.com/runner/executors/shell.html" target="_blank" rel="noopener">The Shell executor</a></li><li><a href="https://www.voidking.com/dev-gitlab-cicd/">《GitLab CI/CD入门篇》</a></li></ul><a id="more"></a><h1 id="GitLab、Runner和Executor"><a href="#GitLab、Runner和Executor" class="headerlink" title="GitLab、Runner和Executor"></a>GitLab、Runner和Executor</h1><p>关于GitLab、Runner和Executor的关系，有一个比喻很恰当：<br>GitLab是老板，会去查看需求单（.gitlab-ci.yml），建立一张又一张有先后顺序的工单（CI Pipeline）。<br>GitLab Runner 是执行 CI Job 的工人，定期去询问老板（GitLab）现在有分配给自己的工作（CI Job）吗？如果拿到工作，就开始执行，并在执行过程中将进度即时写在工单上。<br>Executor 是工人（Runner）执行 CI Job 的工作环境，例如一个 CI Job 是打印出”hello”，那么Runner可以在本地Shell环境中执行，可以在虚拟机环境中执行，还可以在Docker环境中执行；而如果一个CI Job需要在基础镜像上进行构建，那么就需要Docker环境或者K8S环境了。</p><p>Runner通常在安装Runner的同一台机器上处理作业。但是，我们也可以让Runner在容器、k8s 集群、或者云上的自动缩放实例中处理作业。</p><p>安装Runner后，想要使用它，需要在GitLab平台进行注册，注册做的工作就是建立Gitlab与Runner之间的通信。<br>注册完成后，Runner就可以运行来自 GitLab 的 CI/CD 作业了。</p><p>当我们注册一个Runner时，必须选择一个Executor。Executor决定了每个作业运行的环境。</p><p>Gitlab Runner的安装环境包括Linux、MacOS、Windows、Docker和Kubernetes。<br>而不同安装环境的Runner，支持不同的Executors。<br>根据Executor的不同，同一个Runner程序，可以注册为不同Executor类型的Runner，例如SSH、Shell、Parallels、VirtualBox、Docker、Docker Machine (auto-scaling)、Kubernetes、Custom。</p><p>例如：</p><ul><li>如果我们希望 CI/CD 作业运行 PowerShell 命令，那么可以在 Windows 服务器上安装 GitLab Runner，然后注册一个使用 Shell Executor的Runner。</li><li>如果我们希望 CI/CD 作业在自定义 Docker 容器中运行命令，那么可以在 Linux 服务器上安装 GitLab Runner 并注册一个使用 Docker Executor 的 Runner。</li><li>我们还可以在虚拟机上安装 GitLab Runner，并让它使用另一个虚拟机作为Executor。</li></ul><p>最常用的Executor：Shell、Docker、Docker Machine、Kubernetes。</p><p>参考文档：</p><ul><li><a href="https://docs.gitlab.com/runner/" target="_blank" rel="noopener">GitLab Runner</a> </li><li><a href="https://docs.gitlab.com/runner/executors/index.html" target="_blank" rel="noopener">Executors</a></li><li><a href="https://chengweichen.com/2021/03/gitlab-ci-executor.html" target="_blank" rel="noopener">GitLab CI 之 Runner 的 Executor 該如何選擇？</a></li></ul><h1 id="Executor简介"><a href="#Executor简介" class="headerlink" title="Executor简介"></a>Executor简介</h1><h2 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h2><p>Shell 是最简单的配置执行器。构建所需的所有依赖项都需要手动安装在安装 GitLab Runner 的同一台机器上。</p><h2 id="Docker-executor"><a href="#Docker-executor" class="headerlink" title="Docker executor"></a>Docker executor</h2><p>一个很好的选择是使用 Docker，因为它允许一个干净的构建环境，并且具有简单的依赖项管理（构建项目的所有依赖项都可以放在 Docker 映像中）。 Docker 执行器允许您轻松创建具有依赖服务的构建环境，例如 MySQL。</p><p>当我们在 Docker 容器中安装 GitLab Runner 并选择 Docker executor来运行作业时，它有时被称为 Docker-in-Docker （dind）配置。</p><p>注意：有些Docker容器中，默认的shell并不是bash，shell选择逻辑如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ -x /usr/<span class="built_in">local</span>/bin/bash ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exec</span> /usr/<span class="built_in">local</span>/bin/bash <span class="variable">$@</span></span><br><span class="line"><span class="keyword">elif</span> [ -x /usr/bin/bash ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exec</span> /usr/bin/bash <span class="variable">$@</span></span><br><span class="line"><span class="keyword">elif</span> [ -x /bin/bash ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exec</span> /bin/bash <span class="variable">$@</span></span><br><span class="line"><span class="keyword">elif</span> [ -x /usr/<span class="built_in">local</span>/bin/sh ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exec</span> /usr/<span class="built_in">local</span>/bin/sh <span class="variable">$@</span></span><br><span class="line"><span class="keyword">elif</span> [ -x /usr/bin/sh ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exec</span> /usr/bin/sh <span class="variable">$@</span></span><br><span class="line"><span class="keyword">elif</span> [ -x /bin/sh ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exec</span> /bin/sh <span class="variable">$@</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> shell not found</span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><p>参考文档：</p><ul><li><a href="https://shisho.dev/blog/posts/docker-in-docker/" target="_blank" rel="noopener">How To Run Docker in Docker</a></li><li><a href="https://devopscube.com/run-docker-in-docker/" target="_blank" rel="noopener">How To Run Docker in Docker Container</a></li><li><a href="https://medium.com/@tonywooster/docker-in-docker-in-gitlab-runners-220caeb708ca" target="_blank" rel="noopener">Docker-in-Docker in Gitlab Runners</a></li><li><a href="https://gitlab.com/gitlab-org/gitlab-runner/-/issues/1758" target="_blank" rel="noopener">shell in docker executor isn’t bash</a></li></ul><h2 id="Docker-Machine-executor"><a href="#Docker-Machine-executor" class="headerlink" title="Docker Machine executor"></a>Docker Machine executor</h2><p>Docker Machine 是 Docker 执行器的特殊版本，支持自动缩放。它像普通的 Docker 执行器一样工作，但使用 Docker Machine 按需创建的构建主机。</p><p>Docker官方已经废弃了Docker Machine，GitLab Runner使用的是自己维护的Docker Machine。</p><p>Docker Machine executor原理：</p><ul><li>安装Runner并配置gitlab-runner用户具有启动虚拟机的权限</li><li>Runner调用驱动启动Docker Machine VM，VM系统为<a href="https://github.com/boot2docker/boot2docker" target="_blank" rel="noopener">Boot2Docker</a></li><li>当VM中开始跑CI Job时，会启动一个Docker容器作为执行容器，在容器中跑CI Job</li><li>CI Job中可以包含docker build等命令，此时会共享调用VM的Docker，是Docker in Docker模式的一种</li></ul><p>参考文档：</p><ul><li><a href="https://docs.gitlab.com/runner/executors/docker_machine.html" target="_blank" rel="noopener">Install and register GitLab Runner for autoscaling with Docker Machine</a></li><li><a href="https://docs.gitlab.com/runner/configuration/autoscale.html" target="_blank" rel="noopener">Docker Machine Executor autoscale configuration</a></li></ul><h2 id="Kubernetes-executor"><a href="#Kubernetes-executor" class="headerlink" title="Kubernetes executor"></a>Kubernetes executor</h2><p>Kubernetes 执行器允许您使用现有的 Kubernetes 集群进行构建。执行器将调用 Kubernetes 集群 API 并为每个 GitLab CI 作业创建一个新的 Pod（带有构建容器和服务容器）。</p><p>Kubernetes executor也是支持 Docker-in-Docker 的。</p><p>参考文档：</p><ul><li><a href="https://docs.gitlab.com/runner/executors/kubernetes.html" target="_blank" rel="noopener">The Kubernetes executor for GitLab Runner</a></li><li><a href="https://docs.gitlab.com/runner/executors/kubernetes.html#using-docker-in-your-builds" target="_blank" rel="noopener">The Kubernetes executor for GitLab Runner - Using Docker in your builds</a></li><li><a href="https://stackoverflow.com/questions/58847455/cannot-access-docker-daemon-in-gitlab-runner-using-kubernetes-executor" target="_blank" rel="noopener">Cannot access docker daemon in gitlab runner using Kubernetes executor</a></li></ul><h2 id="SSH-executor"><a href="#SSH-executor" class="headerlink" title="SSH executor"></a>SSH executor</h2><p>SSH 执行器是为了完整性而添加的，但它是所有执行器中受支持最少的。它使 GitLab Runner 连接到外部服务器并在那里运行构建。我们有一些来自使用此执行器的组织的成功案例，但通常我们建议使用其他类型之一。</p><h2 id="Virtual-Machine-executor"><a href="#Virtual-Machine-executor" class="headerlink" title="Virtual Machine executor"></a>Virtual Machine executor</h2><p>这种类型的执行器允许您使用已创建的虚拟机，该虚拟机被克隆并用于运行您的构建。我们提供两个完整的系统虚拟化选项：VirtualBox 和 Parallels。如果您想在不同的操作系统上运行构建，它们可能会很有用，因为它允许在 Windows、Linux、macOS 或 FreeBSD 上创建虚拟机，然后 GitLab Runner 连接到虚拟机并在其上运行构建。它的使用也有助于降低基础设施成本。</p><h2 id="Custom-executor"><a href="#Custom-executor" class="headerlink" title="Custom executor"></a>Custom executor</h2><p>自定义执行器允许您指定自己的执行环境。当 GitLab Runner 不提供执行器（例如，LXC 容器）时，您可以向 GitLab Runner 提供自己的可执行文件，以配置和清理您想要使用的任何环境。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;GitLab-Runner简介&quot;&gt;&lt;a href=&quot;#GitLab-Runner简介&quot; class=&quot;headerlink&quot; title=&quot;GitLab Runner简介&quot;&gt;&lt;/a&gt;GitLab Runner简介&lt;/h1&gt;&lt;p&gt;GitLab Runner 是一个开源软件，它与 GitLab CI/CD 配合，在管道流中运行作业。&lt;br&gt;GitLab Runner 是用Go编写，几乎可以直接运行在任何操作系统（个别系统需要自行编译）。&lt;br&gt;GitLab Runner 也可以在 Docker 容器内运行或部署到 Kubernetes 集群中。&lt;/p&gt;
&lt;p&gt;GitLab Runner能不能替换成其他的Runner？可以，但是没有必要，毕竟Gitlab Runner是开源的，有什么个性化需求就自己改一改。而且，也没有找到合适的替代产品。&lt;/p&gt;
&lt;p&gt;参考文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.gitlab.com/runner/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitLab Runner&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.gitlab.cn/jh/ci/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitLab CI/CD中文文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.gitlab.com/ee/ci/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitLab CI/CD文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.gitlab.com/runner/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitLab Runner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.gitlab.com/runner/executors/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Executors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.gitlab.com/runner/executors/shell.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The Shell executor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.voidking.com/dev-gitlab-cicd/&quot;&gt;《GitLab CI/CD入门篇》&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
      <category term="git" scheme="https://www.voidking.com/categories/engineering/git/"/>
    
    
      <category term="cicd" scheme="https://www.voidking.com/tags/cicd/"/>
    
      <category term="git" scheme="https://www.voidking.com/tags/git/"/>
    
      <category term="gitlab" scheme="https://www.voidking.com/tags/gitlab/"/>
    
  </entry>
  
  <entry>
    <title>GitLab Runner安装实践</title>
    <link href="https://www.voidking.com/dev-gitlab-runner-install/"/>
    <id>https://www.voidking.com/dev-gitlab-runner-install/</id>
    <published>2022-11-11T14:00:00.000Z</published>
    <updated>2023-02-14T14:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GitLab-Runner版本说明"><a href="#GitLab-Runner版本说明" class="headerlink" title="GitLab Runner版本说明"></a>GitLab Runner版本说明</h1><p>出于兼容性原因，GitLab Runner major.minor 版本应与 GitLab major.minor 版本保持同步。<br>较旧的runner可能仍然可以使用较新的 GitLab 版本，反之亦然。但是，如果存在版本差异，功能可能无法使用或无法正常工作。<br>minor版本更新时，会保障向后兼容性。但是，有时 GitLab 的minor版本更新会引入新功能，这些新功能需要 GitLab Runner 在同一minor版本上。</p><p>需要特别注意的是：GitLab Runner 15.0 对注册 API 请求格式进行了更改。它阻止 GitLab Runner 与低于 14.8 的 GitLab 版本通信。我们必须使用适合 GitLab 版本的 Runner 版本，或升级 GitLab 应用程序。</p><p>更多内容参考文档<a href="https://docs.gitlab.com/runner/" target="_blank" rel="noopener">GitLab Runner</a></p><a id="more"></a><h1 id="查看安装教程"><a href="#查看安装教程" class="headerlink" title="查看安装教程"></a>查看安装教程</h1><h2 id="指定项目的Runner"><a href="#指定项目的Runner" class="headerlink" title="指定项目的Runner"></a>指定项目的Runner</h2><p>打开gitlab项目 -&gt; Settings -&gt; CI/CD -&gt; Runners -&gt; Expand -&gt; Show Runner installation instructions</p><p>页面的 registration token，用于注册指定项目（当前项目）的runner。</p><h2 id="共享的Runner"><a href="#共享的Runner" class="headerlink" title="共享的Runner"></a>共享的Runner</h2><p>查看Runner：<a href="https://gitlab.voidking.com/admin/runners" target="_blank" rel="noopener">https://gitlab.voidking.com/admin/runners</a>  </p><p>打开gitlab runner管理页面 -&gt; Show Runner installation instructions</p><p>页面的 registration token，用于注册共享runner。</p><h1 id="TOML语法"><a href="#TOML语法" class="headerlink" title="TOML语法"></a>TOML语法</h1><p>gitlab-runner配置文件为config.toml，使用TOML语法。<br>TOML的目标是成为一种易于阅读的最小配置文件格式。<br>TOML被设计为明确地映射到哈希表。<br>TOML应该很容易解析成各种语言的数据结构。</p><p>参考文档：</p><ul><li><a href="https://docs.gitlab.com/runner/configuration/" target="_blank" rel="noopener">Configuring GitLab Runner</a></li><li><a href="https://github.com/toml-lang/toml" target="_blank" rel="noopener">TOML</a></li><li><a href="https://www.cnblogs.com/xingxia/p/toml.html" target="_blank" rel="noopener">TOML 1.0格式语法</a></li><li><a href="https://www.convertjson.com/toml-to-json.htm" target="_blank" rel="noopener">Convert TOML To JSON</a></li></ul><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><p><code>#</code>，井号后面表示注释</p><h2 id="键值对"><a href="#键值对" class="headerlink" title="键值对"></a>键值对</h2><p>键名为字符串，值可以为字符串、整数、浮点数、布尔值、日期、时刻、数组、行内表等。<br>键名在等号的左边，值在等号的右边。</p><p>例如：</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name</span> = <span class="string">"voidking"</span></span><br></pre></td></tr></table></figure><h2 id="表"><a href="#表" class="headerlink" title="表"></a>表</h2><p>表的表示方法：方括号+表名，例如<code>[table]</code>。<br>表是键值对的集合，类似于json中的对象（花括号中内容）。在它下方，直至下一个表头或文件结束，都是这个表的键值对。<br>顶层表，又被称为根表，于文档开始处开始并在第一个表头（或文件结束处）前结束。</p><p>表名的规则和键名的规则相同。</p><p>表的层级结构以点<code>.</code>分隔，分隔的每个部分都是一个表名。<br>定义一个多层级表时，如果最后一个表名前的表没有被创建，那么会被自动创建。</p><p>例如：</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[table]</span></span><br><span class="line"><span class="comment"># 定义一个名为 table 的表</span></span><br><span class="line"><span class="attr">key1</span> = <span class="string">"some string"</span></span><br><span class="line"><span class="attr">key2</span> = <span class="number">123</span></span><br><span class="line"></span><br><span class="line"><span class="attr">fruit.apple.color</span> = <span class="string">"红色"</span></span><br><span class="line"><span class="comment"># 定义一个名为 fruit 的表</span></span><br><span class="line"><span class="comment"># 定义一个名为 fruit.apple 的表</span></span><br><span class="line"></span><br><span class="line"><span class="attr">fruit.apple.taste.sweet</span> = <span class="literal">true</span></span><br><span class="line"><span class="comment"># 定义一个名为 fruit.apple.taste 的表</span></span><br><span class="line"><span class="comment"># fruit 和 fruit.apple 已经创建过了</span></span><br></pre></td></tr></table></figure><h2 id="表数组"><a href="#表数组" class="headerlink" title="表数组"></a>表数组</h2><p>表数组表示方法：双层方括号+表名，例如<code>[[fruits]]</code>。<br>表数组是表的数组，类似于json中的对象数组。</p><p>表数组的第一例定义了这个数组及其首个表元素，而后续的每个表数组在该数组中创建并定义一个新的表元素。</p><figure class="highlight toml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[[fruits]]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">"苹果"</span></span><br><span class="line"></span><br><span class="line"><span class="section">[fruits.physical]</span>  <span class="comment"># 子表</span></span><br><span class="line"><span class="attr">color</span> = <span class="string">"红色"</span></span><br><span class="line"><span class="attr">shape</span> = <span class="string">"圆形"</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[fruits.varieties]]</span>  <span class="comment"># 嵌套表数组</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">"蛇果"</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[fruits.varieties]]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">"澳洲青苹"</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[fruits]]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">"香蕉"</span></span><br><span class="line"></span><br><span class="line"><span class="section">[[fruits.varieties]]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">"车前草"</span></span><br></pre></td></tr></table></figure><p>对应的json格式为：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"fruits"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"苹果"</span>,</span><br><span class="line">      <span class="attr">"physical"</span>: &#123;</span><br><span class="line">        <span class="attr">"color"</span>: <span class="string">"红色"</span>,</span><br><span class="line">        <span class="attr">"shape"</span>: <span class="string">"圆形"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"varieties"</span>: [</span><br><span class="line">        &#123; <span class="attr">"name"</span>: <span class="string">"蛇果"</span> &#125;,</span><br><span class="line">        &#123; <span class="attr">"name"</span>: <span class="string">"澳洲青苹"</span> &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"香蕉"</span>,</span><br><span class="line">      <span class="attr">"varieties"</span>: [</span><br><span class="line">        &#123; <span class="attr">"name"</span>: <span class="string">"车前草"</span> &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="缩进"><a href="#缩进" class="headerlink" title="缩进"></a>缩进</h2><p>TOML中的缩进没有意义，只是为了方便读者理解层级结构。</p><h1 id="Linux环境安装Runner"><a href="#Linux环境安装Runner" class="headerlink" title="Linux环境安装Runner"></a>Linux环境安装Runner</h1><p>参考文档：<a href="https://docs.gitlab.com/runner/install/index.html" target="_blank" rel="noopener">Install GitLab Runner</a></p><p>1、安装runner</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download the binary for your system</span></span><br><span class="line">sudo curl -L --output /usr/<span class="built_in">local</span>/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64</span><br><span class="line"></span><br><span class="line"><span class="comment"># Give it permissions to execute</span></span><br><span class="line">sudo chmod +x /usr/<span class="built_in">local</span>/bin/gitlab-runner</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a GitLab CI user</span></span><br><span class="line">sudo useradd --comment <span class="string">'GitLab Runner'</span> --create-home gitlab-runner --shell /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install and run as service</span></span><br><span class="line">sudo gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner</span><br><span class="line">sudo gitlab-runner start</span><br><span class="line">sudo gitlab-runner -v</span><br></pre></td></tr></table></figure><p>PS：其他版本的runner源码和二进制文件，可以在<a href="https://gitlab.com/gitlab-org/gitlab-runner/-/releases" target="_blank" rel="noopener">gitlab-runner Releases</a>页面找到。</p><p>对于centos系统，可以直接使用rpm包安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y https://gitlab-runner.downloads.s3.amazonaws.com/latest/rpm/gitlab-runner_amd64.rpm</span><br></pre></td></tr></table></figure><p>2、添加到gitlab-runner到docker用户组（可选）<br>如果gitlab-runner执行的ci脚本需要运行docker，那么需要将gitlab-runner到docker用户组</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo usermod -a -G docker gitlab-runner</span><br><span class="line"><span class="comment"># if no docker group</span></span><br><span class="line">sudo usermod -a -G root gitlab-runner</span><br><span class="line"></span><br><span class="line">sudo -u gitlab-runner -H docker info</span><br></pre></td></tr></table></figure><p>3、gitlab-runner添加sudo权限（可选）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sudoers</span><br></pre></td></tr></table></figure><p>添加配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitlab-runner ALL&#x3D;(ALL) NOPASSWD: ALL</span><br></pre></td></tr></table></figure><h1 id="注册Shell类型Runner"><a href="#注册Shell类型Runner" class="headerlink" title="注册Shell类型Runner"></a>注册Shell类型Runner</h1><p>Shell类型的Executor，在Runner程序所在主机上运行CI任务。</p><p>前置条件：安装好了Runner。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo gitlab-runner register -h</span><br><span class="line">sudo gitlab-runner register --url https://gitlab.voidking.com/ --registration-token <span class="variable">$REGISTRATION_TOKEN</span></span><br></pre></td></tr></table></figure><p>REGISTRATION_TOKEN可以在gitlab页面获取到，详情参考上文【查看安装教程】一节。<br>根据提示，填写url、token、description、tags（多个tag以英文逗号分隔）、executor类型等信息，这里executor类型填写<code>shell</code>。</p><h1 id="注册Docker类型Runner"><a href="#注册Docker类型Runner" class="headerlink" title="注册Docker类型Runner"></a>注册Docker类型Runner</h1><p>Docker类型的Executor，在Runner程序所在主机上的Docker容器中运行CI任务。</p><p>前置条件：安装好了Runner，而且Runner所在主机已经安装配置好了Docker。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gitlab-runner register --url https://gitlab.voidking.com/ --registration-token <span class="variable">$REGISTRATION_TOKEN</span></span><br></pre></td></tr></table></figure><p>根据提示，填写url、token、description、tags、executor类型等信息，这里executor类型填写<code>docker</code>，最后填写一个默认的镜像。</p><h1 id="注册Docker-Machine类型Runner"><a href="#注册Docker-Machine类型Runner" class="headerlink" title="注册Docker Machine类型Runner"></a>注册Docker Machine类型Runner</h1><p>参考文档：</p><ul><li><a href="https://docs.gitlab.com/runner/executors/docker_machine.html" target="_blank" rel="noopener">Install and register GitLab Runner for autoscaling with Docker Machine</a></li><li><a href="https://docs.gitlab.com/runner/configuration/autoscale.html" target="_blank" rel="noopener">Docker Machine Executor autoscale configuration</a></li><li><a href="https://www.runoob.com/docker/docker-machine.html" target="_blank" rel="noopener">Docker Machine</a></li><li><a href="https://blog.csdn.net/RenshenLi/article/details/121585307" target="_blank" rel="noopener">docker-machine的安装与使用</a></li></ul><h2 id="安装虚拟机驱动"><a href="#安装虚拟机驱动" class="headerlink" title="安装虚拟机驱动"></a>安装虚拟机驱动</h2><p>可选驱动：</p><ul><li>virtualbox（推荐），参考文档<a href="https://www.voidking.com/dev-linux-virtualbox/">Linux下使用VirtualBox</a></li><li>qemu，参考文档<a href="https://github.com/machine-drivers/docker-machine-driver-qemu" target="_blank" rel="noopener">machine-drivers/docker-machine-driver-qemu</a></li><li>kvm，参考文档<a href="https://github.com/dhiltgen/docker-machine-kvm" target="_blank" rel="noopener">dhiltgen/docker-machine-kvm</a></li></ul><p>1、安装virtualbox驱动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install https://download.virtualbox.org/virtualbox/6.1.26/VirtualBox-6.1-6.1.26_145957_el7-1.x86_64.rpm</span><br></pre></td></tr></table></figure><p>2、安装编译环境</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kernel-devel kernel-devel install gcc make perl kernel-headers</span><br></pre></td></tr></table></figure><p>3、激活virtualbox内核支持</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/sbin/vboxconfig</span><br></pre></td></tr></table></figure><h2 id="安装Docker-Machine"><a href="#安装Docker-Machine" class="headerlink" title="安装Docker Machine"></a>安装Docker Machine</h2><p>1、下载docker-machine二进制文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://gitlab.com/gitlab-org/ci-cd/docker-machine/-/releases/v0.16.2-gitlab.15/downloads/docker-machine-Linux-x86_64</span><br><span class="line">mv docker-machine-Linux-x86_64 /usr/sbin/docker-machine</span><br><span class="line">chmod +x /usr/sbin/docker-machine</span><br></pre></td></tr></table></figure><p>更多版本可以访问<a href="https://gitlab.com/gitlab-org/ci-cd/docker-machine/-/releases" target="_blank" rel="noopener">docker-machine/releases</a>页面查找。</p><p>2、测试启动虚拟机</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-machine create -d virtualbox <span class="built_in">test</span></span><br></pre></td></tr></table></figure><h2 id="注册Runner"><a href="#注册Runner" class="headerlink" title="注册Runner"></a>注册Runner</h2><p>前置条件：安装好了Runner。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gitlab-runner register --url https://gitlab.voidking.com/ --registration-token <span class="variable">$REGISTRATION_TOKEN</span></span><br></pre></td></tr></table></figure><p>根据提示，填写url、token、description、tags、executor类型等信息，这里executor类型填写<code>docker+machine</code>，最后填写一个默认的镜像。</p><h2 id="配置镜像加速"><a href="#配置镜像加速" class="headerlink" title="配置镜像加速"></a>配置镜像加速</h2><p>参考文档：<a href="https://docs.docker.com/registry/" target="_blank" rel="noopener">Docker Registry</a></p><p>1、启动本地仓库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 5001:5000 -e REGISTRY_PROXY_REMOTEURL=https://gcr.io -e HTTPS_PROXY=socks5://192.168.56.1 -v /data/docker_registry_cache_gcr:/var/lib/registry --restart always --name gcr_io_registry registry:2</span><br><span class="line"></span><br><span class="line">docker run -d -p 5000:5000 -e REGISTRY_PROXY_REMOTEURL=https://registry-1.docker.io -v /data/docker_registry_cache_gcr:/var/lib/registry --restart always --name gcr_io_registry registry:2</span><br></pre></td></tr></table></figure><p>2、修改daemon.json</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"registry-mirrors"</span>: [<span class="string">"http://localhost:5000"</span>,<span class="string">"http://localhost:5001"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="配置缓存"><a href="#配置缓存" class="headerlink" title="配置缓存"></a>配置缓存</h2><p>1、启动minio容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name minio \</span><br><span class="line">--restart always \</span><br><span class="line">-p 9000:9000 \</span><br><span class="line">-p 9001:9001  \</span><br><span class="line">-v /data/minio/.minio:/data/.minio \</span><br><span class="line">-v /data/minio/<span class="built_in">export</span>:/<span class="built_in">export</span> \</span><br><span class="line">-e <span class="string">"MINIO_ROOT_USER=root"</span> \</span><br><span class="line">-e <span class="string">"MINIO_ROOT_PASSWORD=xxxxxx"</span> \</span><br><span class="line">minio/minio:latest server /<span class="built_in">export</span> --console-address <span class="string">":9001"</span></span><br></pre></td></tr></table></figure><p>2、页面访问<br><a href="http://192.168.56.101:9001/" target="_blank" rel="noopener">http://192.168.56.101:9001/</a> </p><h2 id="配置Runner"><a href="#配置Runner" class="headerlink" title="配置Runner"></a>配置Runner</h2><p>1、修改 /etc/gitlab-runner/config.toml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">concurrent &#x3D; 3</span><br><span class="line">check_interval &#x3D; 0</span><br><span class="line"></span><br><span class="line">[session_server]</span><br><span class="line">  session_timeout &#x3D; 1800</span><br><span class="line"></span><br><span class="line">[[runners]]</span><br><span class="line">  limit &#x3D; 3</span><br><span class="line">  name &#x3D; &quot;dockermachine&quot;</span><br><span class="line">  url &#x3D; &quot;https:&#x2F;&#x2F;gitlab.voidking.com&quot;</span><br><span class="line">  token &#x3D; &quot;xxx&quot;</span><br><span class="line">  executor &#x3D; &quot;docker+machine&quot;</span><br><span class="line">  [runners.custom_build_dir]</span><br><span class="line">    enabled &#x3D; true</span><br><span class="line">  [runners.cache]</span><br><span class="line">    Type &#x3D; &quot;s3&quot;</span><br><span class="line">    Path &#x3D; &quot;runner&quot;</span><br><span class="line">    Shared &#x3D; true</span><br><span class="line">    [runners.cache.s3]</span><br><span class="line">      ServerAddress &#x3D; &quot;192.168.56.101:9000&quot;</span><br><span class="line">      AccessKey &#x3D; &quot;root&quot;</span><br><span class="line">      SecretKey &#x3D; &quot;xxx&quot;</span><br><span class="line">      BucketName &#x3D; &quot;runner&quot;</span><br><span class="line">      Insecure &#x3D; true</span><br><span class="line">    [runners.cache.gcs]</span><br><span class="line">    [runners.cache.azure]</span><br><span class="line">  [runners.docker]</span><br><span class="line">    tls_verify &#x3D; false</span><br><span class="line">    image &#x3D; &quot;docker:19.03&quot;</span><br><span class="line">    privileged &#x3D; true</span><br><span class="line">    disable_entrypoint_overwrite &#x3D; false</span><br><span class="line">    oom_kill_disable &#x3D; false</span><br><span class="line">    disable_cache &#x3D; false</span><br><span class="line">    volumes &#x3D; [&quot;&#x2F;certs&#x2F;client&quot;,&quot;&#x2F;cache&quot;, &quot;&#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock&quot;]</span><br><span class="line">    pull_policy &#x3D; [&quot;if-not-present&quot;]</span><br><span class="line">    shm_size &#x3D; 0</span><br><span class="line">  [runners.machine]</span><br><span class="line">    IdleCount &#x3D; 5</span><br><span class="line">    MaxGrowthRate &#x3D; 1</span><br><span class="line">    IdleTime &#x3D; 1800</span><br><span class="line">    MachineDriver &#x3D; &quot;virtualbox&quot;</span><br><span class="line">    MachineName &#x3D; &quot;auto-scale-%s&quot;</span><br><span class="line">    MachineOptions &#x3D; [</span><br><span class="line">      &quot;engine-registry-mirror&#x3D;http:&#x2F;&#x2F;192.168.56.101:5000&quot;,</span><br><span class="line">      &quot;virtualbox-memory&#x3D;4048&quot;,</span><br><span class="line">      &quot;virtualbox-disk-size&#x3D;204800&quot;,</span><br><span class="line">      &quot;virtualbox-cpu-count&#x3D;2&quot;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><p>注意：runners.docker.image要指定版本，否则每次构建都会拉取最新版的docker，而最新版本的docker不支持http请求镜像仓库。<br>更多docker版本可以访问<a href="https://hub.docker.com/_/docker/tags?page=1" target="_blank" rel="noopener">dockerhub - docker</a>获取。</p><p>2、重新启动runner</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitlab-runner restart</span><br></pre></td></tr></table></figure><h2 id="管理Docker-Machine"><a href="#管理Docker-Machine" class="headerlink" title="管理Docker Machine"></a>管理Docker Machine</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker-machine ls</span><br><span class="line">docker-machine ssh xxx</span><br></pre></td></tr></table></figure><h1 id="K8S环境安装Runner"><a href="#K8S环境安装Runner" class="headerlink" title="K8S环境安装Runner"></a>K8S环境安装Runner</h1><p>本节中，我们在K8S中通过helm安装Runner。</p><p>参考文档：</p><ul><li><a href="https://docs.gitlab.com/runner/install/kubernetes.html" target="_blank" rel="noopener">GitLab Runner Helm Chart</a></li><li><a href="https://docs.gitlab.com/runner/install/kubernetes.html#running-docker-in-docker-containers-with-gitlab-runner" target="_blank" rel="noopener">GitLab Runner Helm Chart - Running Docker-in-Docker containers with GitLab Runner</a></li><li><a href="https://www.youtube.com/watch?v=0Fes86qtBSc" target="_blank" rel="noopener">GitLab CI CD | Install and Configure GitLab Runner on Kubernetes with Helm</a></li><li><a href="http://docs.idevops.site/gitlabci/chapter05/01/01-runner%E6%9E%84%E5%BB%BA%E7%8E%AF%E5%A2%83%E4%BC%98%E5%8C%96%E9%85%8D%E7%BD%AE/" target="_blank" rel="noopener">Runner构建优化</a></li><li><a href="https://www.qikqiak.com/post/gitlab-runner-install-on-k8s/" target="_blank" rel="noopener">在 Kubernetes 上安装 Gitlab CI Runner</a></li></ul><h2 id="准备存储"><a href="#准备存储" class="headerlink" title="准备存储"></a>准备存储</h2><p>通过helm安装runner，values当前还不支持配置storageclass。因此，需要先自行准备好runner的存储。主要参考文档<a href="https://www.voidking.com/dev-k8s-storageclass/">《K8S中安装配置StorageClass》</a></p><p>准备pvc定义 runner-pvc.yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gitlab-runner-cache</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">nfs-storage</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteMany</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">50Gi</span></span><br></pre></td></tr></table></figure><h2 id="准备Runner配置"><a href="#准备Runner配置" class="headerlink" title="准备Runner配置"></a>准备Runner配置</h2><p>1、添加gitlab repo</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm repo add gitlab https://charts.gitlab.io</span><br><span class="line">helm repo update</span><br></pre></td></tr></table></figure><p>2、查看可用的runner版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm search repo -l gitlab/gitlab-runner</span><br></pre></td></tr></table></figure><p>CHART VERSION有对应的APP VERSION版本，选择需要的APP VERSION版本。<br>这里选择14.0.0版本，对应CHART VERSION为0.30.0</p><p>3、下载chart</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm fetch gitlab/gitlab-runner --version 0.30.0</span><br><span class="line">tar -xzvf gitlab-runner-0.30.0.tgz</span><br></pre></td></tr></table></figure><p>4、values.yaml修改配置</p><ul><li>image：指定版本gitlab/gitlab-runner:alpine-v14.0.1，更多镜像版本可以访问<a href="https://hub.docker.com/r/gitlab/gitlab-runner/tags" target="_blank" rel="noopener">docker hub</a>查找</li><li>gitlabUrl：改成我们自己的的gitlab地址</li><li>runnerRegistrationToken：参考【查看安装教程】一节获取</li><li>resources：修改申请和限制的资源</li><li>rbac.create：改成true，创建sa用于创建runner</li><li>name：改成runner想要在gitlab中显示的名称</li><li>tags：改成runner想要注册的tags，多个tag以英文逗号分隔</li><li>replicas：改成runner期望的副本数，这些runner副本使用同一个name。</li><li>privileged：改成true，启用docker in docker</li><li>runners.config：支持自定义构建目录，支持docker in docker</li></ul><p>runners.config内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[runners.custom_build_dir]</span><br><span class="line">  enabled &#x3D; true</span><br><span class="line"></span><br><span class="line">[[runners.kubernetes.volumes.host_path]]</span><br><span class="line">  name &#x3D; &quot;docker&quot;</span><br><span class="line">  mount_path &#x3D; &quot;&#x2F;var&#x2F;run&#x2F;docker.sock&quot;</span><br><span class="line">  read_only &#x3D; true</span><br><span class="line">  host_path &#x3D; &quot;&#x2F;var&#x2F;run&#x2F;docker.sock&quot;</span><br></pre></td></tr></table></figure><p>我们想要对构建缓存使用持久化存储，因此需要添加</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## configure build cache</span></span><br><span class="line"><span class="attr">cibuild:</span></span><br><span class="line">  <span class="attr">cache:</span></span><br><span class="line">    <span class="attr">pvcName:</span> <span class="string">gitlab-runner-cache</span></span><br><span class="line">    <span class="attr">mountPath:</span> <span class="string">/home/gitlab-runner/ci-build-cache</span></span><br></pre></td></tr></table></figure><p>同时，需要修改gitlab-runner/templates/configmap.yaml<br>data.entrypoint部分添加runner配置，自动挂载存储</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add build cache and </span></span><br><span class="line"><span class="string">cat</span> <span class="string">&lt;&lt;EOF</span> <span class="string">&gt;&gt;/home/gitlab-runner/.gitlab-runner/config.toml</span></span><br><span class="line">  <span class="string">[[runners.kubernetes.volumes.pvc]]</span></span><br><span class="line">    <span class="string">name</span> <span class="string">=</span> <span class="string">"<span class="template-variable">&#123;&#123;.Values.cibuild.cache.pvcName&#125;&#125;</span>"</span></span><br><span class="line">    <span class="string">mount_path</span> <span class="string">=</span> <span class="string">"<span class="template-variable">&#123;&#123;.Values.cibuild.cache.mountPath&#125;&#125;</span>"</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Start the runner</span></span><br><span class="line"><span class="string">exec</span> <span class="string">/entrypoint</span> <span class="string">run</span> <span class="string">--user=gitlab-runner</span> <span class="string">\</span></span><br><span class="line">  <span class="string">--working-directory=/home/gitlab-runner</span></span><br></pre></td></tr></table></figure><h2 id="安装Runner"><a href="#安装Runner" class="headerlink" title="安装Runner"></a>安装Runner</h2><p>1、安装runner</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create ns gitlab-14-0</span><br><span class="line">kubectl apply -f runner-pvc.yaml -n gitlab-14-0</span><br><span class="line">helm install --namespace gitlab-14-0 gitlab-runner ./gitlab-runner</span><br></pre></td></tr></table></figure><p>2、查看安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get all -n gitlab-14-0</span><br><span class="line">kubectl get pvc -n gitlab-14-0</span><br><span class="line">kubectl logs pod/gitlab-runner-gitlab-runner-849988b584-kllqv -n gitlab-14-0</span><br></pre></td></tr></table></figure><p>3、查看runner注册结果<br><a href="https://gitlab.voidking.com/admin/runners" target="_blank" rel="noopener">https://gitlab.voidking.com/admin/runners</a></p><p>找到新的runner，点击右侧的Edit按钮，可以做进一步的配置。</p><h1 id="自定义builds路径"><a href="#自定义builds路径" class="headerlink" title="自定义builds路径"></a>自定义builds路径</h1><p>参考文档<a href="https://docs.gitlab.com/ee/ci/large_repositories/" target="_blank" rel="noopener">Optimize GitLab for large repositories</a></p><p>1、准备builds目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir /builds</span><br><span class="line">mkdir /cache</span><br><span class="line">chown gitlab-runner:gitlab-runner -R /builds</span><br><span class="line">chown gitlab-runner:gitlab-runner -R /cache</span><br></pre></td></tr></table></figure><p>2、修改runner配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/gitlab-runner/config.toml</span><br></pre></td></tr></table></figure><p>添加配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[[runners]]</span><br><span class="line">  builds_dir &#x3D; &quot;&#x2F;builds&quot;</span><br><span class="line">  cache_dir &#x3D; &quot;&#x2F;cache&quot;</span><br><span class="line">  [runners.custom_build_dir]</span><br><span class="line">    enabled &#x3D; true</span><br></pre></td></tr></table></figure><p>3、重启runner</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitlab-runner restart</span><br></pre></td></tr></table></figure><h1 id="取消注册Runner"><a href="#取消注册Runner" class="headerlink" title="取消注册Runner"></a>取消注册Runner</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看token</span></span><br><span class="line">gitlab-runner list</span><br><span class="line"><span class="comment"># token还可以在/etc/gitlab-runner/config.toml中查看</span></span><br><span class="line"><span class="comment"># 取消注册runner</span></span><br><span class="line">gitlab-runner unregister -t <span class="variable">$token</span> -u https://gitlab.voidking.com/</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;GitLab-Runner版本说明&quot;&gt;&lt;a href=&quot;#GitLab-Runner版本说明&quot; class=&quot;headerlink&quot; title=&quot;GitLab Runner版本说明&quot;&gt;&lt;/a&gt;GitLab Runner版本说明&lt;/h1&gt;&lt;p&gt;出于兼容性原因，GitLab Runner major.minor 版本应与 GitLab major.minor 版本保持同步。&lt;br&gt;较旧的runner可能仍然可以使用较新的 GitLab 版本，反之亦然。但是，如果存在版本差异，功能可能无法使用或无法正常工作。&lt;br&gt;minor版本更新时，会保障向后兼容性。但是，有时 GitLab 的minor版本更新会引入新功能，这些新功能需要 GitLab Runner 在同一minor版本上。&lt;/p&gt;
&lt;p&gt;需要特别注意的是：GitLab Runner 15.0 对注册 API 请求格式进行了更改。它阻止 GitLab Runner 与低于 14.8 的 GitLab 版本通信。我们必须使用适合 GitLab 版本的 Runner 版本，或升级 GitLab 应用程序。&lt;/p&gt;
&lt;p&gt;更多内容参考文档&lt;a href=&quot;https://docs.gitlab.com/runner/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitLab Runner&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
      <category term="git" scheme="https://www.voidking.com/categories/engineering/git/"/>
    
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
      <category term="cicd" scheme="https://www.voidking.com/tags/cicd/"/>
    
      <category term="git" scheme="https://www.voidking.com/tags/git/"/>
    
      <category term="gitlab" scheme="https://www.voidking.com/tags/gitlab/"/>
    
      <category term="helm" scheme="https://www.voidking.com/tags/helm/"/>
    
      <category term="virtualbox" scheme="https://www.voidking.com/tags/virtualbox/"/>
    
  </entry>
  
  <entry>
    <title>GitLab CI报错ERROR: Job failed (system failure)</title>
    <link href="https://www.voidking.com/dev-gitlab-ci-job-faild-system-failure/"/>
    <id>https://www.voidking.com/dev-gitlab-ci-job-faild-system-failure/</id>
    <published>2022-11-10T19:00:00.000Z</published>
    <updated>2022-11-10T19:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>GitLab CI任务，Runner使用的是<code>docker machine executor</code>类型的执行器，执行失败报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Running on runner-h6ezaymy-project-1037-concurrent-0 via runner-h6ezaymy-auto-scale-1668060271-ce458595...</span><br><span class="line">...</span><br><span class="line">WARNING: Failed to pull image with policy &quot;if-not-present&quot;: error during connect: Post https:&#x2F;&#x2F;192.168.99.251:2376&#x2F;v1.25&#x2F;images&#x2F;create?fromImage&#x3D;registry.gitlab.com%2Fgitlab-org%2Fgitlab-runner%2Fgitlab-runner-helper&amp;tag&#x3D;x86_64-58ba2b95: dial tcp 192.168.99.251:2376: connect: no route to host (manager.go:205:3s)</span><br><span class="line">ERROR: Job failed (system failure): error during connect: Post https:&#x2F;&#x2F;192.168.99.251:2376&#x2F;v1.25&#x2F;containers&#x2F;47272fbe49e4be0f85724ad99f0657b72f568810ce0f4914c57e7fcf114764e2&#x2F;wait: dial tcp 192.168.99.251:2376: connect: no route to host</span><br></pre></td></tr></table></figure><p>重试，问题依旧。</p><a id="more"></a><h1 id="排查思路"><a href="#排查思路" class="headerlink" title="排查思路"></a>排查思路</h1><p>问题原因猜测：</p><ul><li>偶发问题？确认是否能稳定复现</li><li>CICD配置问题？确认CICD配置，检查用法是否正确</li><li>runner问题？重启runner，再次尝试复现</li></ul><p>排查确认：</p><ul><li>偶发问题，重试失败，但是夜间可以成功执行</li><li>CICD配置正常，报错与配置无关，而且夜间可以成功执行</li><li>runner问题无法排除，需要进一步排查</li></ul><h1 id="Runner问题排查"><a href="#Runner问题排查" class="headerlink" title="Runner问题排查"></a>Runner问题排查</h1><h2 id="网络问题？"><a href="#网络问题？" class="headerlink" title="网络问题？"></a>网络问题？</h2><p>登录到runner所在宿主机，进入到runner</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-machine ssh runner-h6ezaymy-auto-scale-1668060271-ce458595</span><br></pre></td></tr></table></figure><p>提示vm不存在。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-machine ls</span><br></pre></td></tr></table></figure><p>查看当前的vm，负责运行任务的vm确实不存在了，看来不是网络问题。<br>怀疑是vm出问题被干掉了，然后重新创建了一个vm。<br>那么vm为什么会被干掉？看看日志吧。</p><h2 id="查看系统日志"><a href="#查看系统日志" class="headerlink" title="查看系统日志"></a>查看系统日志</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">journalctl -xe</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">cat /var/<span class="built_in">log</span>/messages | grep -i <span class="built_in">kill</span> -A3 -B3</span><br></pre></td></tr></table></figure><p>确实找到了程序被干掉的证据，刚好和gitlabci任务失败的时间吻合。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">11月 10 17:13:42 runner kernel: Out of memory: Kill process 12293 (MainHGCMthread) score 215 or sacrifice child</span><br><span class="line">11月 10 17:13:42 runner kernel: Killed process 12294 (EMT-0), UID 0, total-vm:4345420kB, anon-rss:45340kB, file-rss:2622104kB, shmem-rss:4kB</span><br></pre></td></tr></table></figure><p>那么这个vm为什么被干掉了？oom？</p><h2 id="CI任务占用内存太高？"><a href="#CI任务占用内存太高？" class="headerlink" title="CI任务占用内存太高？"></a>CI任务占用内存太高？</h2><p>检查ci任务的代码，并没有发现导致超高内存占用的逻辑。</p><h2 id="Linux-OOM机制"><a href="#Linux-OOM机制" class="headerlink" title="Linux OOM机制"></a>Linux OOM机制</h2><p>回想起Linux OOM的逻辑，并不是一个程序占用内存高就把它干掉，而是整个系统的内存高，才会选出一个打分最高的程序干掉。</p><p>这就合理了，下午的时候runner所在宿主机上跑满了任务，很有可能出现内存紧张的情况。而这个被干掉的runner当时被打分最高，所以被干掉了。</p><p>Linux OOM机制参考：</p><ul><li><a href="https://www.cnblogs.com/MrLiuZF/p/15229868.html" target="_blank" rel="noopener">Linux OOM机制分析</a></li><li><a href="https://www.vpsee.com/2013/10/how-to-configure-the-linux-oom-killer/" target="_blank" rel="noopener">如何理解和配置 Linux 下的 OOM Killer？</a></li></ul><h1 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h1><p>方法一：增加资源<br>升级宿主机内存，或者添加runner宿主机</p><p>方法二：错峰执行ci任务<br>比如这个失败的任务，还是夜间执行吧</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h1&gt;&lt;p&gt;GitLab CI任务，Runner使用的是&lt;code&gt;docker machine executor&lt;/code&gt;类型的执行器，执行失败报错：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Running on runner-h6ezaymy-project-1037-concurrent-0 via runner-h6ezaymy-auto-scale-1668060271-ce458595...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;WARNING: Failed to pull image with policy &amp;quot;if-not-present&amp;quot;: error during connect: Post https:&amp;#x2F;&amp;#x2F;192.168.99.251:2376&amp;#x2F;v1.25&amp;#x2F;images&amp;#x2F;create?fromImage&amp;#x3D;registry.gitlab.com%2Fgitlab-org%2Fgitlab-runner%2Fgitlab-runner-helper&amp;amp;tag&amp;#x3D;x86_64-58ba2b95: dial tcp 192.168.99.251:2376: connect: no route to host (manager.go:205:3s)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ERROR: Job failed (system failure): error during connect: Post https:&amp;#x2F;&amp;#x2F;192.168.99.251:2376&amp;#x2F;v1.25&amp;#x2F;containers&amp;#x2F;47272fbe49e4be0f85724ad99f0657b72f568810ce0f4914c57e7fcf114764e2&amp;#x2F;wait: dial tcp 192.168.99.251:2376: connect: no route to host&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;重试，问题依旧。&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
      <category term="troubleshooting" scheme="https://www.voidking.com/categories/engineering/troubleshooting/"/>
    
      <category term="git" scheme="https://www.voidking.com/categories/engineering/git/"/>
    
    
      <category term="问题排查" scheme="https://www.voidking.com/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
      <category term="cicd" scheme="https://www.voidking.com/tags/cicd/"/>
    
      <category term="git" scheme="https://www.voidking.com/tags/git/"/>
    
      <category term="gitlab" scheme="https://www.voidking.com/tags/gitlab/"/>
    
      <category term="oom" scheme="https://www.voidking.com/tags/oom/"/>
    
  </entry>
  
  <entry>
    <title>ArgoCD报错Unable to load data问题</title>
    <link href="https://www.voidking.com/dev-argocd-unable-to-load-data/"/>
    <id>https://www.voidking.com/dev-argocd-unable-to-load-data/</id>
    <published>2022-11-03T19:00:00.000Z</published>
    <updated>2022-11-03T19:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>断电后，k8s集群重新拉起。argocd无法同步gitlab中的数据，报错：</p><p>Unable to load data: Failed to fetch default: <code>git fetch origin --tags --force</code> failed exit status 128: fatal: unable to access ‘<a href="https://gitlab.voidking.com/devops/argocd.git/&#39;" target="_blank" rel="noopener">https://gitlab.voidking.com/devops/argocd.git/&#39;</a>: server certificate verification failed. CAfile: none CRLfile: none</p><a id="more"></a><h1 id="查日志"><a href="#查日志" class="headerlink" title="查日志"></a>查日志</h1><h2 id="查看argocd-repo-server日志"><a href="#查看argocd-repo-server日志" class="headerlink" title="查看argocd repo-server日志"></a>查看argocd repo-server日志</h2><p>repo-server负责从gitlab同步数据，查看一下它的日志。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs --tail=100 argo-cd-argocd-repo-server-547b6cf9f9-dff7d -n argocd</span><br></pre></td></tr></table></figure><p>内容为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time&#x3D;&quot;2022-11-03T06:04:33Z&quot; level&#x3D;error msg&#x3D;&quot;finished unary call with code Unknown&quot; error&#x3D;&quot;Get \&quot;https:&#x2F;&#x2F;gitlab.voidking.com&#x2F;devops&#x2F;argocd.git&#x2F;info&#x2F;refs?service&#x3D;git-upload-pack\&quot;: x509: certificate is not valid for any names, but wanted to match gitlab.voidking.com&quot; grpc.code&#x3D;Unknown grpc.method&#x3D;GenerateManifest grpc.request.deadline&#x3D;&quot;2022-11-03T06:05:33Z&quot; grpc.service&#x3D;repository.RepoServerService grpc.start_time&#x3D;&quot;2022-11-03T06:04:33Z&quot; grpc.time_ms&#x3D;38.558 span.kind&#x3D;server system&#x3D;grpc</span><br></pre></td></tr></table></figure><h2 id="查看argocd其他组件日志"><a href="#查看argocd其他组件日志" class="headerlink" title="查看argocd其他组件日志"></a>查看argocd其他组件日志</h2><p>挨个查看argocd其他组件日志，其中dex-server看着有些问题</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs --tail=100 argo-cd-argocd-dex-server-7cc5cc5455-c7q29  -n argocd</span><br></pre></td></tr></table></figure><p>内容为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">time&#x3D;&quot;2022-10-31T03:24:16Z&quot; level&#x3D;info msg&#x3D;&quot;keys expired, rotating&quot;</span><br><span class="line">time&#x3D;&quot;2022-10-31T03:24:16Z&quot; level&#x3D;info msg&#x3D;&quot;keys rotated, next rotation: 2022-10-31 09:24:16.595711381 +0000 UTC&quot;</span><br></pre></td></tr></table></figure><h1 id="证书问题？"><a href="#证书问题？" class="headerlink" title="证书问题？"></a>证书问题？</h1><p>怀疑是证书到期导致的，打算对证书进行更新，参考文档<a href="https://argo-cd.readthedocs.io/en/stable/operator-manual/tls/" target="_blank" rel="noopener">TLS configuration</a></p><p>但是，怎么确认证书已经到期了呢？具体怎么操作更新证书？<br>没有找到方法，先看看还有没有其他可能。</p><h1 id="重启一下试试？"><a href="#重启一下试试？" class="headerlink" title="重启一下试试？"></a>重启一下试试？</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">k get pod argo-cd-argocd-repo-server-547b6cf9f9-dff7d -n argocd -oyaml | k replace --force -f -</span><br></pre></td></tr></table></figure><p>重建pod后，问题解决了。。。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h1&gt;&lt;p&gt;断电后，k8s集群重新拉起。argocd无法同步gitlab中的数据，报错：&lt;/p&gt;
&lt;p&gt;Unable to load data: Failed to fetch default: &lt;code&gt;git fetch origin --tags --force&lt;/code&gt; failed exit status 128: fatal: unable to access ‘&lt;a href=&quot;https://gitlab.voidking.com/devops/argocd.git/&amp;#39;&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://gitlab.voidking.com/devops/argocd.git/&amp;#39;&lt;/a&gt;: server certificate verification failed. CAfile: none CRLfile: none&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
      <category term="troubleshooting" scheme="https://www.voidking.com/categories/engineering/troubleshooting/"/>
    
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
      <category term="问题排查" scheme="https://www.voidking.com/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
      <category term="argocd" scheme="https://www.voidking.com/tags/argocd/"/>
    
      <category term="cicd" scheme="https://www.voidking.com/tags/cicd/"/>
    
      <category term="devops" scheme="https://www.voidking.com/tags/devops/"/>
    
  </entry>
  
  <entry>
    <title>KubeSphere版本升级</title>
    <link href="https://www.voidking.com/dev-kubesphere-upgrade/"/>
    <id>https://www.voidking.com/dev-kubesphere-upgrade/</id>
    <published>2022-11-02T10:00:00.000Z</published>
    <updated>2022-11-18T10:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h1><p>当前KubeSphere版本v3.2.1，但是因为权限管理不好用（不能针对不同集群单独授权），因此计划升级到v3.3.1。<br>KubeSphere v3.3.0之后支持为每个集群单独设置集群成员和集群角色，提供了更细粒度的权限管控机制，进一步完善了 KubeSphere 的多租户系统。</p><p>参考文档：</p><ul><li><a href="https://baijiahao.baidu.com/s?id=1737027419479012228&wfr=spider&for=pc" target="_blank" rel="noopener">KubeSphere 3.3.0 全新升级，来了！</a></li><li><a href="https://kubesphere.io/zh/docs/v3.3/release/release-v331/" target="_blank" rel="noopener">Release Notes - 3.3.1 版本说明</a></li><li><a href="https://kubesphere.io/zh/docs/v3.3/upgrade/upgrade-with-ks-installer/" target="_blank" rel="noopener">使用 ks-installer 升级</a></li><li><a href="https://kubesphere.io/zh/docs/v3.3/upgrade/air-gapped-upgrade-with-ks-installer/" target="_blank" rel="noopener">使用 ks-installer 离线升级</a></li></ul><a id="more"></a><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><ul><li>您应该先在测试环境中实施升级模拟。在测试环境中成功升级并且所有应用程序都正常运行之后，再在生产环境中升级您的集群。</li><li>在升级过程中，应用程序可能会短暂中断（尤其是单副本容器组），请安排合理的升级时间。</li><li>建议在生产环境中升级之前备份 etcd 和有状态应用程序。您可以使用 Velero 来备份和迁移 Kubernetes 资源以及持久化存储卷。</li></ul><p>参考文档：</p><ul><li><a href="https://kubesphere.io/zh/docs/v3.3/upgrade/overview/" target="_blank" rel="noopener">升级 - 概述</a></li><li><a href="https://velero.io/" target="_blank" rel="noopener">Velero</a></li><li><a href="https://baijiahao.baidu.com/s?id=1736481781028427417&wfr=spider&for=pc" target="_blank" rel="noopener">详解kubernetes备份恢复利器 Velero</a></li></ul><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>1、备份<br>2、kubesphere执行升级</p><h1 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h1><h2 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h2><p>备份etcd，参考 <a href="https://www.voidking.com/dev-k8s-etcd-backup-restore/">《K8S集群中etcd备份和恢复》</a></p><h2 id="有状态应用程序"><a href="#有状态应用程序" class="headerlink" title="有状态应用程序"></a>有状态应用程序</h2><p>未完待续</p><h1 id="执行升级"><a href="#执行升级" class="headerlink" title="执行升级"></a>执行升级</h1><p>1、下载yaml文件&amp;提交到k8s集群</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/kubesphere/ks-installer/releases/download/v3.3.1/kubesphere-installer.yaml</span><br><span class="line">kubectl apply -f kubesphere-installer.yaml  --force</span><br></pre></td></tr></table></figure><p>2、观察升级进展</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl get all -n kubesphere-system</span><br><span class="line">kubectl get pods -n kubesphere-system</span><br><span class="line">kubectl describe job.batch/ks-upgrade -n kubesphere-system</span><br><span class="line">kubectl logs -f ks-installer-895b8994d-5qrjs -n kubesphere-system</span><br></pre></td></tr></table></figure><p>3、验证升级后的版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -n kubesphere-system -oyaml | grep image:</span><br></pre></td></tr></table></figure><p>浏览器访问ks，右上角点击<code>用户名</code>，<code>关于</code>，就可以看到当前ks版本。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;需求描述&quot;&gt;&lt;a href=&quot;#需求描述&quot; class=&quot;headerlink&quot; title=&quot;需求描述&quot;&gt;&lt;/a&gt;需求描述&lt;/h1&gt;&lt;p&gt;当前KubeSphere版本v3.2.1，但是因为权限管理不好用（不能针对不同集群单独授权），因此计划升级到v3.3.1。&lt;br&gt;KubeSphere v3.3.0之后支持为每个集群单独设置集群成员和集群角色，提供了更细粒度的权限管控机制，进一步完善了 KubeSphere 的多租户系统。&lt;/p&gt;
&lt;p&gt;参考文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://baijiahao.baidu.com/s?id=1737027419479012228&amp;wfr=spider&amp;for=pc&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;KubeSphere 3.3.0 全新升级，来了！&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://kubesphere.io/zh/docs/v3.3/release/release-v331/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Release Notes - 3.3.1 版本说明&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://kubesphere.io/zh/docs/v3.3/upgrade/upgrade-with-ks-installer/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;使用 ks-installer 升级&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://kubesphere.io/zh/docs/v3.3/upgrade/air-gapped-upgrade-with-ks-installer/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;使用 ks-installer 离线升级&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
      <category term="kubesphere" scheme="https://www.voidking.com/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>K8S配置使用imagePullSecrets</title>
    <link href="https://www.voidking.com/dev-k8s-imagepullsecrets/"/>
    <id>https://www.voidking.com/dev-k8s-imagepullsecrets/</id>
    <published>2022-10-22T14:00:00.000Z</published>
    <updated>2022-12-19T19:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><a href="https://www.voidking.com/dev-harbor-start/">《Harbor入门篇》</a>一文中，我们已经安装配置好了Harbor。<br>本文中，我们来学习一下怎样在K8S中配置使用imagePullSecrets，从Harbor或者其他私有镜像仓库拉取镜像。</p><p>参考文档：</p><ul><li><a href="https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/pull-image-private-registry/" target="_blank" rel="noopener">从私有仓库拉取镜像</a></li></ul><a id="more"></a><h1 id="创建imagePullSecrets"><a href="#创建imagePullSecrets" class="headerlink" title="创建imagePullSecrets"></a>创建imagePullSecrets</h1><p>创建一个docker-registry类型的secret，名字为<code>harbor-secret</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret docker-registry harbor-secret \</span><br><span class="line">  --docker-server=harbor.voidking.com \</span><br><span class="line">  --docker-username=admin \</span><br><span class="line">  --docker-password=Harbor12345</span><br></pre></td></tr></table></figure><h1 id="使用imagePullSecrets"><a href="#使用imagePullSecrets" class="headerlink" title="使用imagePullSecrets"></a>使用imagePullSecrets</h1><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">testpod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">harbor.voidking.com/voidking/busybox:1.31</span></span><br><span class="line">    <span class="attr">command:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="string">sleep</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"36000"</span></span><br><span class="line">  <span class="attr">imagePullSecrets:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">harbor-secret</span></span><br></pre></td></tr></table></figure><h1 id="给pod添加默认imagePullSecrets"><a href="#给pod添加默认imagePullSecrets" class="headerlink" title="给pod添加默认imagePullSecrets"></a>给pod添加默认imagePullSecrets</h1><p>上面的配置，已经可以正常从harbor镜像仓库拉取镜像了。<br>但是，每个pod都需要指定一下imagePullSecrets，也是比较麻烦。<br>这里我们可以在命名空间默认sa中添加imagePullSecrets，这样我们就不用在pod中指定imagePullSecrets了，创建pod时会自动注入。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl patch serviceaccount default \</span><br><span class="line">  -p <span class="string">"&#123;\"imagePullSecrets\": [&#123;\"name\": \"docker-secret\"&#125;]&#125;"</span> \</span><br><span class="line">  -n &lt;your-namespace&gt;</span><br></pre></td></tr></table></figure><h1 id="全局配置imagePullSecrets"><a href="#全局配置imagePullSecrets" class="headerlink" title="全局配置imagePullSecrets"></a>全局配置imagePullSecrets</h1><p>如果新增了namespace，那么这个namespace就需要单独添加一次imagePullSecrets，而且这个namespace的sa也需要添加imagePullSecrets。</p><p>这里可以使用imagepullsecret-patcher来简化我们的工作，参考文档：</p><ul><li><a href="https://devopstales.github.io/kubernetes/k8s-imagepullsecret-patcher/" target="_blank" rel="noopener">How to use imagePullSecrets cluster-wide??</a></li><li><a href="https://medium.com/titansoft-engineering/kubernetes-cluster-wide-access-to-private-container-registry-with-imagepullsecret-patcher-b8b8fb79f7e5" target="_blank" rel="noopener">Kubernetes cluster-wide access to private container registry with imagepullsecret-patcher</a></li><li><a href="https://github.com/titansoft-pte-ltd/imagepullsecret-patcher" target="_blank" rel="noopener">imagepullsecret-patcher</a></li><li><a href="https://github.com/titansoft-pte-ltd/imagepullsecret-patcher/tree/master/deploy-example" target="_blank" rel="noopener">imagepullsecret-patcher deploy-example</a></li></ul><p>1、创建 sa.yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">""</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">secrets</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">serviceaccounts</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">patch</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">create</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">delete</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">""</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">namespaces</span></span><br><span class="line">  <span class="attr">verbs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">list</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">get</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">imagepullsecret-patcher</span></span><br></pre></td></tr></table></figure><p>2、获取 dockerconfigjson</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secret harbor-secret -oyaml</span><br></pre></td></tr></table></figure><p>3、创建 deployment.yaml</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">kubernetes.io/dockerconfigjson</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">image-pull-secret-src</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="string">.dockerconfigjson:</span> <span class="string">eyJhdXRocyI6eyJnY3IuaW8iOnsicGFzc3dvcmQiOiJ7XCJhdXRoXCI6e1wiZ2NyLmlvXCI6e1widXNlcm5hbWVcIjpcIl9qc29uX2tleVwiLFwicGFzc3dvcmRcIjpcInt9XCJ9fX0iLCJ1c2VybmFtZSI6Il9qc29uX2tleSJ9fX0=</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">automountServiceAccountToken:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">serviceAccountName:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">imagepullsecret-patcher</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">"quay.io/titansoft/imagepullsecret-patcher:v0.14"</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CONFIG_FORCE</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">"true"</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CONFIG_DEBUG</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">"false"</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CONFIG_ALLSERVICEACCOUNT</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">"true"</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CONFIG_DOCKERCONFIGJSONPATH</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">"/app/secrets/.dockerconfigjson"</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CONFIG_SECRETNAME</span></span><br><span class="line">              <span class="attr">value:</span> <span class="string">"harbor-secret"</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">src-dockerconfigjson</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">"/app/secrets"</span></span><br><span class="line">              <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">          <span class="attr">resources:</span></span><br><span class="line">            <span class="attr">requests:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="number">0.1</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">15Mi</span></span><br><span class="line">            <span class="attr">limits:</span></span><br><span class="line">              <span class="attr">cpu:</span> <span class="number">0.2</span></span><br><span class="line">              <span class="attr">memory:</span> <span class="string">30Mi</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">src-dockerconfigjson</span></span><br><span class="line">          <span class="attr">secret:</span> </span><br><span class="line">            <span class="attr">secretName:</span> <span class="string">image-pull-secret-src</span></span><br></pre></td></tr></table></figure><p>其中dockerconfigjson改成步骤2中获取到的配置，CONFIG_SECRETNAME变量的value改成期望的secret名称。</p><p>4、安装imagepullsecret-patcher</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f sa.yaml</span><br><span class="line">kubectl apply -f deployment.yaml</span><br></pre></td></tr></table></figure><p>5、查看安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get all -n imagepullsecret-patcher</span><br><span class="line">kubectl get sa -n imagepullsecret-patcher</span><br><span class="line">kubectl get sa default -n imagepullsecret-patcher -oyaml</span><br></pre></td></tr></table></figure><p>可以发现，<code>harbor-secret</code> 已经注入到了sa中。</p><h1 id="删除imagePullSecrets"><a href="#删除imagePullSecrets" class="headerlink" title="删除imagePullSecrets"></a>删除imagePullSecrets</h1><p>有时候，我们需要替换imagePullSecrets，比如imagePullSecrets名称发生了变更。这时就需要删除原本的imagePullSecrets。</p><p>单个sa删除imagePullSecrets方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INDEX=$(kubectl get sa default -n imagepullsecret-patcher -o json | jq <span class="string">'.imagePullSecrets | map(.name == "harbor-secret") | index(true)'</span>)</span><br><span class="line">kubectl patch sa default --<span class="built_in">type</span>=json -p=<span class="string">"[&#123;'op': 'remove', 'path': '/imagePullSecrets/<span class="variable">$INDEX</span>'&#125;]"</span> -n imagepullsecret-patcher</span><br></pre></td></tr></table></figure><p>批量sa删除imagePullSecrets方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">kubectl get ns | awk <span class="string">'&#123;print $1&#125;'</span> | grep -v <span class="string">"NAME"</span> &gt; namespace.txt</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> namespace <span class="keyword">in</span> `cat namespace.txt`;<span class="keyword">do</span></span><br><span class="line">  INDEX=$(kubectl get sa default -n <span class="variable">$namespace</span> -o json | jq <span class="string">'.imagePullSecrets | map(.name == "harbor-secret") | index(true)'</span>)</span><br><span class="line">  kubectl patch sa default --<span class="built_in">type</span>=json -p=<span class="string">"[&#123;'op': 'remove', 'path': '/imagePullSecrets/<span class="variable">$INDEX</span>'&#125;]"</span> -n <span class="variable">$namespace</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.voidking.com/dev-harbor-start/&quot;&gt;《Harbor入门篇》&lt;/a&gt;一文中，我们已经安装配置好了Harbor。&lt;br&gt;本文中，我们来学习一下怎样在K8S中配置使用imagePullSecrets，从Harbor或者其他私有镜像仓库拉取镜像。&lt;/p&gt;
&lt;p&gt;参考文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://kubernetes.io/zh-cn/docs/tasks/configure-pod-container/pull-image-private-registry/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;从私有仓库拉取镜像&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="docker" scheme="https://www.voidking.com/categories/engineering/docker/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
    
      <category term="docker" scheme="https://www.voidking.com/tags/docker/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
      <category term="harbor" scheme="https://www.voidking.com/tags/harbor/"/>
    
  </entry>
  
  <entry>
    <title>K8S中安装配置KubeSphere</title>
    <link href="https://www.voidking.com/dev-k8s-kubesphere/"/>
    <id>https://www.voidking.com/dev-k8s-kubesphere/</id>
    <published>2022-10-10T15:00:00.000Z</published>
    <updated>2023-01-11T10:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="KubeSphere简介"><a href="#KubeSphere简介" class="headerlink" title="KubeSphere简介"></a>KubeSphere简介</h1><blockquote><p>KubeSphere 愿景是打造一个以 Kubernetes 为内核的云原生分布式操作系统，它的架构可以非常方便地使第三方应用与云原生生态组件进行即插即用（plug-and-play）的集成，支持云原生应用在多云与多集群的统一分发和运维管理。</p></blockquote><p>简单来说，KubeSphere（下文简称ks）就是一个容器管理平台，可以图形化管理多个K8S集群。</p><p>相关链接：</p><ul><li><a href="https://kubesphere.io/zh/" target="_blank" rel="noopener">KubeSphere官网</a></li><li><a href="https://kubesphere.io/zh/videos/" target="_blank" rel="noopener">KubeSphere学习视频</a></li></ul><a id="more"></a><h1 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h1><p>参考<a href="https://kubesphere.io/zh/docs/v3.3/installing-on-kubernetes/introduction/prerequisites/" target="_blank" rel="noopener">在 Kubernetes 上安装 KubeSphere - 准备工作</a>，确认环境满足ks安装需求。</p><h2 id="k8s版本"><a href="#k8s版本" class="headerlink" title="k8s版本"></a>k8s版本</h2><p>计划安装kubesphere-v3.3.0版本，需要确认 Kubernetes 版本必须为：v1.19.x，v1.20.x，v1.21.x，v1.22.x 或 v1.23.x（实验性支持）。</p><h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>可用 CPU &gt; 1 核；内存 &gt; 2 G。CPU 必须为 x86_64，暂时不支持 Arm 架构的 CPU。</p><h2 id="StorageClass"><a href="#StorageClass" class="headerlink" title="StorageClass"></a>StorageClass</h2><p>Kubernetes 集群已配置默认 StorageClass（请使用 <code>kubectl get sc</code> 进行确认）。<br>这一条是最重要的，因为k8s集群默认并不会配置storageclass，需要我们自己单独配置。<br>storage安装配置方法参考<a href="https://www.voidking.com/dev-k8s-storageclass/">《K8S中安装配置StorageClass》</a></p><h1 id="安装ks"><a href="#安装ks" class="headerlink" title="安装ks"></a>安装ks</h1><p>参考<a href="https://kubesphere.io/zh/docs/v3.3/installing-on-kubernetes/introduction/overview/" target="_blank" rel="noopener">在 Kubernetes 上安装 KubeSphere - 概述</a>，安装kubesphere-v3.3.0版本</p><p>1、下载yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/kubesphere/ks-installer/releases/download/v3.3.0/kubesphere-installer.yaml</span><br><span class="line">wget https://github.com/kubesphere/ks-installer/releases/download/v3.3.0/cluster-configuration.yaml</span><br></pre></td></tr></table></figure><p>2、修改yaml<br>按需修改cluster-configuration.yaml。<br>ks-apiserver和ks-controller-manager的资源调整示例如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">common:</span></span><br><span class="line">    <span class="attr">core:</span></span><br><span class="line">      <span class="attr">console:</span></span><br><span class="line">        <span class="attr">enableMultiLogin:</span> <span class="literal">true</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">30880</span></span><br><span class="line">      <span class="attr">apiserver:</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">400Mi</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">"2"</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">8Gi</span></span><br><span class="line">      <span class="attr">controllerManager:</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">400Mi</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">"2"</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">8Gi</span></span><br></pre></td></tr></table></figure><p>因为ks-apiserver和ks-controller-manager容易OOM，所以内存上限设置高。</p><p>3、提交yaml到k8s集群</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f kubesphere-installer.yaml</span><br><span class="line">kubectl apply -f cluster-configuration.yaml</span><br></pre></td></tr></table></figure><p>4、查看安装过程</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">k describe pod/ks-installer-xxx-xxx -n kubesphere-system</span><br><span class="line">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l <span class="string">'app in (ks-install, ks-installer)'</span> -o jsonpath=<span class="string">'&#123;.items[0].metadata.name&#125;'</span>) -f</span><br></pre></td></tr></table></figure><p>5、查看ks状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl get all -n kubesphere-system</span><br><span class="line">kubectl get svc/ks-console -n kubesphere-system</span><br></pre></td></tr></table></figure><h1 id="storageclass问题排查"><a href="#storageclass问题排查" class="headerlink" title="storageclass问题排查"></a>storageclass问题排查</h1><p>redis没有ready，一直处于pending状态，查看详情</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe pod/redis-d744b7468-45sh4 -n kubesphere-system</span><br></pre></td></tr></table></figure><p>报错：0/x nodes are available: x pod has unbound immediate PersistentVolumeClaims.</p><p>查看nfs-client-provisioner日志</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs --tail=100 nfs-client-provisioner-7975f9b954-7fw5l</span><br></pre></td></tr></table></figure><p>报错：<br>provision “kubesphere-system/redis-pvc” class “nfs-storage”: unexpected error getting claim reference: selfLink was empty, can’t make reference</p><p>这是因为，1.20.x之后的k8s版本，selflink已经弃用了。而nfs-client-provisioner的实现基于selflink，因此报错。</p><p>解决办法：apiserver启动时添加参数<code>--feature-gates=RemoveSelfLink=false</code><br>1、编辑kube-apiserver.yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/kubernetes/manifests/kube-apiserver.yaml</span><br></pre></td></tr></table></figure><p>如下修改：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">kube-apiserver</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">--...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">--feature-gates=RemoveSelfLink=false</span></span><br></pre></td></tr></table></figure><p>2、重建apiserver pod<br>因为apiserver是static pod，所以在修改完kube-apiserver.yaml后会自动重建。</p><p>参考文档：</p><ul><li><a href="https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner/issues/25" target="_blank" rel="noopener">unexpected error getting claim reference: selfLink was empty, can’t make reference</a></li><li><a href="https://www.cnblogs.com/zhangsi-lzq/p/14292628.html" target="_blank" rel="noopener">kubernetes1.20版本 nfs-provisioner报错问题:”selfLink was empty”</a></li></ul><h1 id="验证ks"><a href="#验证ks" class="headerlink" title="验证ks"></a>验证ks</h1><p>KS默认对外开放 30880 端口，通过 NodePort (IP:30880) 使用默认帐户和密码 (admin/P@88w0rd) 访问 Web 控制台。<br><a href="http://192.168.56.101:30880/login" target="_blank" rel="noopener">http://192.168.56.101:30880/login</a><br>第一次登录时，会提示修改密码。</p><h1 id="修改ks配置"><a href="#修改ks配置" class="headerlink" title="修改ks配置"></a>修改ks配置</h1><p>如果ks已经安装完成，想要修改ks集群配置的话，可以通过修改clusterconfiguration配置来实现。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get cm kubesphere-config -n kubesphere-system -oyaml</span><br><span class="line">kubectl get clusterconfiguration ks-installer -n kubesphere-system -oyaml</span><br><span class="line">kubectl edit clusterconfiguration ks-installer -n kubesphere-system</span><br></pre></td></tr></table></figure><p>修改ks-installer配置后，相关pod会自动重启（请耐心等待，大概5分钟内会自动重启）。</p><p>参考文档<a href="https://kubesphere.io/zh/docs/v3.3/access-control-and-account-management/external-authentication/use-an-ldap-service/" target="_blank" rel="noopener">KubeSphere - LDAP身份提供者</a></p><h1 id="重置ks密码"><a href="#重置ks密码" class="headerlink" title="重置ks密码"></a>重置ks密码</h1><p>如果忘记了ks的密码，可以通过kubectl命令进行重置。参考文档<a href="https://kubesphere.io/docs/v3.3/faq/access-control/forgot-password/" target="_blank" rel="noopener">Reset the Account Password</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl patch users &lt;USERNAME&gt; -p <span class="string">'&#123;"spec":&#123;"password":"&lt;YOURPASSWORD&gt;"&#125;&#125;'</span> --<span class="built_in">type</span>=<span class="string">'merge'</span> &amp;&amp; kubectl annotate users &lt;USERNAME&gt; iam.kubesphere.io/password-encrypted-</span><br></pre></td></tr></table></figure><h1 id="nginx配置"><a href="#nginx配置" class="headerlink" title="nginx配置"></a>nginx配置</h1><p>配置好nginx，通过域名访问ks正常，但是在ks页面上访问容器终端时可能报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Could not connect to the container. Do you have sufficient privileges?</span><br></pre></td></tr></table></figure><p>这是因为页面访问终端需要websocket支持，所以nginx配置中需要添加websocket支持，配置方法参考<a href="https://www.voidking.com/dev-nginx-start/">《Nginx入门篇》</a>。</p><h1 id="添加项目到企业空间"><a href="#添加项目到企业空间" class="headerlink" title="添加项目到企业空间"></a>添加项目到企业空间</h1><p>Kubernetes命名空间就是KubeSphere项目，这些项目可以在 平台管理-&gt;集群管理-&gt;具体集群-&gt;项目 中查看到。</p><p>添加现有KubeSphere项目到企业空间：<br>1、以管理员身份登录KubeSphere控制台，转到集群管理页面。点击项目，可以查看在当前集群中运行的所有项目。<br>2、通过 kubectl 创建的命名空间不属于任何企业空间。请点击右侧的三个点，选择分配企业空间。<br>3、在弹出的对话框中，为该项目选择一个企业空间和项目管理员，然后点击确定。<br>4、转到企业空间，可以在项目页面看到该项目已显示。</p><p>参考文档：</p><ul><li><a href="https://kubesphere.io/zh/docs/v3.3/faq/access-control/add-kubernetes-namespace-to-kubesphere-workspace/" target="_blank" rel="noopener">添加现有 Kubernetes 命名空间至 KubeSphere 企业空间</a></li></ul><h1 id="批量添加项目到企业空间"><a href="#批量添加项目到企业空间" class="headerlink" title="批量添加项目到企业空间"></a>批量添加项目到企业空间</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get ns |grep voidking | awk <span class="string">'&#123;print $1&#125;'</span> | xargs kubectl patch ns -p <span class="string">'metadata: &#123;labels: &#123;kubesphere.io/workspace: "voidking"&#125;, annotations: &#123;kubesphere.io/creator: "haojin"&#125;&#125;'</span></span><br></pre></td></tr></table></figure><h1 id="ks多集群"><a href="#ks多集群" class="headerlink" title="ks多集群"></a>ks多集群</h1><p>参考文档：</p><ul><li><a href="https://blog.51cto.com/u_15127592/2803374" target="_blank" rel="noopener">Kubernetes 多集群在开源项目 KubeSphere 的应用</a></li></ul><h1 id="多租户管理"><a href="#多租户管理" class="headerlink" title="多租户管理"></a>多租户管理</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul><li>集群：k8s集群。</li><li>企业空间：业务管理基本单元。</li><li>公司部门：公司内部的部门和ks部门没有必然联系。</li><li>ks部门：企业空间中权限划分的单位，每个企业空间包含多个ks部门，每个ks部门包含多个用户，方便批量授权。</li><li>ks用户：每个公司成员，对应一个ks用户，一个ks用户可以属于多个ks部门。</li><li>项目：项目对应k8s中的namespace，一个项目可以同时分配给不同的ks部门。</li></ul><p>集群和企业空间，是多对多的关系。一个企业空间可以包含多个集群，一个集群可以被多个企业空间包含。</p><p>ks中每个项目只能添加到一个企业空间，因此企业空间按照业务来划分，作为业务管理的基本单位。</p><p>企业空间作为操作kubesphere的唯一入口，在企业空间授权一个项目的管理权限后，如果用户通过集群管理找到一个项目，是没有权限的。</p><p>每个企业空间，建议设置1-3个管理员。管理员负责本企业空间的具体权限管理，例如添加管理员、新建部门、给新成员授权等</p><p>ks部门划分的目的，是为了项目的权限管理，因此需要先对集群和项目权限进行规划。<br>通过ks部门，授权可以精确到每个项目和每个人。</p><p>参考文档：</p><ul><li><a href="https://kubesphere.io/zh/docs/v3.3/access-control-and-account-management/multi-tenancy-in-kubesphere/" target="_blank" rel="noopener">KubeSphere 中的多租户</a></li><li><a href="https://kubesphere.io/zh/docs/v3.3/faq/access-control/add-kubernetes-namespace-to-kubesphere-workspace/" target="_blank" rel="noopener">添加现有 Kubernetes 命名空间至 KubeSphere 企业空间</a></li></ul><h2 id="多租户管理操作流程"><a href="#多租户管理操作流程" class="headerlink" title="多租户管理操作流程"></a>多租户管理操作流程</h2><p>1、创建企业空间，并关联集群</p><p>2、添加现有项目到企业空间</p><p>3、创建部门，针对部门精细化授权</p><p>4、添加用户到部门</p><p>5、通知ks入口都使用企业空间，不要使用集群管理</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;KubeSphere简介&quot;&gt;&lt;a href=&quot;#KubeSphere简介&quot; class=&quot;headerlink&quot; title=&quot;KubeSphere简介&quot;&gt;&lt;/a&gt;KubeSphere简介&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;KubeSphere 愿景是打造一个以 Kubernetes 为内核的云原生分布式操作系统，它的架构可以非常方便地使第三方应用与云原生生态组件进行即插即用（plug-and-play）的集成，支持云原生应用在多云与多集群的统一分发和运维管理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单来说，KubeSphere（下文简称ks）就是一个容器管理平台，可以图形化管理多个K8S集群。&lt;/p&gt;
&lt;p&gt;相关链接：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://kubesphere.io/zh/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;KubeSphere官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://kubesphere.io/zh/videos/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;KubeSphere学习视频&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
      <category term="troubleshooting" scheme="https://www.voidking.com/categories/engineering/troubleshooting/"/>
    
      <category term="storage" scheme="https://www.voidking.com/categories/engineering/storage/"/>
    
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
      <category term="问题排查" scheme="https://www.voidking.com/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
      <category term="kubesphere" scheme="https://www.voidking.com/tags/kubesphere/"/>
    
      <category term="storageclass" scheme="https://www.voidking.com/tags/storageclass/"/>
    
      <category term="存储" scheme="https://www.voidking.com/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>KubeSphere登录后报错Session Timeout</title>
    <link href="https://www.voidking.com/dev-kubesphere-session-timeout/"/>
    <id>https://www.voidking.com/dev-kubesphere-session-timeout/</id>
    <published>2022-10-10T15:00:00.000Z</published>
    <updated>2022-11-02T11:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>大部分用户能够正常登录和使用ks，但是个别用户（voidking01）登录ks后报错。<br>用户登录ks，正常；登录后查看工作台，正常；查看host集群和只包含host集群的企业空间，正常。</p><p>但是，选择一个非host集群或者选择一个包含非host集群的企业空间后，页面就会弹出错误提示：<br>Session timeout or this account is logged in elsewhere, please login again</p><p>然后转到登录页面，再次登录，继续弹出上面的错误提示。循环往复。</p><a id="more"></a><h1 id="权限问题？"><a href="#权限问题？" class="headerlink" title="权限问题？"></a>权限问题？</h1><p>更改用户权限为admin，问题依旧。</p><p>重新给用户授权，问题依旧。</p><h1 id="ks版本问题？"><a href="#ks版本问题？" class="headerlink" title="ks版本问题？"></a>ks版本问题？</h1><p>ks版本从3.2.1升级到了3.3.1，问题依旧。</p><h1 id="kube-events组件问题？"><a href="#kube-events组件问题？" class="headerlink" title="kube-events组件问题？"></a>kube-events组件问题？</h1><p>参考文档<a href="https://kubesphere.com.cn/forum/d/1501" target="_blank" rel="noopener">登录成功后，总是提示会话超时或此账户在其他登录地方登录，请重新登录</a></p><p>经检查，并没有kube-events失败日志，不是它的问题。</p><h1 id="ks配置问题？"><a href="#ks配置问题？" class="headerlink" title="ks配置问题？"></a>ks配置问题？</h1><p>参考文档：</p><ul><li><a href="https://kubesphere.io/docs/v3.3/faq/access-control/session-timeout/" target="_blank" rel="noopener">Session Timeout</a></li><li><a href="https://kubesphere.io/docs/v3.3/access-control-and-account-management/external-authentication/set-up-external-authentication/" target="_blank" rel="noopener">Set Up External Authentication</a></li></ul><p>阅读ks文档，怀疑是ks配置不对引起的。那就按照官方文档重新配置一下试试。</p><h2 id="host集群"><a href="#host集群" class="headerlink" title="host集群"></a>host集群</h2><p>1、编辑ks-installer配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kubesphere-system edit cc ks-installer</span><br></pre></td></tr></table></figure><p>2、修改authentication部分配置</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">authentication:</span></span><br><span class="line">    <span class="attr">jwtSecret:</span> <span class="string">''</span></span><br><span class="line">    <span class="attr">authenticateRateLimiterMaxTries:</span> <span class="number">10</span></span><br><span class="line">    <span class="attr">authenticateRateLimiterDuration:</span> <span class="string">10m0s</span></span><br><span class="line">    <span class="attr">loginHistoryRetentionPeriod:</span> <span class="string">168h</span></span><br><span class="line">    <span class="attr">maximumClockSkew:</span> <span class="string">10s</span></span><br><span class="line">    <span class="attr">multipleLogin:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">oauthOptions:</span></span><br><span class="line">      <span class="attr">accessTokenMaxAge:</span> <span class="string">1h</span></span><br><span class="line">      <span class="attr">accessTokenInactivityTimeout:</span> <span class="string">30m</span></span><br><span class="line">      <span class="attr">identityProviders:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">LDAP</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">LDAPIdentityProvider</span></span><br><span class="line">        <span class="attr">mappingMethod:</span> <span class="string">auto</span></span><br><span class="line">        <span class="attr">provider:</span></span><br><span class="line">          <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.2</span><span class="string">:389</span></span><br><span class="line">          <span class="attr">managerDN:</span> <span class="string">uid=root,cn=users,dc=nas</span></span><br><span class="line">          <span class="attr">managerPassword:</span> <span class="string">********</span></span><br><span class="line">          <span class="attr">userSearchBase:</span> <span class="string">cn=users,dc=nas</span></span><br><span class="line">          <span class="attr">loginAttribute:</span> <span class="string">uid</span></span><br><span class="line">          <span class="attr">mailAttribute:</span> <span class="string">mail</span></span><br></pre></td></tr></table></figure><h2 id="member集群"><a href="#member集群" class="headerlink" title="member集群"></a>member集群</h2><p>member集群只要配置<code>jwtSecret</code>即可，和host集群保持一致。详情参考<a href="https://kubesphere.io/docs/v3.3/multicluster-management/enable-multicluster/direct-connection/" target="_blank" rel="noopener">Direct Connection</a></p><p>修改完成，ks pod重建后，问题依旧。</p><h1 id="删除用户重建？"><a href="#删除用户重建？" class="headerlink" title="删除用户重建？"></a>删除用户重建？</h1><p>删除用户，用户重新登录，重新授权，问题依旧。</p><h1 id="时钟问题？"><a href="#时钟问题？" class="headerlink" title="时钟问题？"></a>时钟问题？</h1><p>参考<a href="https://kubesphere.io/docs/v3.3/faq/access-control/session-timeout/" target="_blank" rel="noopener">Session Timeout</a>文档，还有一种可能是节点时钟偏差。</p><blockquote><p>The node clock skew affects time-sensitive operations such as validating the expiration time of a user token. You can configure the server time synchronization with an NTP server. MaximumClockSkew can also be set, which defaults to 10 seconds.</p></blockquote><p>分别登录host集群和member集群的apiserver pod，执行<code>date</code>命令查看时间。<br>发现不同集群的时区配置不同，啊哈，大概率是这个问题了！！！</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></pre></td></tr></table></figure><p>统一所有集群节点时区为<code>Asia/Shanghai</code>，然后重建ks pod。问题依旧。</p><p>把<code>maximumClockSkew</code>也调大一些，默认10s，调整到60s试试。问题依旧。</p><h1 id="查看日志"><a href="#查看日志" class="headerlink" title="查看日志"></a>查看日志</h1><p>参考文档<a href="https://kubesphere.com.cn/docs/v3.3/faq/multi-cluster-management/host-cluster-access-member-cluster/" target="_blank" rel="noopener">恢复主集群对成员集群的访问权限</a>，查看member集群的api-server日志。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kubesphere-system logs ks-apiserver-7c9c9456bd-qv6bs</span><br></pre></td></tr></table></figure><p>出现报错信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">W1104 11:13:28.432457       1 clusterroles.go:117] invalid aggregation role found: cluster-admin, role-template-manage-configmaps</span><br><span class="line">W1104 11:13:28.432464       1 clusterroles.go:117] invalid aggregation role found: cluster-admin, role-template-view-secrets</span><br><span class="line">W1104 11:13:28.432469       1 clusterroles.go:117] invalid aggregation role found: cluster-admin, role-template-manage-secrets</span><br><span class="line">W1104 11:13:28.432475       1 clusterroles.go:117] invalid aggregation role found: cluster-admin, role-template-view-service-accounts</span><br><span class="line">W1104 11:13:28.432484       1 clusterroles.go:117] invalid aggregation role found: cluster-admin, role-template-manage-service-accounts</span><br><span class="line">E1104 11:13:51.879574       1 upgradeaware.go:401] Error proxying data from backend to client: readfrom tcp 10.244.161.166:9090-&gt;192.168.50.74:34540: write tcp 10.244.161.166:9090-&gt;192.168.50.74:34540: write: connection reset by peer</span><br></pre></td></tr></table></figure><p>顺着这个日志，在kubesphere社区找到了一个相同的问题<a href="https://kubesphere.com.cn/forum/d/7394-kubesphere-member" target="_blank" rel="noopener">kubesphere使用子账户…会跳转到登录界面</a></p><blockquote><p>看起来是多集群同步出问题了，看下 host 集群 kube-federation-system 这个 namespace 下的 pod 是否都正常</p></blockquote><p>根据论坛大佬的提示，检查kube-federation-system 这个 namespace 下的pod信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -n kube-federation-system</span><br><span class="line">kubectl logs --tail=100 kubefed-admission-webhook-657959d4d6-2sx5f -n kube-federation-system</span><br><span class="line">kubectl logs --tail=100 kubefed-controller-manager-54fbd87f7f-6t7jq -n kube-federation-system</span><br><span class="line">kubectl logs --tail=100 kubefed-controller-manager-54fbd87f7f-fh9pk -n kube-federation-system</span><br></pre></td></tr></table></figure><p>看着也没有什么明显的报错信息。</p><p>根据论坛的提示，有两个解决办法：一个是替换kubeconfig，一个是升级kubefed controller。</p><ul><li><a href="https://github.com/kubesphere/kubesphere/issues/4891" target="_blank" rel="noopener">Update the version of kubefed controller </a></li><li><a href="https://github.com/kubernetes-sigs/kubefed/pull/1505" target="_blank" rel="noopener">fix: controller-manager panic when kubeconfig set filed insecure-skip-tls-verify</a></li></ul><p>这里我们选择升级kubefed controller。</p><h1 id="升级kubefed-controller"><a href="#升级kubefed-controller" class="headerlink" title="升级kubefed controller"></a>升级kubefed controller</h1><p>1、查看当前kubefed controller版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployment.apps/kubefed-controller-manager -n kube-federation-system -oyaml| grep image</span><br></pre></td></tr></table></figure><p>查看到当前版本v0.8.1</p><p>2、查看kubefed controller最新版本<br>访问<a href="https://hub.docker.com/r/kubesphere/kubefed/tags" target="_blank" rel="noopener">dockerhub - kubesphere/kubefed</a><br>找到当前最新版本，也是v0.8.1</p><p>莫非不是版本问题？再对比本地镜像和线上镜像的DIGEST，发现它们是不同的。看来是修复bug后，使用了原来的镜像tag。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect kubesphere/kubefed:v0.8.1 | grep -i id</span><br></pre></td></tr></table></figure><p>3、缩容kubefed controller</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale --replicas=0 deployment.apps/kubefed-controller-manager -n kube-federation-system</span><br></pre></td></tr></table></figure><p>4、删除宿主机本地镜像&amp;拉取最新镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker rmi kubesphere/kubefed:v0.8.1 </span><br><span class="line">docker pull kubesphere/kubefed:v0.8.1</span><br></pre></td></tr></table></figure><p>5、重新拉起kubefed controller</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale --replicas=1 deployment.apps/kubefed-controller-manager -n kube-federation-system</span><br></pre></td></tr></table></figure><p>问题依旧。。。</p><h1 id="废弃集群的问题？"><a href="#废弃集群的问题？" class="headerlink" title="废弃集群的问题？"></a>废弃集群的问题？</h1><p>再次查看kubefed-controller-manager的日志，感觉像是废弃集群引起的问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">E1104 08:10:15.107249       1 controller.go:512] failed to delete FederatedGlobalRoleBinding &quot;voidking01-platform-regular&quot;: the following clusters were not ready: vk-dev, edge-cluster</span><br><span class="line">I1104 08:10:15.702028       1 controller.go:471] Ensuring deletion of FederatedGlobalRoleBinding &quot;voidking01-platform-admin&quot;</span><br><span class="line">I1104 08:10:15.702064       1 controller.go:500] Deserializing delete options of FederatedGlobalRoleBinding &quot;voidking01-platform-admin&quot;</span><br><span class="line">I1104 08:10:15.702072       1 controller.go:508] Deleting resources managed by FederatedGlobalRoleBinding &quot;voidking01-platform-admin&quot; from member clusters.</span><br><span class="line">E1104 08:10:15.702117       1 controller.go:512] failed to delete FederatedGlobalRoleBinding &quot;voidking01-platform-admin&quot;: the following clusters were not ready: vk-dev, edge-cluster</span><br></pre></td></tr></table></figure><p>删除废弃的集群后（未就绪的集群），问题解决。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h1&gt;&lt;p&gt;大部分用户能够正常登录和使用ks，但是个别用户（voidking01）登录ks后报错。&lt;br&gt;用户登录ks，正常；登录后查看工作台，正常；查看host集群和只包含host集群的企业空间，正常。&lt;/p&gt;
&lt;p&gt;但是，选择一个非host集群或者选择一个包含非host集群的企业空间后，页面就会弹出错误提示：&lt;br&gt;Session timeout or this account is logged in elsewhere, please login again&lt;/p&gt;
&lt;p&gt;然后转到登录页面，再次登录，继续弹出上面的错误提示。循环往复。&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
      <category term="troubleshooting" scheme="https://www.voidking.com/categories/engineering/troubleshooting/"/>
    
      <category term="storage" scheme="https://www.voidking.com/categories/engineering/storage/"/>
    
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
      <category term="问题排查" scheme="https://www.voidking.com/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
      <category term="kubesphere" scheme="https://www.voidking.com/tags/kubesphere/"/>
    
      <category term="storageclass" scheme="https://www.voidking.com/tags/storageclass/"/>
    
      <category term="存储" scheme="https://www.voidking.com/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>K8S集群中变更数据存储路径</title>
    <link href="https://www.voidking.com/dev-change-data-dir-in-k8s/"/>
    <id>https://www.voidking.com/dev-change-data-dir-in-k8s/</id>
    <published>2022-10-09T20:00:00.000Z</published>
    <updated>2022-11-01T10:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h1><p>docker的默认工作目录是<code>/var/lib/docker</code>，会存放镜像文件、容器日志和写入到容器临时目录的文件等，默认挂载在系统盘。</p><p>kubelet的默认工作目录是<code>/var/lib/kubelet</code>，会存放volume文件（包括emptyDir volume)、plugin文件等，也是默认挂载在系统盘。</p><p>使用kubeadm安装的etcd，默认数据目录是<code>/var/lib/etcd</code>，也是默认挂载在系统盘。</p><p>而系统盘一般都不会太大，因此最好把docker工作目录、kubelet工作目录和etcd数据目录更改到数据盘。</p><a id="more"></a><h1 id="操作思路"><a href="#操作思路" class="headerlink" title="操作思路"></a>操作思路</h1><p>节点分为两类，master节点（多个节点）和worker节点（多个节点）。</p><p>单个master节点操作流程：<br>1、master-x禁止调度、驱逐pod<br>2、master-x操作修改docker工作目录、kubelet工作目录<br>3、master-x开放调度<br>4、master-x操作修改etcd数据目录</p><p>单个worker节点操作流程：<br>1、worker-x禁止调度、驱逐pod<br>2、worker-x操作修改docker工作目录、kubelet工作目录<br>3、worker-x开放调度</p><p>master节点挨个操作，worker节点挨个操作或者分批操作。</p><h1 id="master节点操作"><a href="#master节点操作" class="headerlink" title="master节点操作"></a>master节点操作</h1><p>以master-0为例，方便进行描述。</p><h2 id="禁止调度-amp-驱逐pod"><a href="#禁止调度-amp-驱逐pod" class="headerlink" title="禁止调度&amp;驱逐pod"></a>禁止调度&amp;驱逐pod</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl drain master-0 --ignore-daemonsets</span><br></pre></td></tr></table></figure><p>驱逐master-0节点上的pod，附带效果禁止调度。</p><h2 id="修改docker工作目录"><a href="#修改docker工作目录" class="headerlink" title="修改docker工作目录"></a>修改docker工作目录</h2><p>详情参考 <a href="https://www.voidking.com/dev-docker-data-root/">《Docker修改工作目录》</a></p><h2 id="修改kubelet工作目录"><a href="#修改kubelet工作目录" class="headerlink" title="修改kubelet工作目录"></a>修改kubelet工作目录</h2><p>详情参考 <a href="https://www.voidking.com/dev-kubelet-root-dir/">《kubelet修改工作目录》</a></p><h2 id="开放调度"><a href="#开放调度" class="headerlink" title="开放调度"></a>开放调度</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl uncordon master-0</span><br></pre></td></tr></table></figure><h2 id="单个节点修改etcd数据目录"><a href="#单个节点修改etcd数据目录" class="headerlink" title="单个节点修改etcd数据目录"></a>单个节点修改etcd数据目录</h2><p>详情参考 <a href="https://www.voidking.com/dev-etcd-data-dir/">《etcd修改数据目录》</a></p><h1 id="worker节点操作"><a href="#worker节点操作" class="headerlink" title="worker节点操作"></a>worker节点操作</h1><p>以worker-0为例，方便进行描述。</p><h2 id="禁止调度-amp-驱逐pod-1"><a href="#禁止调度-amp-驱逐pod-1" class="headerlink" title="禁止调度&amp;驱逐pod"></a>禁止调度&amp;驱逐pod</h2><p><code>kubectl drain worker-0 --ignore-daemonsets</code></p><p>驱逐worker-0节点上的pod，附带效果禁止调度。</p><h2 id="修改docker工作目录-1"><a href="#修改docker工作目录-1" class="headerlink" title="修改docker工作目录"></a>修改docker工作目录</h2><p>详情参考 <a href="https://www.voidking.com/dev-docker-data-root/">《Docker修改工作目录》</a></p><h2 id="修改kubelet工作目录-1"><a href="#修改kubelet工作目录-1" class="headerlink" title="修改kubelet工作目录"></a>修改kubelet工作目录</h2><p>详情参考 <a href="https://www.voidking.com/dev-kubelet-root-dir/">《kubelet修改工作目录》</a></p><h2 id="开放调度-1"><a href="#开放调度-1" class="headerlink" title="开放调度"></a>开放调度</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl uncordon worker-0</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;需求描述&quot;&gt;&lt;a href=&quot;#需求描述&quot; class=&quot;headerlink&quot; title=&quot;需求描述&quot;&gt;&lt;/a&gt;需求描述&lt;/h1&gt;&lt;p&gt;docker的默认工作目录是&lt;code&gt;/var/lib/docker&lt;/code&gt;，会存放镜像文件、容器日志和写入到容器临时目录的文件等，默认挂载在系统盘。&lt;/p&gt;
&lt;p&gt;kubelet的默认工作目录是&lt;code&gt;/var/lib/kubelet&lt;/code&gt;，会存放volume文件（包括emptyDir volume)、plugin文件等，也是默认挂载在系统盘。&lt;/p&gt;
&lt;p&gt;使用kubeadm安装的etcd，默认数据目录是&lt;code&gt;/var/lib/etcd&lt;/code&gt;，也是默认挂载在系统盘。&lt;/p&gt;
&lt;p&gt;而系统盘一般都不会太大，因此最好把docker工作目录、kubelet工作目录和etcd数据目录更改到数据盘。&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="docker" scheme="https://www.voidking.com/categories/engineering/docker/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
    
      <category term="docker" scheme="https://www.voidking.com/tags/docker/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>etcd修改数据目录</title>
    <link href="https://www.voidking.com/dev-etcd-data-dir/"/>
    <id>https://www.voidking.com/dev-etcd-data-dir/</id>
    <published>2022-10-09T15:00:00.000Z</published>
    <updated>2022-11-01T10:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h1><p>使用kubeadm安装的etcd，默认数据目录是<code>/var/lib/etcd</code>，默认挂载在系统盘。</p><p>而系统盘一般都不会太大，因此最好把etcd的数据目录更改到数据盘。</p><p>本文中，我们会把etcd的数据目录从<code>/var/lib/etcd</code>改到<code>/data/etcd</code>，其中<code>/data</code>目录挂载了数据盘。</p><a id="more"></a><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>想到两个方法：</p><ul><li>修改配置法：拷贝数据到新目录，修改工作目录配置到新目录。</li><li>软链法：拷贝数据到新目录，使用新目录的软链替换原来的工作目录。不推荐，不知道有没有什么隐藏坑。</li></ul><p>etcd是集群，为了保证etcd服务可用，需要挨个节点停服操作，完成一个节点再进行下一个。</p><h1 id="修改配置法"><a href="#修改配置法" class="headerlink" title="修改配置法"></a>修改配置法</h1><p>1、停止etcd</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo docker ps | grep etcd</span><br><span class="line">sudo mv /etc/kubernetes/manifests/etcd.yaml ~/</span><br><span class="line">sudo docker ps | grep etcd</span><br><span class="line">sudo etcdctl  --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key --endpoints=<span class="string">"https://192.168.56.101:2379,https://192.168.56.102:2379,https://192.168.56.103:2379"</span> endpoint health</span><br></pre></td></tr></table></figure><p>2、修改etcd数据目录<br>编辑<code>~/etcd.yaml</code>，etcd-data的path从<code>/var/lib/etcd</code>改为<code>/data/etcd</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/etc/kubernetes/pki/etcd</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">DirectoryOrCreate</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">etcd-certs</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/data/etcd</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">DirectoryOrCreate</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">etcd-data</span></span><br></pre></td></tr></table></figure><p>3、拷贝数据</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /data/etcd</span><br><span class="line">sudo cp -rf /var/lib/etcd/. /data/etcd</span><br><span class="line">sudo mv /var/lib/etcd /var/lib/etcd.old</span><br></pre></td></tr></table></figure><p>4、启动etcd&amp;查看etcd状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo mv ~/etcd.yaml /etc/kubernetes/manifests/</span><br><span class="line">sudo docker ps | grep etcd</span><br><span class="line">sudo etcdctl  --cacert=/etc/kubernetes/pki/etcd/ca.crt \</span><br><span class="line">    --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key \</span><br><span class="line">    --endpoints=<span class="string">"https://192.168.56.101:2379,https://192.168.56.102:2379,https://192.168.56.103:2379"</span> \</span><br><span class="line">    endpoint health</span><br></pre></td></tr></table></figure><h1 id="软链法"><a href="#软链法" class="headerlink" title="软链法"></a>软链法</h1><p>可以参考 <a href="https://www.voidking.com/dev-docker-data-root/">《Docker修改工作目录》</a></p><h1 id="kubeadm指定etcd数据目录"><a href="#kubeadm指定etcd数据目录" class="headerlink" title="kubeadm指定etcd数据目录"></a>kubeadm指定etcd数据目录</h1><h2 id="修改etcd数据目录"><a href="#修改etcd数据目录" class="headerlink" title="修改etcd数据目录"></a>修改etcd数据目录</h2><p>使用kubeadm安装的etcd，etcd的数据目录是在kubeadm.conf文件中指定的。</p><p>根据kubeadm.conf中的配置，新加入的master节点上会生成<code>/etc/kubernetes/manifests/etcd.yaml</code>文件，然后etcd就会作为static pod运行。</p><p>对于已经安装好的k8s集群，可以通过kubectl修改集群中kubeadm的配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit cm kubeadm-config -n kube-system</span><br></pre></td></tr></table></figure><p>其中，etcd数据目录的修改方法为：etcd.local.dataDir 变量修改为 <code>/data/etcd</code></p><p>修改之后，并不会马上生效，有新的master节点加入，才会使用这份新的etcd数据目录配置。</p><h2 id="初始化前指定etcd数据目录"><a href="#初始化前指定etcd数据目录" class="headerlink" title="初始化前指定etcd数据目录"></a>初始化前指定etcd数据目录</h2><p>在执行<code>kubeadm init</code>之前，在kubeadm.conf文件中指定数据目录。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">etcd:</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="attr">dataDir:</span> <span class="string">/data/etcd</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;需求描述&quot;&gt;&lt;a href=&quot;#需求描述&quot; class=&quot;headerlink&quot; title=&quot;需求描述&quot;&gt;&lt;/a&gt;需求描述&lt;/h1&gt;&lt;p&gt;使用kubeadm安装的etcd，默认数据目录是&lt;code&gt;/var/lib/etcd&lt;/code&gt;，默认挂载在系统盘。&lt;/p&gt;
&lt;p&gt;而系统盘一般都不会太大，因此最好把etcd的数据目录更改到数据盘。&lt;/p&gt;
&lt;p&gt;本文中，我们会把etcd的数据目录从&lt;code&gt;/var/lib/etcd&lt;/code&gt;改到&lt;code&gt;/data/etcd&lt;/code&gt;，其中&lt;code&gt;/data&lt;/code&gt;目录挂载了数据盘。&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/tags/cloudnative/"/>
    
      <category term="etcd" scheme="https://www.voidking.com/tags/etcd/"/>
    
  </entry>
  
  <entry>
    <title>kubelet修改工作目录</title>
    <link href="https://www.voidking.com/dev-kubelet-root-dir/"/>
    <id>https://www.voidking.com/dev-kubelet-root-dir/</id>
    <published>2022-10-09T14:00:00.000Z</published>
    <updated>2022-11-01T10:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h1><p>kubelet的默认工作目录（存储目录）是<code>/var/lib/kubelet</code>，会存放volume文件（包括emptyDir volume)、plugin文件等，默认挂载在系统盘。</p><p>而系统盘一般都不会太大，因此最好把kubelet工作目录更改到数据盘。</p><p>本文中，我们会把docker的工作目录从<code>/var/lib/kubelet</code>改到<code>/data/kubelet</code>，其中<code>/data</code>目录挂载了数据盘。</p><a id="more"></a><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>想到两个方法：</p><ul><li>修改配置法：拷贝数据到新目录，修改工作目录配置到新目录。</li><li>软链法：拷贝数据到新目录，使用新目录的软链替换原来的工作目录。不推荐，不知道有没有什么隐藏坑。</li></ul><p>修改kubelet配置之前，为了保证不影响节点上的服务，最好先对节点操作禁止调度和驱逐。</p><h1 id="修改配置法"><a href="#修改配置法" class="headerlink" title="修改配置法"></a>修改配置法</h1><p>1、停止kubelet</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop kubelet</span><br></pre></td></tr></table></figure><p>2、拷贝kubelet数据文件到新路径</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /data/kubelet</span><br><span class="line">sudo cp -rf /var/lib/kubelet/. /data/kubelet</span><br><span class="line">sudo mv /var/lib/kubelet /var/lib/kubelet.old</span><br></pre></td></tr></table></figure><p>3、保留config.yaml和kubeadm-flags.env在老路径</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /var/lib/kubelet</span><br><span class="line">sudo cp /var/lib/kubelet.old/config.yaml /var/lib/kubelet/</span><br><span class="line">sudo cp /var/lib/kubelet.old/kubeadm-flags.env /var/lib/kubelet/</span><br></pre></td></tr></table></figure><p>4、添加或修改 /etc/sysconfig/kubelet 配置文件，添加<code>root-dir</code>参数</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">KUBELET_EXTRA_ARGS</span>=<span class="string">"--root-dir=/data/kubelet"</span></span><br></pre></td></tr></table></figure><p>PS：如果是ubuntu系统，则要修改 /etc/default/kubelet 配置文件</p><p>5、重启kubelet</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload &amp;&amp; sudo systemctl restart kubelet</span><br><span class="line">sudo systemctl status kubelet</span><br></pre></td></tr></table></figure><p>此时kubelet启动失败，是正常的，不用特殊处理。</p><h1 id="软链法"><a href="#软链法" class="headerlink" title="软链法"></a>软链法</h1><p>1、停止kubelet</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop kubelet</span><br></pre></td></tr></table></figure><p>2、拷贝kubelet数据文件到新路径</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /data/kubelet</span><br><span class="line">sudo cp -rf /var/lib/kubelet/. /data/kubelet</span><br><span class="line">sudo mv /var/lib/kubelet /var/lib/kubelet.old</span><br></pre></td></tr></table></figure><p>3、创建软链</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /data/kubelet /var/<span class="class"><span class="keyword">lib</span>/<span class="title">kubelet</span></span></span><br></pre></td></tr></table></figure><p>4、启动kubelet</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload &amp;&amp; sudo systemctl restart kubelet</span><br><span class="line">sudo systemctl status kubelet</span><br></pre></td></tr></table></figure><p>此时kubelet启动失败，是正常的，不用特殊处理。</p><h1 id="kubeadm指定kubelet工作目录"><a href="#kubeadm指定kubelet工作目录" class="headerlink" title="kubeadm指定kubelet工作目录"></a>kubeadm指定kubelet工作目录</h1><p>与其临渴掘井，不如未雨绸缪。能否在使用kubeadm部署k8s集群的时候，直接指定好kubelet的工作目录？必须是可以的。</p><p>在执行<code>kubeadm init</code>之前，修改kubeadm.conf文件，添加kubeletExtraArgs字段。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">InitConfiguration</span></span><br><span class="line"><span class="attr">nodeRegistration:</span>  </span><br><span class="line">  <span class="attr">kubeletExtraArgs:</span>    </span><br><span class="line">    <span class="attr">root-dir:</span> <span class="string">"/data/kubelet"</span></span><br></pre></td></tr></table></figure><p>参考文档：</p><ul><li><a href="https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/#kubeadm-k8s-io-v1beta3-NodeRegistrationOptions" target="_blank" rel="noopener">kubeadm Configuration - NodeRegistrationOptions</a></li></ul><h1 id="kubeadm部署kubelet原理"><a href="#kubeadm部署kubelet原理" class="headerlink" title="kubeadm部署kubelet原理"></a>kubeadm部署kubelet原理</h1><p>本节属于扩展阅读。<br>在修改kubelet工作目录时，走了很多弯路。其实如果熟悉kubeadm部署kubelet的原理，会发现修改kubelet工作目录是很简单的。<br>好好读文档！好好读文档！好好读文档！</p><p>参考文档：</p><ul><li><a href="https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/kubelet-integration/" target="_blank" rel="noopener">使用 kubeadm 配置集群中的每个 kubelet</a></li><li><a href="https://blog.51cto.com/u_15127640/4093908" target="_blank" rel="noopener">kubelet源码分析——kubelet简介与启动</a></li></ul><h2 id="kubeadm-init-时的工作流程"><a href="#kubeadm-init-时的工作流程" class="headerlink" title="kubeadm init 时的工作流程"></a>kubeadm init 时的工作流程</h2><p>当调用 kubeadm init 时，kubelet 的配置会被写入磁盘 /var/lib/kubelet/config.yaml， 并上传到集群 kube-system 命名空间的 kubelet-config ConfigMap。 kubelet 配置信息也被写入 /etc/kubernetes/kubelet.conf，其中包含集群内所有 kubelet 的基线配置。 此配置文件指向允许 kubelet 与 API 服务器通信的客户端证书。 这解决了将集群级配置传播到每个 kubelet 的需求。</p><p>针对为特定实例提供配置细节， kubeadm 的解决方法是将环境文件写入 /var/lib/kubelet/kubeadm-flags.env，其中包含了一个标志列表<code>KUBELET_KUBEADM_ARGS</code></p><p>将这两个文件编组到磁盘后，如果使用 systemd，则 kubeadm 尝试运行以下两个命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart kubelet</span><br></pre></td></tr></table></figure><h2 id="kubeadm-join-时的工作流程"><a href="#kubeadm-join-时的工作流程" class="headerlink" title="kubeadm join 时的工作流程"></a>kubeadm join 时的工作流程</h2><p>当运行 kubeadm join 时，kubeadm 使用 Bootstrap Token 证书执行 TLS 引导，该引导会获取一份证书， 该证书需要下载 kubelet-config ConfigMap 并把它写入 /var/lib/kubelet/config.yaml 中。 动态环境文件的生成方式恰好与 kubeadm init 完全相同。</p><p>接下来，kubeadm 运行以下两个命令将新配置加载到 kubelet 中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart kubelet</span><br></pre></td></tr></table></figure><p>在 kubelet 加载新配置后，kubeadm 将写入 /etc/kubernetes/bootstrap-kubelet.conf KubeConfig 文件中， 该文件包含 CA 证书和引导程序令牌。 kubelet 使用这些证书执行 TLS 引导程序并获取唯一的凭据，该凭据被存储在 /etc/kubernetes/kubelet.conf 中。</p><p>当 /etc/kubernetes/kubelet.conf 文件被写入后，kubelet 就完成了 TLS 引导过程。 Kubeadm 在完成 TLS 引导过程后将删除 /etc/kubernetes/bootstrap-kubelet.conf 文件。</p><h2 id="kubelet-的-systemd-drop-in-文件"><a href="#kubelet-的-systemd-drop-in-文件" class="headerlink" title="kubelet 的 systemd drop-in 文件"></a>kubelet 的 systemd drop-in 文件</h2><p>通过 kubeadm DEB 包 或者 RPM 包 安装的配置文件被写入 /etc/systemd/system/kubelet.service.d/10-kubeadm.conf 并由 systemd 使用。它对原来的 RPM 版本 kubelet.service 或者 DEB 版本 kubelet.service 做了增强。</p><p>10-kubeadm.conf 示例内容如下：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[Service]</span></span><br><span class="line"><span class="attr">Environment</span>=<span class="string">"KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"</span></span><br><span class="line"><span class="attr">Environment</span>=<span class="string">"KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"</span></span><br><span class="line"><span class="comment"># 这是 "kubeadm init" 和 "kubeadm join" 运行时生成的文件，</span></span><br><span class="line"><span class="comment"># 动态地填充 KUBELET_KUBEADM_ARGS 变量</span></span><br><span class="line"><span class="attr">EnvironmentFile</span>=-/var/lib/kubelet/kubeadm-flags.env</span><br><span class="line"><span class="comment"># 这是一个文件，用户在不得已下可以将其用作替代 kubelet args。</span></span><br><span class="line"><span class="comment"># 用户最好使用 .NodeRegistration.KubeletExtraArgs 对象在配置文件中替代。</span></span><br><span class="line"><span class="comment"># KUBELET_EXTRA_ARGS 应该从此文件中获取。</span></span><br><span class="line"><span class="attr">EnvironmentFile</span>=-/etc/default/kubelet</span><br><span class="line"><span class="attr">ExecStart</span>=</span><br><span class="line"><span class="attr">ExecStart</span>=/usr/bin/kubelet <span class="variable">$KUBELET_KUBECONFIG_ARGS</span> <span class="variable">$KUBELET_CONFIG_ARGS</span> <span class="variable">$KUBELET_KUBEADM_ARGS</span> <span class="variable">$KUBELET_EXTRA_ARGS</span></span><br></pre></td></tr></table></figure><p>参数说明：</p><ul><li>用于 TLS 引导程序的 KubeConfig 文件为 /etc/kubernetes/bootstrap-kubelet.conf， 但仅当 /etc/kubernetes/kubelet.conf 不存在时才能使用。</li><li>具有唯一 kubelet 标识的 KubeConfig 文件为 /etc/kubernetes/kubelet.conf。</li><li>包含 kubelet 的组件配置的文件为 /var/lib/kubelet/config.yaml。</li><li><code>KUBELET_KUBEADM_ARGS</code> 来源于 /var/lib/kubelet/kubeadm-flags.env ，</li><li><code>KUBELET_EXTRA_ARGS</code> 来源于 /etc/default/kubelet（对于 DEB），或者 /etc/sysconfig/kubelet（对于 RPM）。<code>KUBELET_EXTRA_ARGS</code> 在标志链中排在最后，并且在设置冲突时具有最高优先级。</li></ul><h2 id="指定kubelet工作目录"><a href="#指定kubelet工作目录" class="headerlink" title="指定kubelet工作目录"></a>指定kubelet工作目录</h2><p>通过上面的原理我们了解到，对于kubelet，可以在<code>KUBELET_KUBEADM_ARGS</code>或者<code>KUBELET_EXTRA_ARGS</code>标志列表中添加<code>root-dir</code>标志，指定kubelet的工作目录。</p><p>方法一：/var/lib/kubelet/kubeadm-flags.env 中添加标志</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">KUBELET_KUBEADM_ARGS</span>=<span class="string">"--root-dir=/data/kubelet"</span></span><br></pre></td></tr></table></figure><p>方法二：/etc/sysconfig/kubelet 中添加标志</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">KUBELET_EXTRA_ARGS</span>=<span class="string">"--root-dir=/data/kubelet"</span></span><br></pre></td></tr></table></figure><p>添加标志后，重启kubelet即可。</p><p>也可以在部署k8s集群时一步到位指定kubelet工作目录，具体操作方法参考 kubeadm指定kubelet工作目录 小节。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;需求描述&quot;&gt;&lt;a href=&quot;#需求描述&quot; class=&quot;headerlink&quot; title=&quot;需求描述&quot;&gt;&lt;/a&gt;需求描述&lt;/h1&gt;&lt;p&gt;kubelet的默认工作目录（存储目录）是&lt;code&gt;/var/lib/kubelet&lt;/code&gt;，会存放volume文件（包括emptyDir volume)、plugin文件等，默认挂载在系统盘。&lt;/p&gt;
&lt;p&gt;而系统盘一般都不会太大，因此最好把kubelet工作目录更改到数据盘。&lt;/p&gt;
&lt;p&gt;本文中，我们会把docker的工作目录从&lt;code&gt;/var/lib/kubelet&lt;/code&gt;改到&lt;code&gt;/data/kubelet&lt;/code&gt;，其中&lt;code&gt;/data&lt;/code&gt;目录挂载了数据盘。&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/tags/cloudnative/"/>
    
  </entry>
  
  <entry>
    <title>Docker修改工作目录</title>
    <link href="https://www.voidking.com/dev-docker-data-root/"/>
    <id>https://www.voidking.com/dev-docker-data-root/</id>
    <published>2022-10-09T13:00:00.000Z</published>
    <updated>2022-11-01T10:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="需求描述"><a href="#需求描述" class="headerlink" title="需求描述"></a>需求描述</h1><p>docker的默认工作目录（存储目录）是<code>/var/lib/docker</code>，会存放镜像文件、容器日志和写入到容器临时目录的文件等，默认挂载在系统盘。</p><p>而系统盘一般都不会太大，因此最好把docker工作目录更改到数据盘。</p><p>本文中，我们会把docker的工作目录从<code>/var/lib/docker</code>改到<code>/data/docker</code>，其中<code>/data</code>目录挂载了数据盘。</p><a id="more"></a><h1 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h1><p>想到两个方法：</p><ul><li>修改配置法：拷贝数据到新目录，修改工作目录配置到新目录。</li><li>软链法：拷贝数据到新目录，使用新目录的软链替换原来的工作目录。不推荐，不知道有没有什么隐藏坑。</li></ul><h1 id="修改配置法"><a href="#修改配置法" class="headerlink" title="修改配置法"></a>修改配置法</h1><p>参考文档<a href="https://tienbm90.medium.com/how-to-change-docker-root-data-directory-89a39be1a70b" target="_blank" rel="noopener">How to change docker root data directory</a></p><p>1、关闭docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop docker</span><br></pre></td></tr></table></figure><p>Warning: Stopping docker.service, but it can still be activated by: docker.socket<br>该警告意味着：如果你试图连接到docker socket，而docker服务没有运行，系统将自动启动docker。<br>这是因为除了docker.service单元文件，还有一个docker.socket单元文件，用于套接字激活。</p><p>这里可以使用另外一个命令关闭docker，禁止套接字激活。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop docker.socket</span><br></pre></td></tr></table></figure><p>2、更改docker数据存储路径<br><code>sudo vim /etc/docker/daemon.json</code><br>添加：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"data-root"</span>: <span class="string">"/data/docker"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3、拷贝docker数据文件到新路径</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /data/docker</span><br><span class="line">sudo cp -rf /var/lib/docker/. /data/docker</span><br><span class="line">sudo mv /var/lib/docker /var/lib/docker.old</span><br></pre></td></tr></table></figure><p>4、重启docker&amp;确认工作目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start docker</span><br><span class="line">sudo docker info | grep Dir</span><br></pre></td></tr></table></figure><h1 id="软链法"><a href="#软链法" class="headerlink" title="软链法"></a>软链法</h1><p>1、关闭docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop docker</span><br><span class="line">sudo systemctl stop docker.socket</span><br></pre></td></tr></table></figure><p>2、拷贝docker数据文件到新路径</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /data/docker</span><br><span class="line">sudo cp -rf /var/lib/docker/. /data/docker</span><br><span class="line">sudo mv /var/lib/docker /var/lib/docker.old</span><br></pre></td></tr></table></figure><p>3、创建软链</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -s /data/docker /var/lib/docker</span><br></pre></td></tr></table></figure><p>4、重启docker&amp;确认工作目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start docker</span><br><span class="line">sudo docker info | grep Dir</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;需求描述&quot;&gt;&lt;a href=&quot;#需求描述&quot; class=&quot;headerlink&quot; title=&quot;需求描述&quot;&gt;&lt;/a&gt;需求描述&lt;/h1&gt;&lt;p&gt;docker的默认工作目录（存储目录）是&lt;code&gt;/var/lib/docker&lt;/code&gt;，会存放镜像文件、容器日志和写入到容器临时目录的文件等，默认挂载在系统盘。&lt;/p&gt;
&lt;p&gt;而系统盘一般都不会太大，因此最好把docker工作目录更改到数据盘。&lt;/p&gt;
&lt;p&gt;本文中，我们会把docker的工作目录从&lt;code&gt;/var/lib/docker&lt;/code&gt;改到&lt;code&gt;/data/docker&lt;/code&gt;，其中&lt;code&gt;/data&lt;/code&gt;目录挂载了数据盘。&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="docker" scheme="https://www.voidking.com/categories/engineering/docker/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
    
      <category term="docker" scheme="https://www.voidking.com/tags/docker/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/tags/cloudnative/"/>
    
  </entry>
  
  <entry>
    <title>kubeadm安装的K8S集群证书过期问题</title>
    <link href="https://www.voidking.com/dev-kubeadm-k8s-cert-expired/"/>
    <id>https://www.voidking.com/dev-kubeadm-k8s-cert-expired/</id>
    <published>2022-09-26T20:00:00.000Z</published>
    <updated>2022-11-14T15:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>使用kubectl访问k8s集群，报错证书过期：<br>Unable to connect to the server: x509: certificate has expired or is not yet valid: current time 2022-09-26T01:33:25-04:00 is after 2022-09-26T03:45:02Z</p><a id="more"></a><h1 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h1><p>1、确认证书过期<br>2、更新证书<br>3、更新相关配置</p><p>参考文档：</p><ul><li><a href="https://juejin.cn/post/7068909995701567501" target="_blank" rel="noopener">解决kubernetes证书过期问题</a></li><li><a href="https://cloud.tencent.com/developer/article/1962891" target="_blank" rel="noopener">Kubeadm集群证书过期后的处理</a></li></ul><h1 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h1><h2 id="确认证书过期"><a href="#确认证书过期" class="headerlink" title="确认证书过期"></a>确认证书过期</h2><p>1、登录证书过期集群的任意master节点</p><p>2、查看证书过期时间</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm certs check-expiration</span><br></pre></td></tr></table></figure><p>看到 RESIDUAL TIME 为 <code>&lt;invalid&gt;</code>，表明证书已经过期。</p><h2 id="更新证书"><a href="#更新证书" class="headerlink" title="更新证书"></a>更新证书</h2><p>注意：更新证书时，所有master节点都需要操作</p><p>1、备份k8s配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp -r /etc/kubernetes&#123;,.old&#125;</span><br><span class="line"><span class="comment">#cp -r /var/lib/etcd&#123;,.old&#125;</span></span><br></pre></td></tr></table></figure><p>2、更新证书</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm certs renew all</span><br></pre></td></tr></table></figure><p>更新成功后，会提示重启一些pod：</p><blockquote><p>Done renewing certificates. You must restart the kube-apiserver, kube-controller-manager, kube-scheduler and etcd, so that they can use the new certificates.</p></blockquote><p>3、重启kubelet和容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart kubelet</span><br><span class="line">docker ps | grep -v pause | grep -E <span class="string">"etcd|scheduler|controller|apiserver"</span> | awk <span class="string">'&#123;print $1&#125;'</span> | awk <span class="string">'&#123;print "docker","restart",$1&#125;'</span> | bash</span><br></pre></td></tr></table></figure><p>4、验证</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/kubernetes/pki</span><br><span class="line">ll</span><br><span class="line">kubeadm certs check-expiration</span><br></pre></td></tr></table></figure><h2 id="更新kubectl配置"><a href="#更新kubectl配置" class="headerlink" title="更新kubectl配置"></a>更新kubectl配置</h2><p>1、更新kubeconfig配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /etc/kubernetes/admin.conf .kube/config</span><br></pre></td></tr></table></figure><p>2、测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure><h2 id="更新kubesphere配置"><a href="#更新kubesphere配置" class="headerlink" title="更新kubesphere配置"></a>更新kubesphere配置</h2><p>以上，k8s集群的证书过期问题已经解决。但是，使用通过kubesphere的管理页面访问k8s集群时，会报错：</p><blockquote><p>会话超时或此帐户在其它地方登录，请重新登录</p></blockquote><p>ks官方给的解决方案是在页面上更新 kubeconfig，但是这个方案只适用于v3.3以上的版本（页面上会提示kubeconfig已过期），详情参考<a href="https://kubesphere.io/zh/docs/v3.3/multicluster-management/enable-multicluster/update-kubeconfig/" target="_blank" rel="noopener">更新 Kubeconfig</a></p><p>如果是v3.2或者更低版本，可以通过kubectl修改CRD clusters.cluster.kubesphere.io，详情参考<a href="https://kubesphere.com.cn/forum/d/5952-memberkubespherekubeconfig" target="_blank" rel="noopener">member节点证书到期，续约证书后，kubesphere如何更新kubeconfig？</a></p><p>为方便描述，假设证书过期的k8s集群名称为 <code>dev</code>。证书更新后，在kubesphere主集群执行如下操作：</p><p>1、查看所有集群配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get clusters.cluster.kubesphere.io -n kubesphere-system</span><br></pre></td></tr></table></figure><p>2、备份dev集群配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get clusters.cluster.kubesphere.io/dev -n kubesphere-system -o yaml &gt; dev.yaml</span><br></pre></td></tr></table></figure><p>3、base64加密新的dev集群的kubeconfig</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat .kube/config | base64 | tr -d <span class="string">'\n'</span></span><br></pre></td></tr></table></figure><p>4、更新dev集群配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit clusters.cluster.kubesphere.io/dev -n kubesphere-system</span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">connection:</span></span><br><span class="line">    <span class="attr">kubeconfig:</span> <span class="string">xxx</span></span><br></pre></td></tr></table></figure><p>把 kubeconfig 的value替换为base64加密后的kubeconfig内容。</p><p>5、验证<br>通过ks的管理页面再次访问k8s集群，已经可以正常访问。</p><h2 id="更新argocd配置"><a href="#更新argocd配置" class="headerlink" title="更新argocd配置"></a>更新argocd配置</h2><p>查看argocd和k8s dev集群的连接，发现CONNECTION STATUS已经失联。</p><p>参考<a href="https://argo-cd.readthedocs.io/en/stable/user-guide/commands/argocd_cluster_add/" target="_blank" rel="noopener">Argocd cluster add</a>，通过<code>--upsert</code>参数更新集群配置。<br>注意：更新集群配置时，集群的名称一定要和现有名称保持一致。</p><p>假设：</p><ul><li>argocd所在k8s集群为manager</li><li>manager的master节点上包含dev集群的新的kubeconfig，路径为<code>~/.kube/newconfig</code></li><li><code>dev</code>集群在argocd中的名称为<code>dev(开发)</code></li><li>argo-cd-argocd-server pod ip为 <code>10.x.x.x</code></li></ul><p>那么，在manager集群的master节点上执行如下操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -n argocd -owide</span><br><span class="line">argocd login 10.x.x.x:8080 --grpc-web</span><br><span class="line">argocd cluster list</span><br><span class="line">argocd cluster add kubernetes-admin@kubernetes --kubeconfig ~/.kube/newconfig --name <span class="string">"dev(开发)"</span> --upsert</span><br></pre></td></tr></table></figure><p>如果master节点没有argocd client，可以登录到argo-cd-argocd-server pod中进行操作。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h1&gt;&lt;p&gt;使用kubectl访问k8s集群，报错证书过期：&lt;br&gt;Unable to connect to the server: x509: certificate has expired or is not yet valid: current time 2022-09-26T01:33:25-04:00 is after 2022-09-26T03:45:02Z&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
      <category term="troubleshooting" scheme="https://www.voidking.com/categories/engineering/troubleshooting/"/>
    
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
      <category term="问题排查" scheme="https://www.voidking.com/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
      <category term="cicd" scheme="https://www.voidking.com/tags/cicd/"/>
    
      <category term="kubesphere" scheme="https://www.voidking.com/tags/kubesphere/"/>
    
      <category term="kubeadm" scheme="https://www.voidking.com/tags/kubeadm/"/>
    
  </entry>
  
  <entry>
    <title>Linux配置网络代理</title>
    <link href="https://www.voidking.com/dev-linux-network-proxy/"/>
    <id>https://www.voidking.com/dev-linux-network-proxy/</id>
    <published>2022-09-13T13:00:00.000Z</published>
    <updated>2022-12-29T22:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="网络代理"><a href="#网络代理" class="headerlink" title="网络代理"></a>网络代理</h1><p><a href="https://www.voidking.com/dev-linux-snat/">《Linux配置SNAT上网》</a>一文中，我们了解到，通过SNAT的方式能够让局域网中所有主机都能访问外网。<br>而网络代理，也能让局域网中所有主机都能访问外网。并且，如果网络代理支持科学上网，那么所有使用这个代理的主机也可以科学上网。</p><p>本文我们就来学习一下Linux中常见的网络代理配置方法，参考文档：</p><ul><li><a href="https://www.cnblogs.com/zaq12wsx/p/14371537.html" target="_blank" rel="noopener">linux设置代理上网</a></li><li><a href="https://www.cnblogs.com/linjiangCN/p/16135203.html" target="_blank" rel="noopener">docker pull 配置代理</a></li></ul><p>已知网络代理的IP和PORT为：<code>192.168.56.1:7890</code></p><a id="more"></a><h1 id="bash环境网络代理"><a href="#bash环境网络代理" class="headerlink" title="bash环境网络代理"></a>bash环境网络代理</h1><p>bash环境网络代理设置，是适用于全局的，因为绝大部分软件都会从环境变量中读取数据，比如curl命令、yum命令、wget命令等等。</p><h2 id="临时配置"><a href="#临时配置" class="headerlink" title="临时配置"></a>临时配置</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> https_proxy=http://192.168.56.1:7890 http_proxy=http://192.168.56.1:7890 all_proxy=socks5://192.168.56.1:7890 ftp_proxy=http://192.168.56.1:7890 no_proxy=localhost,127.0.0.1,192.168.56.0/24</span><br></pre></td></tr></table></figure><p>这里的<code>no_proxy</code>需要注意，不同的软件对于它有不同的处理。最典型的例子：</p><ul><li><code>example.com</code>：大部分软件都支持精确匹配和下一级域名匹配，例如还可以匹配<code>subdomain.example.com</code></li><li><code>.example.com</code>：curl剥离前缀<code>.</code>，对于<code>example.com</code>不会使用代理；wget不会剥离前缀<code>.</code>，对于<code>example.com</code>会使用代理</li><li><code>192.168.56.0/24</code>：只有Go和Ruby支持这种CIDR块</li></ul><p>详情参考<a href="https://about.gitlab.com/blog/2021/01/27/we-need-to-talk-no-proxy/" target="_blank" rel="noopener">We need to talk: Can we standardize NO_PROXY?</a></p><h2 id="永久生效"><a href="#永久生效" class="headerlink" title="永久生效"></a>永久生效</h2><p>1、写入配置内容到<code>.bashrc</code>文件中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> https_proxy=http://192.168.56.1:7890 </span><br><span class="line"><span class="built_in">export</span> http_proxy=http://192.168.56.1:7890 </span><br><span class="line"><span class="built_in">export</span> all_proxy=socks5://192.168.56.1:7890</span><br><span class="line"><span class="built_in">export</span> ftp_proxy=http://192.168.56.1:7890 </span><br><span class="line"><span class="built_in">export</span> no_proxy=localhost,127.0.0.1,192.168.56.0/24</span><br></pre></td></tr></table></figure><p>写到<code>.bashrc</code>，无论是登录session还是非登录session，都可以使用这些变量，详情参考<a href="https://www.voidking.com/dev-bashprofile-bashrc/">bash_profile和bashrc的区别</a>。</p><p>2、使生效</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> .bashrc</span><br></pre></td></tr></table></figure><h1 id="wget代理"><a href="#wget代理" class="headerlink" title="wget代理"></a>wget代理</h1><p>编辑文件<code>/etc/wgetrc</code>，添加内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http_proxy = http://192.168.56.1:7890  </span><br><span class="line">https_proxy = http://192.168.56.1:7890</span><br><span class="line">ftp_proxy = http://192.168.56.1:7890</span><br></pre></td></tr></table></figure><h1 id="yum代理"><a href="#yum代理" class="headerlink" title="yum代理"></a>yum代理</h1><p>编辑文件<code>/etc/yum.conf</code>，添加内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proxy&#x3D;http:&#x2F;&#x2F;192.168.56.1:7890</span><br></pre></td></tr></table></figure><h1 id="浏览器上网代理"><a href="#浏览器上网代理" class="headerlink" title="浏览器上网代理"></a>浏览器上网代理</h1><p>以Firefox浏览器为例：<br>Edit -&gt; Preferences -&gt; Advanced -&gt; Network<br>在Connection下点击Settings，manual proxy configuration里设置IP和PORT。</p><h1 id="docker-pull代理"><a href="#docker-pull代理" class="headerlink" title="docker pull代理"></a>docker pull代理</h1><p>1、创建docker配置目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /etc/systemd/system/docker.service.d</span><br></pre></td></tr></table></figure><p>2、添加代理配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/systemd/system/docker.service.d/http-proxy.conf</span><br></pre></td></tr></table></figure><p>写入内容为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Service]</span><br><span class="line">Environment&#x3D;&quot;HTTP_PROXY&#x3D;http:&#x2F;&#x2F;192.168.56.1:7890&quot;</span><br><span class="line">Environment&#x3D;&quot;HTTPS_PROXY&#x3D;http:&#x2F;&#x2F;192.168.56.1:7890&quot;</span><br><span class="line">Environment&#x3D;&quot;NO_PROXY&#x3D;localhost,127.0.0.1,192.168.56.200,harbor.voidking.com&quot;</span><br></pre></td></tr></table></figure><p>需要注意的是，20.10.18和更早的docker版本，NO_PROXY不支持CIDR，详情参考<a href="https://github.com/docker/docs/issues/8191" target="_blank" rel="noopener">NO_PROXY does not support CIDR notation</a></p><p>3、重启docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><p>4、查看docker代理</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl show docker --property Environment</span><br><span class="line">docker info | grep Proxy</span><br></pre></td></tr></table></figure><h1 id="docker-build代理"><a href="#docker-build代理" class="headerlink" title="docker build代理"></a>docker build代理</h1><p>docker build时，容器内需要使用pip下载依赖。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker build \</span><br><span class="line">--network=host \</span><br><span class="line">--build-arg HTTP_PROXY=http://192.168.56.1:7890 \</span><br><span class="line">--build-arg HTTPS_PROXY=http://192.168.56.1:7890 \</span><br><span class="line">-t voidking/demo:v1.0.0 . \</span><br><span class="line">-f Dockerfile_test</span><br></pre></td></tr></table></figure><h1 id="pip代理"><a href="#pip代理" class="headerlink" title="pip代理"></a>pip代理</h1><p>执行pip命令时直接指定代理</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install xxx --proxy http://192.168.56.1:7890</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;网络代理&quot;&gt;&lt;a href=&quot;#网络代理&quot; class=&quot;headerlink&quot; title=&quot;网络代理&quot;&gt;&lt;/a&gt;网络代理&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.voidking.com/dev-linux-snat/&quot;&gt;《Linux配置SNAT上网》&lt;/a&gt;一文中，我们了解到，通过SNAT的方式能够让局域网中所有主机都能访问外网。&lt;br&gt;而网络代理，也能让局域网中所有主机都能访问外网。并且，如果网络代理支持科学上网，那么所有使用这个代理的主机也可以科学上网。&lt;/p&gt;
&lt;p&gt;本文我们就来学习一下Linux中常见的网络代理配置方法，参考文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/zaq12wsx/p/14371537.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;linux设置代理上网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/linjiangCN/p/16135203.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;docker pull 配置代理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;已知网络代理的IP和PORT为：&lt;code&gt;192.168.56.1:7890&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="docker" scheme="https://www.voidking.com/categories/engineering/docker/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
      <category term="network" scheme="https://www.voidking.com/categories/engineering/network/"/>
    
    
      <category term="docker" scheme="https://www.voidking.com/tags/docker/"/>
    
      <category term="linux" scheme="https://www.voidking.com/tags/linux/"/>
    
      <category term="centos" scheme="https://www.voidking.com/tags/centos/"/>
    
      <category term="网络" scheme="https://www.voidking.com/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>GitLab CI报错no space left on device</title>
    <link href="https://www.voidking.com/dev-gitlab-ci-no-space-left-on-device/"/>
    <id>https://www.voidking.com/dev-gitlab-ci-no-space-left-on-device/</id>
    <published>2022-09-08T20:00:00.000Z</published>
    <updated>2022-10-13T20:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>gitlab CI任务，拉基础镜像的时候报错no space left on device：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">failed to register layer: Error processing tar file(exit status 1): write &#x2F;root&#x2F;miniconda3&#x2F;envs&#x2F;cv&#x2F;lib&#x2F;python3.7&#x2F;site-packages&#x2F;xxx.so: no space left on device</span><br></pre></td></tr></table></figure><a id="more"></a><h1 id="排查思路"><a href="#排查思路" class="headerlink" title="排查思路"></a>排查思路</h1><p>问题原因猜测：</p><ul><li>偶发问题？确认是否能稳定复现</li><li>磁盘空间问题？确认runner所在主机的磁盘空间</li><li>CICD配置问题？确认CICD配置，检查用法是否正确</li><li>runner问题？重启runner，再次尝试复现</li></ul><p>排查确认：</p><ul><li>问题偶发复现，都是在同一个runner所在主机</li><li>runner所在主机的磁盘空间充足</li><li>CICD配置正确</li><li>重启runner后无法复现，问题解决了，说明是runner问题。但是过几天会再次复现，需要继续定位根因。</li></ul><h1 id="runner问题排查"><a href="#runner问题排查" class="headerlink" title="runner问题排查"></a>runner问题排查</h1><p>出问题的runner，使用的执行器是 <code>docker machine executor</code><br>docker machine类型的执行器，特点是先创建VM，然后在VM中执行作业。<br>了解了这个特点，我们就能知道报错磁盘满的并不是runner所在宿主机，而是实际执行作业的VM。</p><p>1、登录到执行作业的VM进行确认</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker-machine ls</span><br><span class="line">docker-machine ssh xxx</span><br><span class="line">df -h</span><br></pre></td></tr></table></figure><p>经确认，确实是执行作业的VM磁盘满了。因为runner所在宿主机磁盘充足，因此解决办法是给VM扩磁盘。</p><p>2、VM磁盘扩容<br>因此VM是受runner管理的，所以最好不要通过<code>docker-machine</code>命令手动扩容，而是通过修改runner配置来修改。</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/gitlab-runner/<span class="built_in">config</span>.toml</span><br></pre></td></tr></table></figure><p>config.toml中的<code>virtualbox-disk-size</code>修改到期望的值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">  [runners.machine]</span><br><span class="line">    IdleCount &#x3D; 5</span><br><span class="line">    MaxGrowthRate &#x3D; 1</span><br><span class="line">    IdleTime &#x3D; 1800</span><br><span class="line">    MachineDriver &#x3D; &quot;virtualbox&quot;</span><br><span class="line">    MachineName &#x3D; &quot;auto-scale-%s&quot;</span><br><span class="line">    MachineOptions &#x3D; [</span><br><span class="line">      &quot;engine-registry-mirror&#x3D;http:&#x2F;&#x2F;xxxxxx:5000&quot;,</span><br><span class="line">      &quot;virtualbox-memory&#x3D;4048&quot;,</span><br><span class="line">      &quot;virtualbox-disk-size&#x3D;204800&quot;,</span><br><span class="line">      &quot;virtualbox-cpu-count&#x3D;2&quot;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><p>3、重启runner</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gitlab-runner restart</span><br><span class="line">docker-machine ls</span><br></pre></td></tr></table></figure><p>重启runner后，我们可以看到VM被重建了。</p><p>4、确认磁盘大小</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker-machine ssh xxx</span><br><span class="line">df -h</span><br></pre></td></tr></table></figure><p>以上，问题解决。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;问题描述&quot;&gt;&lt;a href=&quot;#问题描述&quot; class=&quot;headerlink&quot; title=&quot;问题描述&quot;&gt;&lt;/a&gt;问题描述&lt;/h1&gt;&lt;p&gt;gitlab CI任务，拉基础镜像的时候报错no space left on device：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;failed to register layer: Error processing tar file(exit status 1): write &amp;#x2F;root&amp;#x2F;miniconda3&amp;#x2F;envs&amp;#x2F;cv&amp;#x2F;lib&amp;#x2F;python3.7&amp;#x2F;site-packages&amp;#x2F;xxx.so: no space left on device&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
      <category term="troubleshooting" scheme="https://www.voidking.com/categories/engineering/troubleshooting/"/>
    
      <category term="git" scheme="https://www.voidking.com/categories/engineering/git/"/>
    
    
      <category term="问题排查" scheme="https://www.voidking.com/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
      <category term="cicd" scheme="https://www.voidking.com/tags/cicd/"/>
    
      <category term="git" scheme="https://www.voidking.com/tags/git/"/>
    
      <category term="gitlab" scheme="https://www.voidking.com/tags/gitlab/"/>
    
  </entry>
  
  <entry>
    <title>GitLab CI/CD入门篇</title>
    <link href="https://www.voidking.com/dev-gitlab-cicd/"/>
    <id>https://www.voidking.com/dev-gitlab-cicd/</id>
    <published>2022-09-08T20:00:00.000Z</published>
    <updated>2023-02-21T14:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GitLab-CI-CD是啥？"><a href="#GitLab-CI-CD是啥？" class="headerlink" title="GitLab CI/CD是啥？"></a>GitLab CI/CD是啥？</h1><p>CI，CONTINUOUS INTEGRATION，持续集成。简单来说就是自动化构建和测试。<br>一个应用程序的代码存储在Git仓库中。开发人员推送的每个更改，甚至是开发分支，都可以通过一组脚本来自动地构建和测试。这些测试可确保更改通过您为应用程序建立的所有测试、指南和代码合规性标准。</p><p>CD，CONTINUOUS DELIVERY，持续交付。简单来说就是自动化构建和测试+支持手动触发部署。<br>每次将代码更改推送到代码库时，不仅会自动构建和测试应用程序，还支持一键部署应用程序，这里的部署需要手动触发。</p><p>CD，CONTINUOUS DEPLOYMENT，持续部署。简单来说就是自动化构建和测试+自动部署。<br>持续部署类似于持续交付，不同之处在于，不是手动触发部署应用程序，而是将其设置为自动部署。</p><p>而GitLab CI/CD，就是一种支持在GitLab中配置使用持续集成、持续交付和持续部署的工具。</p><p>参考文档：</p><ul><li><a href="https://docs.gitlab.com/ee/ci/" target="_blank" rel="noopener">GitLab CI/CD Document</a></li><li><a href="https://docs.gitlab.cn/jh/ci/" target="_blank" rel="noopener">GitLab CI/CD 中文文档</a></li><li><a href="https://docs.gitlab.cn/jh/ci/introduction/index.html" target="_blank" rel="noopener">CI/CD 概念</a></li><li><a href="http://www.ttlsa.com/news/ci-cd-cd/" target="_blank" rel="noopener">详解CI、CD &amp; CD</a></li><li><a href="https://linux.cn/article-9926-1.html" target="_blank" rel="noopener">什么是 CI/CD？</a></li><li><a href="https://en.wikipedia.org/wiki/Deployment_environment" target="_blank" rel="noopener">Deployment environment</a></li></ul><a id="more"></a><h1 id="GitLab-CI-CD基本概念"><a href="#GitLab-CI-CD基本概念" class="headerlink" title="GitLab CI/CD基本概念"></a>GitLab CI/CD基本概念</h1><ul><li>pipeline：在每个仓库中，使用名为<code>.gitlab-ci.yml</code>的yaml文件配置gitlab ci/cd流水线（pipeline）</li><li>stage：一条流水线可以包含多个阶段（stage），一个阶段可以包含多个作业</li><li>job：作业（job）是具体要执行的任务，是命令脚本语句的集合</li><li>runner：runner是每个作业的执行节点；每个作业可以根据标签选择不同的执行节点</li></ul><h1 id="Gitlab-CI-CD工作机制"><a href="#Gitlab-CI-CD工作机制" class="headerlink" title="Gitlab CI/CD工作机制"></a>Gitlab CI/CD工作机制</h1><p>1、在gitlab仓库中添加<code>.gitlab-ci.yml</code>文件，定义流水线  </p><p>2、当仓库中发生commit、push、merge等事件时，根据<code>.gitlab-ci.yml</code>的定义触发流水线  </p><p>3、流水线会调用gitlab runner，在gitlab runner中按照<code>.gitlab-ci.yml</code>的定义跑作业</p><h1 id="GitLab-CI-CD流水线语法"><a href="#GitLab-CI-CD流水线语法" class="headerlink" title="GitLab CI/CD流水线语法"></a>GitLab CI/CD流水线语法</h1><p>参考文档：</p><ul><li><a href="https://docs.gitlab.com/ee/ci/yaml/gitlab_ci_yaml.html" target="_blank" rel="noopener">The .gitlab-ci.yml file</a></li><li><a href="https://docs.gitlab.com/ee/ci/yaml/" target="_blank" rel="noopener">.gitlab-ci.yml keyword reference</a></li><li><a href="https://docs.gitlab.cn/jh/ci/yaml/" target="_blank" rel="noopener">.gitlab-ci.yml 关键字参考</a></li><li><a href="https://zhuanlan.zhihu.com/p/510820543" target="_blank" rel="noopener">GitLabCI-CD流水线语法</a></li></ul><h2 id="典型示例"><a href="#典型示例" class="headerlink" title="典型示例"></a>典型示例</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">stages:</span> <span class="comment">#对stages的编排</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">build</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">test</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">deploy</span></span><br><span class="line"></span><br><span class="line"><span class="attr">variables:</span></span><br><span class="line">  <span class="attr">DEPLOY_ENV:</span> <span class="string">"dev"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">ciinit:</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">build</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">.pre</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"Pipeline init first job"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">ciend:</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">build</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">.post</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"Pipeline end job"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">before_script:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"Before script section"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"For example you might run an update here or install a build dependency"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"Or perhaps you might print out some debugging details"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">after_script:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"After script section"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"For example you might do some cleanup here"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">build:</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">build</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"Do your build here"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">test1:</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s</span>  </span><br><span class="line">  <span class="attr">stage:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"Do a test here"</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"For example run a test suite"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">test2:</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s</span>  </span><br><span class="line">  <span class="attr">stage:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"Do a test here"</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"For example run a test suite"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">tags:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s</span>  </span><br><span class="line">  <span class="attr">stage:</span> <span class="string">deploy</span></span><br><span class="line">  <span class="attr">variables:</span></span><br><span class="line">    <span class="attr">DEPLOY_ENV:</span> <span class="string">"test"</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"$&#123;DEPLOY_ENV&#125;"</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"Do your deploy here"</span></span><br></pre></td></tr></table></figure><h2 id="stages阶段控制"><a href="#stages阶段控制" class="headerlink" title="stages阶段控制"></a>stages阶段控制</h2><ul><li>stages里可以定义各个stage执行的前后顺序，但是<code>.pre</code>和<code>.post</code>阶段不受其控制</li><li><code>.pre</code>阶段的作业总是在流水线开始时执行</li><li><code>.post</code>阶段的作业总是在流水线结束时执行</li><li>如果两个或者多个作业，指向同一个阶段名称，则该阶段下的所有作业都并行运行；如果不能并行运行，需要检查runner的配置文件中的<code>concurrent</code></li></ul><h2 id="variables环境变量"><a href="#variables环境变量" class="headerlink" title="variables环境变量"></a>variables环境变量</h2><p>环境变量可以分为两类：全局变量和局部变量，局部变量优先级高于全局变量</p><ul><li>全局变量是整个流水线生效的，局部变量是仅在作业中生效的</li><li>全局变量可以使用CI自带的预定义变量，也可以自定义变量</li><li>全局变量定义在全局 variables 中，也可以定义在 workflow:rules:variables 中</li><li>局部变量定义在 job:variables 中，也可以定义在 job:rules:variables 中</li></ul><p>.gitlab-ci.yml解析顺序为：全局变量 -&gt; workflow规则 -&gt; job规则，因此：job中变量优先级 &gt; workflow中变量优先级 &gt; 全局变量优先级</p><p>常用全局预定义变量：</p><table><thead><tr><th align="left">变量名称</th><th align="center">GitLab</th><th align="center">GitLab Runner</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">CI</td><td align="center">all</td><td align="center">0.4</td><td align="left">对CI/CD中的所有作业可见，值为true</td></tr><tr><td align="left">CI_BUILDS_DIR</td><td align="center">all</td><td align="center">11.10</td><td align="left">构建时的最顶层目录</td></tr><tr><td align="left">CI_COMMIT_AUTHOR</td><td align="center">13.11</td><td align="center">all</td><td align="left">提交的作者，格式为：名称&lt;邮箱&gt;</td></tr><tr><td align="left">CI_COMMIT_BEFORE_SHA</td><td align="center">11.2</td><td align="center">all</td><td align="left">当前分支的上一个提交哈希值</td></tr><tr><td align="left">CI_COMMIT_BRANCH</td><td align="center">12.6</td><td align="center">0.5</td><td align="left">提交的分支名，在合并流水线和tag流水线时不可见</td></tr><tr><td align="left">CI_COMMIT_DESCRIPTION</td><td align="center">10.8</td><td align="center">all</td><td align="left">提交的描述</td></tr><tr><td align="left">CI_COMMIT_MESSAGE</td><td align="center">10.8</td><td align="center">all</td><td align="left">完整的提交信息</td></tr><tr><td align="left">CI_COMMIT_REF_NAME</td><td align="center">9.0</td><td align="center">all</td><td align="left">项目的分支名或tag名</td></tr><tr><td align="left">CI_COMMIT_REF_PROTECTED</td><td align="center">11.11</td><td align="center">all</td><td align="left">如果作业正在构建的是被保护的分支或tag，值为true</td></tr><tr><td align="left">CI_COMMIT_REF_SLUG</td><td align="center">9.0</td><td align="center">all</td><td align="left">CI_COMMIT_REF_NAME的小写形式。</td></tr><tr><td align="left">CI_COMMIT_SHA</td><td align="center">9.0</td><td align="center">all</td><td align="left">提交的完整哈希值</td></tr><tr><td align="left">CI_COMMIT_SHORT_SHA</td><td align="center">11.7</td><td align="center">all</td><td align="left">8个字符的提交哈希值</td></tr><tr><td align="left">CI_COMMIT_TAG</td><td align="center">9.0</td><td align="center">0.5</td><td align="left">提交的tag，仅在tag流水线可见</td></tr><tr><td align="left">CI_COMMIT_TIMESTAMP</td><td align="center">13.4</td><td align="center">all</td><td align="left">提交时的时间戳</td></tr><tr><td align="left">CI_COMMIT_TITLE</td><td align="center">10.8</td><td align="center">all</td><td align="left">提交的标题</td></tr><tr><td align="left">CI_DEFAULT_BRANCH</td><td align="center">12.4</td><td align="center">all</td><td align="left">项目的默认分支</td></tr><tr><td align="left">CI_DEPLOY_FREEZE</td><td align="center">13.2</td><td align="center">all</td><td align="left">当流水运行是处于部署冻结阶段时可见，值为true。</td></tr><tr><td align="left">CI_ENVIRONMENT_NAME</td><td align="center">8.15</td><td align="center">all</td><td align="left">当前作业的部署环境名，当设置了environment:name 时可见</td></tr><tr><td align="left">CI_ENVIRONMENT_URL</td><td align="center">9.3</td><td align="center">all</td><td align="left">当前作业的部署环境地址，只有设置了environment:url可见</td></tr><tr><td align="left">CI_JOB_ID</td><td align="center">9.0</td><td align="center">all</td><td align="left">当前作业的ID，系统内唯一</td></tr><tr><td align="left">CI_JOB_IMAGE</td><td align="center">12.9</td><td align="center">12.9</td><td align="left">当前作业使用的Docker镜像名</td></tr><tr><td align="left">CI_JOB_NAME</td><td align="center">9.0</td><td align="center">0.5</td><td align="left">当前作业名称</td></tr><tr><td align="left">CI_JOB_STAGE</td><td align="center">9.0</td><td align="center">0.5</td><td align="left">当前作业所属的阶段名</td></tr><tr><td align="left">CI_PIPELINE_ID</td><td align="center">8.10</td><td align="center">all</td><td align="left">当前流水线ID（实例级），系统内唯一</td></tr><tr><td align="left">CI_PIPELINE_SOURCE</td><td align="center">10.0</td><td align="center">all</td><td align="left">流水线触发方式，枚举值为push,web, schedule, api, external, chat, webide,merge_request_event, external_pull_request_event, parent_pipeline, trigger, 或者 pipeline</td></tr><tr><td align="left">CI_PIPELINE_TRIGGERED</td><td align="center">all</td><td align="center">all</td><td align="left">当作业是使用trigger触发的时为true</td></tr><tr><td align="left">CI_PIPELINE_URL</td><td align="center">11.1</td><td align="center">0.5</td><td align="left">流水线详情的地址</td></tr><tr><td align="left">CI_PIPELINE_CREATED_AT</td><td align="center">13.10</td><td align="center">all</td><td align="left">流水线创建时间</td></tr><tr><td align="left">CI_PROJECT_DIR</td><td align="center">all</td><td align="center">all</td><td align="left">存放克隆项目的完整路径，作业运行的目录。</td></tr><tr><td align="left">CI_PROJECT_NAME</td><td align="center">8.10</td><td align="center">0.5</td><td align="left">当前项目名称，不包含组名</td></tr><tr><td align="left">CI_PROJECT_NAMESPACE</td><td align="center">8.10</td><td align="center">0.5</td><td align="left">项目的命名空间（组名或用户名）</td></tr><tr><td align="left">CI_PROJECT_PATH</td><td align="center">8.10</td><td align="center">0.5</td><td align="left">包含项目名称的命名空间</td></tr><tr><td align="left">CI_PROJECT_TITLE</td><td align="center">12.4</td><td align="center">all</td><td align="left">项目名称（网页上显示的）</td></tr><tr><td align="left">CI_PROJECT_URL</td><td align="center">8.10</td><td align="center">0.5</td><td align="left">项目HTTP(S)地址</td></tr><tr><td align="left">CI_RUNNER_TAGS</td><td align="center">8.10</td><td align="center">0.5</td><td align="left">逗号分割的runner标签列表</td></tr><tr><td align="left">GITLAB_USER_EMAIL</td><td align="center">8.12</td><td align="center">all</td><td align="left">开始当前作业的用户邮箱</td></tr><tr><td align="left">GITLAB_USER_LOGIN</td><td align="center">10.0</td><td align="center">all</td><td align="left">开始当前作业的登录用户名</td></tr><tr><td align="left">GITLAB_USER_NAME</td><td align="center">10.0</td><td align="center">all</td><td align="left">开始当前作业的用户名</td></tr><tr><td align="left">CI_MERGE_REQUEST_APPROVED （仅合并流水线）</td><td align="center">14.1</td><td align="center">all</td><td align="left">当合并流水线的MR被通过时值为true</td></tr><tr><td align="left">CI_MERGE_REQUEST_ASSIGNEES （仅合并流水线）</td><td align="center">11.9</td><td align="center">all</td><td align="left">逗号分割的合并请求指派人列表</td></tr><tr><td align="left">CI_MERGE_REQUEST_SOURCE_BRANCH_NAME（仅合并流水线）</td><td align="center">11.6</td><td align="center">all</td><td align="left">合并请求中的源分支名称</td></tr><tr><td align="left">CI_MERGE_REQUEST_TARGET_BRANCH_NAME（仅合并流水线）</td><td align="center">11.6</td><td align="center">all</td><td align="left">合并请求中的目标分支名称</td></tr><tr><td align="left">CI_MERGE_REQUEST_TITLE（仅合并流水线）</td><td align="center">11.9</td><td align="center">all</td><td align="left">合并请求的标题</td></tr></tbody></table><p>预定义变量详情参考文档：</p><ul><li><a href="https://docs.gitlab.com/ee/ci/variables/predefined_variables.html" target="_blank" rel="noopener">Predefined variables reference</a></li><li><a href="https://cloud.tencent.com/developer/article/1976361" target="_blank" rel="noopener">GitLab CI/CD中的常用预设变量</a></li></ul><h2 id="job关键字"><a href="#job关键字" class="headerlink" title="job关键字"></a>job关键字</h2><ul><li>variables：定义作业中的环境变量</li><li>tags：根据标签选择运行作业的节点，如果有多个标签，则匹配具有所有标签的节点</li><li>stage：指定当前作业所属的阶段名称</li><li>before_script：作业在运行前执行的Shell命令行</li><li>script：作业在运行中执行的Shell命令行，每个作业至少要包含一个script</li><li>after_script：作业在运行后执行的Shell命令行</li><li>only：作业控制，满足条件时执行</li><li>except：作业控制，满足条件时不执行</li><li>rules：作业控制，12.3之后引入的特性，不能与only/except混用，具体用法参考【jobs:rules作业控制】一节</li></ul><p>有了before_script、script、和after_script，可以方便我们把通用的脚本抽象出来。</p><ul><li>before_script：有命令执行结果非0，job判定失败，不再执行before_script的后续命令，跳过script，继续执行after_script</li><li>script：有命令执行结果为0，job判定失败，不再执行script的后续命令，继续执行after_script</li><li>after_script：有命令执行结果非0，job判定不受影响，不再执行after_script后续命令</li></ul><h2 id="job-rules作业控制"><a href="#job-rules作业控制" class="headerlink" title="job:rules作业控制"></a>job:rules作业控制</h2><p>使用 job:rules 关键字来控制何时创建作业。</p><p>rules包含以下子关键字：</p><ul><li>if：条件判断，为true时再看对应的其他规则。<ul><li>if的语法和bash中的if语法很像</li><li>不同1：模式匹配时添加了两个斜杠</li><li>不同2：变量不能加花括号（版本14.0.5）</li></ul></li><li>when：前面的作业成功或者失败时运行。on_success（默认值）前面作业成功时执行；on_failure 前面作业失败时执行；always 总是执行；manual 手动执行；delayed&amp;start_in 延迟执行；never 永不执行。</li><li>allow_failure：是否允许作业失败，默认值为false。启用后，作业失败不会阻塞接下来的任务。</li><li>retry：作业遇到错误重新运行的次数。</li><li>timeout：作业运行超时时间。</li><li>needs：作业依赖控制。当前作业可能只依赖前一个stage的其中一个作业，就不用等前一个stage的作业全部完成。</li><li>parallel：生成多个作业，并行运行。值在<code>2-50</code>之间。</li><li>variables：定义特定作业条件下的变量。</li></ul><p>参考文档：</p><ul><li><a href="https://my.oschina.net/zeyangli/blog/4346888" target="_blank" rel="noopener">GitLabCI系列之流水线语法第三部分</a></li><li><a href="https://docs.gitlab.com/ee/ci/jobs/job_control.html" target="_blank" rel="noopener">Choose when to run jobs</a></li><li><a href="https://docs.gitlab.cn/jh/ci/jobs/job_control.html" target="_blank" rel="noopener">选择何时运行作业</a></li><li><a href="https://docs.gitlab.cn/jh/ci/yaml/index.html#rules" target="_blank" rel="noopener">.gitlab-ci.yml 关键字参考 - rules</a></li></ul><h2 id="workflow-rules流水线控制"><a href="#workflow-rules流水线控制" class="headerlink" title="workflow:rules流水线控制"></a>workflow:rules流水线控制</h2><p>使用 workflow:rules 关键字来控制何时创建流水线。<br>workflow:rules 关键字在作业之前进行评估。例如，将作业配置为针对标签运行，但工作流阻止标签流水线，则该作业永远不会运行。</p><p>rules包含以下关键字：</p><ul><li>if：条件判断，为true时再看对应的when规则。</li><li>when：取值<code>never</code>表示流水线不运行，取值<code>always</code>或者缺省表示流水线运行。<ul><li>最后一个规则的if缺省，<code>when: always</code>表示其他所有流水线类型都运行。</li><li>最后一个规则不是<code>when: always</code>，表示其他所有流水线类型都不运行。</li></ul></li><li>variables：定义特定流水线条件的变量（引入于13.11版本）。例如不同分支，同一个变量可以定义不同的值。</li></ul><p>参考文档：</p><ul><li><a href="https://docs.gitlab.cn/jh/ci/yaml/workflow.html" target="_blank" rel="noopener">GitLab CI/CD workflow 关键字</a></li><li><a href="https://docs.gitlab.cn/jh/ci/yaml/index.html#workflowrulesvariables" target="_blank" rel="noopener">.gitlab-ci.yml 关键字参考 - workflow</a></li><li><a href="https://forum.gitlab.com/t/interaction-between-workflow-rules-and-rules/49704" target="_blank" rel="noopener">Interaction between workflow:rules and rules</a></li></ul><h2 id="include"><a href="#include" class="headerlink" title="include"></a>include</h2><p>使用 include 在 CI/CD 配置中包含外部 YAML 文件。 您可以将一个长的 .gitlab-ci.yml 文件拆分为多个文件以提高可读性，或减少同一配置在多个位置的重复。</p><p>您还可以将模板文件存储在中央仓库中并将它们包含在项目中。</p><p>include 文件说明：</p><ul><li>与 .gitlab-ci.yml 文件中的那些合并。</li><li>无论 include 关键字的位置如何，始终先求值，然后与 .gitlab-ci.yml 文件的内容合并。</li></ul><p>include 子键：</p><ul><li>include:local</li><li>include:project，include:file，include:ref</li><li>include:remote</li><li>include:template</li></ul><p>注意：如果include了多个文件中都包含stages，那么最后一个文件中的stages会生效。</p><p>参考文档：<a href="https://docs.gitlab.cn/jh/ci/yaml/#include" target="_blank" rel="noopener">gitlab-ci - include</a></p><h2 id="extends"><a href="#extends" class="headerlink" title="extends"></a>extends</h2><p>使用 extends 来重用配置 section。它是 YAML 锚点 的替代方案，并且更加灵活和可读。</p><p>关键字类型：作业关键字。您只能将其用作作业的一部分。</p><p>可能的输入：</p><ul><li>流水线中另一个作业的名称。</li><li>流水线中其他作业的名称列表（数组）。</li></ul><p>注意：extends父作业时，如果不想执行父作业，那么父作业的名称应该以点<code>.</code>开头。</p><p>参考文档：<a href="https://docs.gitlab.cn/jh/ci/yaml/#extends" target="_blank" rel="noopener">gitlab-ci - extends</a></p><h1 id="常用配置"><a href="#常用配置" class="headerlink" title="常用配置"></a>常用配置</h1><h2 id="当流水线成功时合并分支"><a href="#当流水线成功时合并分支" class="headerlink" title="当流水线成功时合并分支"></a>当流水线成功时合并分支</h2><p>1、项目配置<br>Project -&gt; Settings -&gt; General -&gt; Merge requests -&gt; Expand -&gt; Merge checks -&gt; 勾选 Pipelines must succeed</p><p>2、gitlab-ci配置<br>gitlab-ci配置时，要保证workflow和job中都允许merge requests触发pipeline。</p><p>3、触发合并请求<br>gitlab页面上发起一次合并请求，或者使用glab发起合并请求</p><p>4、流水线成功时自动合并<br>打开合并代码的页面，当pipeline运行时，点击 Merge when pipeline succeeds</p><p>参考文档：</p><ul><li><a href="https://docs.gitlab.cn/jh/user/project/merge_requests/merge_when_pipeline_succeeds.html" target="_blank" rel="noopener">当流水线成功时合并</a></li><li><a href="https://gitlab.voidking.com/help/ci/merge_request_pipelines/index.md#configuring-pipelines-for-merge-requests" target="_blank" rel="noopener">Configuring pipelines for merge requests</a></li><li><a href="https://blog.csdn.net/wzj_110/article/details/104515993" target="_blank" rel="noopener">配置Gitlab合并流水线</a></li><li><a href="https://www.jianshu.com/p/54d57ed593e9" target="_blank" rel="noopener">Gitlab 发起合并请求，一行命令就搞定！</a></li></ul><h1 id="Gitlab-Runner"><a href="#Gitlab-Runner" class="headerlink" title="Gitlab Runner"></a>Gitlab Runner</h1><p>参考文档<a href="https://www.voidking.com/dev-gitlab-runner/">《GitLab Runner入门篇》</a></p><h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul><li>阅读<a href="https://docs.gitlab.com/ee/ci/yaml/gitlab_ci_yaml.html" target="_blank" rel="noopener">The .gitlab-ci.yml file</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;GitLab-CI-CD是啥？&quot;&gt;&lt;a href=&quot;#GitLab-CI-CD是啥？&quot; class=&quot;headerlink&quot; title=&quot;GitLab CI/CD是啥？&quot;&gt;&lt;/a&gt;GitLab CI/CD是啥？&lt;/h1&gt;&lt;p&gt;CI，CONTINUOUS INTEGRATION，持续集成。简单来说就是自动化构建和测试。&lt;br&gt;一个应用程序的代码存储在Git仓库中。开发人员推送的每个更改，甚至是开发分支，都可以通过一组脚本来自动地构建和测试。这些测试可确保更改通过您为应用程序建立的所有测试、指南和代码合规性标准。&lt;/p&gt;
&lt;p&gt;CD，CONTINUOUS DELIVERY，持续交付。简单来说就是自动化构建和测试+支持手动触发部署。&lt;br&gt;每次将代码更改推送到代码库时，不仅会自动构建和测试应用程序，还支持一键部署应用程序，这里的部署需要手动触发。&lt;/p&gt;
&lt;p&gt;CD，CONTINUOUS DEPLOYMENT，持续部署。简单来说就是自动化构建和测试+自动部署。&lt;br&gt;持续部署类似于持续交付，不同之处在于，不是手动触发部署应用程序，而是将其设置为自动部署。&lt;/p&gt;
&lt;p&gt;而GitLab CI/CD，就是一种支持在GitLab中配置使用持续集成、持续交付和持续部署的工具。&lt;/p&gt;
&lt;p&gt;参考文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.gitlab.com/ee/ci/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitLab CI/CD Document&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.gitlab.cn/jh/ci/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitLab CI/CD 中文文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.gitlab.cn/jh/ci/introduction/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CI/CD 概念&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.ttlsa.com/news/ci-cd-cd/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;详解CI、CD &amp;amp; CD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://linux.cn/article-9926-1.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;什么是 CI/CD？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Deployment_environment&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Deployment environment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
      <category term="git" scheme="https://www.voidking.com/categories/engineering/git/"/>
    
    
      <category term="cicd" scheme="https://www.voidking.com/tags/cicd/"/>
    
      <category term="git" scheme="https://www.voidking.com/tags/git/"/>
    
      <category term="gitlab" scheme="https://www.voidking.com/tags/gitlab/"/>
    
  </entry>
  
  <entry>
    <title>Argo CD入门篇</title>
    <link href="https://www.voidking.com/dev-argocd-start/"/>
    <id>https://www.voidking.com/dev-argocd-start/</id>
    <published>2022-09-08T20:00:00.000Z</published>
    <updated>2023-02-06T17:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Argo-CD是啥？"><a href="#Argo-CD是啥？" class="headerlink" title="Argo CD是啥？"></a>Argo CD是啥？</h1><blockquote><p>What Is Argo CD? Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.<br>Why Argo CD? Application definitions, configurations, and environments should be declarative and version controlled. Application deployment and lifecycle management should be automated, auditable, and easy to understand.</p></blockquote><p>Argo CD是什么？Argo CD是一个声明式的基于GitOps的用于K8S的持续交付工具。<br>为什么要使用Argo CD？应用定义、配置和环境都应该被声明和版本控制。应用部署和生命周期管理都应该是自动的、可审计的、易理解的。</p><p>Argo CD 遵循 GitOps 模式，使用 Git 仓库作为定义所需应用程序状态的真实来源，Argo CD 支持多种 Kubernetes 清单：</p><ul><li>kustomize</li><li>helm charts</li><li>ksonnet applications</li><li>jsonnet files</li><li>Plain directory of YAML/json manifests</li><li>Any custom config management tool configured as a config management plugin<br>Argo CD 可在指定的目标环境中自动部署所需的应用程序状态，应用程序部署可以在 Git 提交时跟踪对分支、标签的更新，或固定到清单的指定版本。</li></ul><p>参考文档：</p><ul><li><a href="https://argo-cd.readthedocs.io/en/stable/" target="_blank" rel="noopener">Argo CD官方文档</a></li><li><a href="https://www.qikqiak.com/k8strain2/devops/gitops/argocd/" target="_blank" rel="noopener">Argo CD</a></li></ul><a id="more"></a><h1 id="GitOps是啥？"><a href="#GitOps是啥？" class="headerlink" title="GitOps是啥？"></a>GitOps是啥？</h1><p>上面提到了GitOps，这是个啥？<br>在聊GitOps之前，先聊一下<a href="https://zh.wikipedia.org/wiki/DevOps" target="_blank" rel="noopener">DevOps</a>。<br><img src="https://cdn.voidking.com/@/imgs/argocd-start/devops.png?imageView2/0/w/800" alt=""></p><blockquote><p>DevOps（Development和Operations的组合词）是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。通过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。</p></blockquote><p>DevOps简单来说，就是敏捷思维（版本更新又快又好）！为了实现敏捷，需要标准和规范，需要开发、测试、运维合作，需要自动化。</p><p>而GitOps，正是基于敏捷思维而诞生的一种持续交付方式，能够用声明的方式优雅地进行CICD。<br>1、源码存储于Git源码仓库，开发人员推送提交包含新功能的代码到代码仓库的对应分支中；代码审核通过后将被合并至对应分支。<br>2、合并请求通过后会触发构建并进行测试，构建好的镜像将被推送至镜像仓库中。<br>3、GitOps检测到有新的镜像，会提取最新的镜像标记，然后同步到Git配置仓库（Config）的清单中。<br>4、GitOps检测到集群状态过期，会从配置仓库中拉取更新后的清单，并将包含新功能的镜像通过部署到集群里。</p><p>对于不同环境而言，可以在Config仓中创建多个子目录或者子分支管理不同环境对应的多个集群，从而实现多环境的GitOps。</p><p>更多内容参考<a href="https://bbs.huaweicloud.com/blogs/314858" target="_blank" rel="noopener">浅谈GitOps</a></p><h1 id="Argo-CD架构"><a href="#Argo-CD架构" class="headerlink" title="Argo CD架构"></a>Argo CD架构</h1><p><img src="https://cdn.voidking.com/@/imgs/argocd-start/argocd_architecture.png?imageView2/0/w/800" alt=""></p><ul><li>API Server是一个 gRPC/REST server，它开放了 Web UI、CLI 和 CI/CD 系统使用的 API。</li><li>Repository Server是一个内部服务，它维护应用清单的Git仓库的本地缓存，负责生成和返回 Kubernetes 清单。</li><li>Application Controller是一个 Kubernetes 控制器，它持续监控正在运行的应用程序并将当前的活动状态与所需的目标状态（如 repo 中指定的）进行比较，检测 OutOfSync 应用程序状态并可选择采取纠正措施。负责为生命周期事件（PreSync、Sync、PostSync）调用用户定义的钩子。</li></ul><p>以上是官方给的argocd架构图和说明，详情参考<a href="https://argo-cd.readthedocs.io/en/stable/operator-manual/architecture/" target="_blank" rel="noopener">Architectural Overview</a>。<br>这个架构图不太友好，没有明显体现出argocd监听git仓库。</p><p>下面再看一个比较友好的argocd架构图：<br><img src="https://cdn.voidking.com/@/imgs/argocd-start/arch.jpeg?imageView2/0/w/800" alt=""><br>CI流水线触发更新Git仓库中的K8S应用清单，或者工程师直接修改Git仓库中的K8S应用清单，Argo CD都会自动拉取最新的配置并应用到K8S集群中。详情参考<a href="https://zhuanlan.zhihu.com/p/551331656" target="_blank" rel="noopener">Argo CD 入门教程</a></p><h1 id="触发Argo-CD同步的方式"><a href="#触发Argo-CD同步的方式" class="headerlink" title="触发Argo CD同步的方式"></a>触发Argo CD同步的方式</h1><p>触发Argo CD同步有三种方式：</p><ul><li>手动：在页面上点击触发同步，或者使用CLI触发同步</li><li>自动：配置后自动触发同步</li><li>Webhook：Git仓库更新后，通过Webhook告知Argo CD触发同步。详情参考文档<a href="https://argo-cd.readthedocs.io/en/stable/operator-manual/webhook/" target="_blank" rel="noopener">Git Webhook Configuration</a></li></ul><h1 id="Argo-CD使用"><a href="#Argo-CD使用" class="headerlink" title="Argo CD使用"></a>Argo CD使用</h1><p>参考文档：</p><ul><li><a href="https://argo-cd.readthedocs.io/en/stable/getting_started/" target="_blank" rel="noopener">Argo CD - Getting Started</a></li><li><a href="https://zhuanlan.zhihu.com/p/551331656" target="_blank" rel="noopener">Argo CD 入门教程</a></li><li><a href="https://blog.csdn.net/youzhouliu/article/details/125033353" target="_blank" rel="noopener">Argo CD 使用</a></li><li><a href="https://zhuanlan.zhihu.com/p/162884286" target="_blank" rel="noopener">Kustomize + Argo CD 优化发布流程</a></li><li><a href="https://argo-cd.readthedocs.io/en/stable/user-guide/auto_sync/" target="_blank" rel="noopener">Argo CD - Automated Sync Policy</a></li><li><a href="https://argo-cd.readthedocs.io/en/stable/user-guide/sync-options/" target="_blank" rel="noopener">Argo CD - Sync Options</a></li></ul><h2 id="准备git仓库"><a href="#准备git仓库" class="headerlink" title="准备git仓库"></a>准备git仓库</h2><p>创建一个git仓库，包含k8s资源清单（一般是kustomization文件）。<br>使用这些资源清单可以在k8s中创建和变更deployment、service等资源对象（不使用argocd，直接使用kubectl也可以）。</p><p>git仓库参考：<a href="https://github.com/voidking/argocd-demo" target="_blank" rel="noopener">voidking/argocd-demo</a></p><p>kustomize相关知识点参考：<a href="https://www.voidking.com/dev-kubectl-kustomize/">《Kustomize工具》</a></p><h2 id="配置argocd应用"><a href="#配置argocd应用" class="headerlink" title="配置argocd应用"></a>配置argocd应用</h2><p>通过argocd的client或者UI界面，配置一个argocd应用。<br>应用会指定git仓库、路径，这样就知道使用哪些资源清单了。<br>应用还会指定k8s集群，这样就知道在哪个集群中创建和变更资源对象了。</p><p>Automated SYNC POLICY​​​：</p><ul><li>RRUNE RESOURCES​​：自动修剪。集群上某个资源在 GitRepo 中找不到对应的配置时，自动删除集群上的该资源。</li><li>SELF HEAL​​：自愈。因各种原因（如手动修改）集群上资源的实时状态而导致与 GitRepo 不匹配时，自动将实际状态与 GitRepo 的期望状态同步。不勾选时，虽然也会进行自动同步的探测，但是只有当GitRepo中清单发生变化时，才会触发k8s资源变更。</li><li>自动同步时间间隔：默认180s。详情参考文档<a href="https://github.com/argoproj/argo-cd/issues/8378" target="_blank" rel="noopener">Automated Sync Policy default interval value</a></li></ul><p>SYNC OPTIONS：<br>​- SKIP SCHEMA VALIDATION​​：是否执行资源规范格式的校验。<br>​​- AUTO-CREATE NAMESPACE​​：自动创建命名空间。<br>​​- PRUNE LAST​​：在同步操作的最后在执行修剪操作，即其他资源已经部署且转为健康状态后再进行 prune<br>​​- APPLY OUT OF SYNC ONLY​​​：仅对那些处于 ​​OutOfSync​​​ 状态的资源执行同步操作。<br>​​- REPLACE​​：将使用 kubectl replace/create 命令同步资源，而非默认的 apply<br>​​- PRUNE PROPAGATION POLICY​​：资源修剪传播策略，默认值使用 foreground 策略，还有 background 和 orphan<br>​​- RESPECT IGNORE DIFFERENCES​​​：在同步阶段忽略期望状态的字段。例如我们有个 deployment，里面的 replicas 为 20，代表我们期望的 pod 数量为 20 个，但如果我们进行灰度发布的时候，可能多，也可能少。这个时候，如果不勾选 ​​RESPECT IGNORE DIFFERENCES​​ ，就会导致灰度发布出现问题，所以这时候我们最好是勾选上该参数。</p><h2 id="资源创建-变更"><a href="#资源创建-变更" class="headerlink" title="资源创建/变更"></a>资源创建/变更</h2><p>配置完成，点击同步，argocd就会从git仓库获取最新的配置清单，apply到k8s集群。<br>如果配置了自动同步，那么默认3分钟自动同步一次，可以修改<code>timeout.reconciliation</code>字段修改同步间隔。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Argo-CD是啥？&quot;&gt;&lt;a href=&quot;#Argo-CD是啥？&quot; class=&quot;headerlink&quot; title=&quot;Argo CD是啥？&quot;&gt;&lt;/a&gt;Argo CD是啥？&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;What Is Argo CD? Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.&lt;br&gt;Why Argo CD? Application definitions, configurations, and environments should be declarative and version controlled. Application deployment and lifecycle management should be automated, auditable, and easy to understand.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Argo CD是什么？Argo CD是一个声明式的基于GitOps的用于K8S的持续交付工具。&lt;br&gt;为什么要使用Argo CD？应用定义、配置和环境都应该被声明和版本控制。应用部署和生命周期管理都应该是自动的、可审计的、易理解的。&lt;/p&gt;
&lt;p&gt;Argo CD 遵循 GitOps 模式，使用 Git 仓库作为定义所需应用程序状态的真实来源，Argo CD 支持多种 Kubernetes 清单：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kustomize&lt;/li&gt;
&lt;li&gt;helm charts&lt;/li&gt;
&lt;li&gt;ksonnet applications&lt;/li&gt;
&lt;li&gt;jsonnet files&lt;/li&gt;
&lt;li&gt;Plain directory of YAML/json manifests&lt;/li&gt;
&lt;li&gt;Any custom config management tool configured as a config management plugin&lt;br&gt;Argo CD 可在指定的目标环境中自动部署所需的应用程序状态，应用程序部署可以在 Git 提交时跟踪对分支、标签的更新，或固定到清单的指定版本。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考文档：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://argo-cd.readthedocs.io/en/stable/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Argo CD官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.qikqiak.com/k8strain2/devops/gitops/argocd/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Argo CD&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="k8s" scheme="https://www.voidking.com/categories/engineering/k8s/"/>
    
      <category term="cloudnative" scheme="https://www.voidking.com/categories/engineering/cloudnative/"/>
    
      <category term="devops" scheme="https://www.voidking.com/categories/engineering/devops/"/>
    
    
      <category term="k8s" scheme="https://www.voidking.com/tags/k8s/"/>
    
      <category term="argocd" scheme="https://www.voidking.com/tags/argocd/"/>
    
      <category term="cicd" scheme="https://www.voidking.com/tags/cicd/"/>
    
      <category term="devops" scheme="https://www.voidking.com/tags/devops/"/>
    
  </entry>
  
  <entry>
    <title>Clickhouse入门篇</title>
    <link href="https://www.voidking.com/dev-clickhouse-start/"/>
    <id>https://www.voidking.com/dev-clickhouse-start/</id>
    <published>2022-09-06T20:00:00.000Z</published>
    <updated>2023-01-28T11:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ClickHouse简介"><a href="#ClickHouse简介" class="headerlink" title="ClickHouse简介"></a>ClickHouse简介</h1><blockquote><p><a href="https://clickhouse.tech/" target="_blank" rel="noopener">ClickHouse</a> 是一个用于联机分析(OLAP)的列式数据库管理系统(DBMS)。</p></blockquote><p>参考文档： </p><ul><li><a href="https://clickhouse.com/docs/zh/" target="_blank" rel="noopener">什么是ClickHouse？</a></li><li><a href="https://zhuanlan.zhihu.com/p/98135840" target="_blank" rel="noopener">ClickHouse深度揭秘</a></li></ul><a id="more"></a><h1 id="ClickHouse基础概念"><a href="#ClickHouse基础概念" class="headerlink" title="ClickHouse基础概念"></a>ClickHouse基础概念</h1><p>在clickhouse集群中，clickhouse的表有两种类型：一种是本地表，一种是分布式表。<br>在单机情况下，使用本地表就可以了；在集群情况下，一般使用分布式表。<br>ch的单机和分布式的增删查改差异很大，使用的时候需要注意。<br>分布式表首先需要在集群所有节点上创建本地表，然后在本地表的基础上创建分布式表（本质是分布式视图），通过分布式表引擎聚合本地表引擎的数据。</p><p>一般写入使用本地表，查询使用分布式表。</p><p>写分布式表的优点：可以让ClickHouse控制数据到分片的路由。<br>写分布式表的缺点：</p><ul><li>数据是先写到一个分布式表的实例中并缓存起来，再逐渐分发到各个分片上去，实际是双写了数据（写入放大），浪费资源；</li><li>数据写入默认是异步的，短时间内可能造成不一致；</li><li>目标表中会产生较多的小parts，使merge（即compaction）过程压力增大。</li></ul><p>写本地表优点：同步操作，更快，parts的大小也比较合适。<br>写本地表缺点：要求应用层额外实现sharding和路由逻辑，如轮询或者随机等。</p><p>表引擎特殊说明：</p><ul><li>20版本的ch只有使用了replicated开头的engine的引擎的表，才能够在拥有on cluster xxx条件的ddl语句中进行集群更新；其他engine的表，只能够每个node进行update；21版本修复了这个bug。</li><li>目前阿里云20版本的ch的mergeTree引擎是支持on cluster xxx这样的ddl语句的。</li></ul><p>参考文档：</p><ul><li><a href="https://help.aliyun.com/document_detail/167447.html" target="_blank" rel="noopener">ClickHouse - 基本概念</a></li><li><a href="https://blog.csdn.net/weixin_46124208/article/details/123705318" target="_blank" rel="noopener">ClickHouse创建分布式表</a></li><li><a href="https://help.aliyun.com/document_detail/162815.html" target="_blank" rel="noopener">ClickHouse常见问题</a></li><li><a href="https://cloud.tencent.com/developer/article/1979174" target="_blank" rel="noopener">「Clickhouse系列」分布式表&amp;本地表详解</a></li><li><a href="https://www.cnblogs.com/laoqing/p/15954171.html" target="_blank" rel="noopener">CK 分布式表和本地表</a></li><li><a href="https://www.modb.pro/db/84325" target="_blank" rel="noopener">clickhouse单机的增删查询实现方案和clickhouse分布式部署的增删查改实现方案</a></li><li><a href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/replication/#creating-replicated-tables" target="_blank" rel="noopener">ClickHouse - Data Replication</a></li><li><a href="https://blog.csdn.net/qq_25073261/article/details/123670028" target="_blank" rel="noopener">clickhouse删除ReplicatedMergeTree复制表后，新建同名表失败原因分析</a></li></ul><h1 id="安装Clickhouse"><a href="#安装Clickhouse" class="headerlink" title="安装Clickhouse"></a>安装Clickhouse</h1><p>参考文档<a href="https://www.voidking.com/dev-k8s-clickhouse/">《K8S中安装配置Clickhouse》</a></p><h1 id="使用ClickHouse"><a href="#使用ClickHouse" class="headerlink" title="使用ClickHouse"></a>使用ClickHouse</h1><h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><p>使用dbeaver，可以图形化连接clickhouse。<br>使用clickhouse-client，可以命令行连接clickhouse。</p><h2 id="使用分布式表"><a href="#使用分布式表" class="headerlink" title="使用分布式表"></a>使用分布式表</h2><p>1、新建分布式表</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 查看宏变量</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="string">`system`</span>.macros;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 查看cluster</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="string">`system`</span>.clusters;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建本地表</span></span><br><span class="line"><span class="comment">-- create table `default`.optest on cluster cluster (a UInt64) Engine = MergeTree() order by tuple();</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="string">`default`</span>.optest <span class="keyword">on</span> cluster cluster (a UInt64) <span class="keyword">Engine</span> = ReplicatedMergeTree(<span class="string">'/clickhouse/tables/&#123;shard&#125;/default.optest'</span>,<span class="string">'&#123;replica&#125;'</span>) <span class="keyword">order</span> <span class="keyword">by</span> tuple();</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建本地表对应的分布式表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="string">`default`</span>.optest_dis <span class="keyword">on</span> cluster cluster <span class="keyword">as</span> optest <span class="keyword">Engine</span> = <span class="keyword">Distributed</span>(cluster, <span class="keyword">default</span>, optest, cityHash64(a));</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 删除本地表</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="string">`default`</span>.optest <span class="keyword">on</span> cluster cluster;</span><br><span class="line"><span class="comment">-- 要等待480s才会删除zk中的数据</span></span><br></pre></td></tr></table></figure><p>order by指定的字段是对分区内数据进行排序，在ReplicatedMergeTree引擎下，会对相邻的重复数据进行删除。</p><p>2、增删查改</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`default`</span>.optest(a) <span class="keyword">values</span>(<span class="number">10</span>);</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="string">`default`</span>.optest_dis;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`default`</span>.optest  <span class="keyword">on</span> cluster cluster <span class="keyword">UPDATE</span> <span class="string">`a`</span> = <span class="string">'11'</span> <span class="keyword">WHERE</span> <span class="string">`a`</span> = <span class="string">'10'</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="string">`default`</span>.optest_dis;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`default`</span>.optest <span class="keyword">on</span> cluster cluster <span class="keyword">DELETE</span> <span class="keyword">WHERE</span> <span class="string">`a`</span>=<span class="string">'11'</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="string">`default`</span>.optest_dis;</span><br></pre></td></tr></table></figure><h1 id="更新延迟处理"><a href="#更新延迟处理" class="headerlink" title="更新延迟处理"></a>更新延迟处理</h1><p>从使用场景来说，Clickhouse是个分析型数据库。这种场景下，数据一般是不变的，因此Clickhouse对update、delete的支持是比较弱的，实际上并不支持标准的update、delete操作。</p><p>Clickhouse通过alter方式实现更新、删除，它把update、delete操作叫做mutation(突变)。</p><p>标准SQL的更新、删除操作是同步的，即客户端要等服务端反回执行结果（通常是int值）；而Clickhouse的update、delete是通过异步方式实现的，当执行update语句时，服务端立即反回，但是实际上此时数据还没变，而是排队等着。</p><p>ClickHouse本身对update的执行是低效的，因为ClickHouse的MergeTree存储一旦生成一个Data Part，这个Part就不支持更改，而是需要删除旧Part, 重写整个Part。所以从MergeTree存储内核层面，ClickHouse就不擅长做数据更新删除操作。</p><p>参考文档：</p><ul><li><a href="https://www.modb.pro/db/197765" target="_blank" rel="noopener">ClickHouse多种实时更新方法总结</a></li><li><a href="https://www.cnblogs.com/MrYang-11-GetKnow/p/15975818.html" target="_blank" rel="noopener">clickhouse数据实时更新实现的三种方式</a></li><li><a href="https://blog.csdn.net/qq_41893274/article/details/117093168" target="_blank" rel="noopener">Clickhouse中update/delete的使用</a></li></ul><h2 id="mutations-sync"><a href="#mutations-sync" class="headerlink" title="mutations_sync"></a>mutations_sync</h2><p>使用mutations_sync参数，是最简单的方法。<br>方法一：客户端和clickhouse建立连接时，添加参数<code>mutations_sync=2</code><br>方法二：执行sql时，添加参数<code>settings mutations_sync=2</code><br>方法三：修改clickhouse服务端配置，设置<code>mutations_sync=2</code></p><p>python客户端连接参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ck_config = &#123;</span><br><span class="line">  <span class="string">"host"</span>: ck_host, </span><br><span class="line">  <span class="string">"port"</span>: ck_port, </span><br><span class="line">  <span class="string">"user"</span>: ck_user, </span><br><span class="line">  <span class="string">"password"</span>: ck_pwd, </span><br><span class="line">  <span class="string">"settings"</span>: &#123;<span class="string">"mutations_sync"</span>: <span class="string">"2"</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是，如果存在大量更新，这种方法会大量重建Part，效率会很低。</p><h2 id="ReplacingMergeTree"><a href="#ReplacingMergeTree" class="headerlink" title="ReplacingMergeTree"></a>ReplacingMergeTree</h2><p>ReplacingMergeTree + INSERT + Final 可以实现虚拟更新，以insert代替alter操作，每次select时都拉取最新一条数据。<br>当执行optimize时，老的数据才会被删除。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tb_test_replacing(</span><br><span class="line">ts DateTime,</span><br><span class="line">uid <span class="keyword">String</span>,</span><br><span class="line">biz <span class="keyword">String</span></span><br><span class="line">) <span class="keyword">ENGINE</span> = ReplacingMergeTree(ts) <span class="keyword">ORDER</span> <span class="keyword">BY</span> (ts) <span class="keyword">SETTINGS</span> index_granularity = <span class="number">8192</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> tb_test_replacing <span class="keyword">VALUES</span> (<span class="string">'2019-06-07 20:01:01'</span>, <span class="string">'c'</span>, <span class="string">'c1'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> tb_test_replacing <span class="keyword">VALUES</span> (<span class="string">'2019-06-07 20:01:01'</span>, <span class="string">'c'</span>, <span class="string">'c2'</span>);</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> tb_test_replacing;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> tb_test_replacing <span class="keyword">FINAL</span>;</span><br><span class="line"><span class="keyword">optimize</span> <span class="keyword">table</span> tb_test_replacing;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> tb_test_replacing;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;ClickHouse简介&quot;&gt;&lt;a href=&quot;#ClickHouse简介&quot; class=&quot;headerlink&quot; title=&quot;ClickHouse简介&quot;&gt;&lt;/a&gt;ClickHouse简介&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://clickhouse.tech/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ClickHouse&lt;/a&gt; 是一个用于联机分析(OLAP)的列式数据库管理系统(DBMS)。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考文档： &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://clickhouse.com/docs/zh/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;什么是ClickHouse？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/98135840&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ClickHouse深度揭秘&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="engineering" scheme="https://www.voidking.com/categories/engineering/"/>
    
      <category term="database" scheme="https://www.voidking.com/categories/engineering/database/"/>
    
    
      <category term="数据库" scheme="https://www.voidking.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="clickhouse" scheme="https://www.voidking.com/tags/clickhouse/"/>
    
  </entry>
  
</feed>
