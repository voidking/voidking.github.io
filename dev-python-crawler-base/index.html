<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:new URL("https://www.voidking.com").hostname,root:"/",scheme:"Gemini",version:"7.7.1",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1,cdn:{enable:!0,url:"//qiniu.cdn.voidking.com/doc/search.xml"}},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}}}</script><meta name="description" content="前言Python非常适合用来开发网页爬虫，理由如下：1、抓取网页本身的接口相比与其他静态编程语言，如java，c#，c++，python抓取网页文档的接口更简洁；相比其他动态脚本语言，如perl，shell，python的urllib包提供了较为完整的访问网页文档的API。（当然ruby也是很好的选择）此外，抓取网页有时候需要模拟浏览器的行为，很多网站对于生硬的爬虫抓取都是封杀的。这是我们需要模拟"><meta property="og:type" content="article"><meta property="og:title" content="Python爬虫基础"><meta property="og:url" content="https://www.voidking.com/dev-python-crawler-base/index.html"><meta property="og:site_name" content="好好学习的郝"><meta property="og:description" content="前言Python非常适合用来开发网页爬虫，理由如下：1、抓取网页本身的接口相比与其他静态编程语言，如java，c#，c++，python抓取网页文档的接口更简洁；相比其他动态脚本语言，如perl，shell，python的urllib包提供了较为完整的访问网页文档的API。（当然ruby也是很好的选择）此外，抓取网页有时候需要模拟浏览器的行为，很多网站对于生硬的爬虫抓取都是封杀的。这是我们需要模拟"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://cdn.voidking.com//imgs/python-crawler-base/structure.jpg"><meta property="og:image" content="http://cdn.voidking.com//imgs/python-crawler-base/flow.jpg"><meta property="og:image" content="http://cdn.voidking.com//imgs/python-crawler-base/error504.jpg"><meta property="og:image" content="http://cdn.voidking.com//imgs/python-crawler-base/result.jpg"><meta property="og:image" content="http://cdn.voidking.com//imgs/python-crawler-base/error400.jpg"><meta property="og:image" content="http://cdn.voidking.com//imgs/python-crawler-base/handler.jpg"><meta property="og:image" content="http://cdn.voidking.com//imgs/python-crawler-base/beautifulsoup.jpg"><meta property="og:image" content="http://cdn.voidking.com//imgs/python-crawler-base/beautifulsoup2.jpg"><meta property="og:image" content="http://cdn.voidking.com//imgs/python-crawler-base/warning.jpg"><meta property="article:published_time" content="2017-01-17T11:21:00.000Z"><meta property="article:modified_time" content="2017-01-17T11:21:00.000Z"><meta property="article:author" content="好好学习的郝"><meta property="article:tag" content="python"><meta property="article:tag" content="爬虫"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http://cdn.voidking.com//imgs/python-crawler-base/structure.jpg"><link rel="canonical" href="https://www.voidking.com/dev-python-crawler-base/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0}</script><title>Python爬虫基础 | 好好学习的郝</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b759ac2a7fa45129e3ef060bf68259f0";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="好好学习的郝" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">好好学习的郝</span><span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">一个计算机技术爱好者与学习者</h1></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div> <a href="https://github.com/voidking" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.voidking.com/dev-python-crawler-base/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="好好学习的郝"><meta itemprop="description" content="一个计算机技术爱好者与学习者"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="好好学习的郝"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> Python爬虫基础</h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2017-01-17 11:21:00" itemprop="dateCreated datePublished" datetime="2017-01-17T11:21:00+00:00">2017-01-17</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/engineering/" itemprop="url" rel="index"><span itemprop="name">engineering</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/engineering/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="前言"><span class="post-title-index">1.</span><a href="#前言" class="headerlink" title="前言"></a> 前言</h1><p>Python非常适合用来开发网页爬虫，理由如下：<br>1、抓取网页本身的接口<br>相比与其他静态编程语言，如java，c#，c++，python抓取网页文档的接口更简洁；相比其他动态脚本语言，如perl，shell，python的urllib包提供了较为完整的访问网页文档的API。（当然ruby也是很好的选择）<br>此外，抓取网页有时候需要模拟浏览器的行为，很多网站对于生硬的爬虫抓取都是封杀的。这是我们需要模拟user agent的行为构造合适的请求，譬如模拟用户登陆、模拟session/cookie的存储和设置。在python里都有非常优秀的第三方包帮你搞定，如Requests，mechanize</p><p>2、网页抓取后的处理<br>抓取的网页通常需要处理，比如过滤html标签，提取文本等。python的beautifulsoap提供了简洁的文档处理功能，能用极短的代码完成大部分文档的处理。<br>其实以上功能很多语言和工具都能做，但是用python能够干得最快，最干净。</p><blockquote><p>Life is short, you need python.</p></blockquote><p>PS：python2.x和python3.x有很大不同，本文只讨论python3.x的爬虫实现方法。</p><span id="more"></span><h1 id="爬虫架构"><span class="post-title-index">2.</span><a href="#爬虫架构" class="headerlink" title="爬虫架构"></a> 爬虫架构</h1><h2 id="架构组成"><span class="post-title-index">2.1.</span><a href="#架构组成" class="headerlink" title="架构组成"></a> 架构组成</h2><p><img src="http://cdn.voidking.com//imgs/python-crawler-base/structure.jpg"><br>URL管理器：管理待爬取的url集合和已爬取的url集合，传送待爬取的url给网页下载器。<br>网页下载器（urllib）：爬取url对应的网页，存储成字符串，传送给网页解析器。<br>网页解析器（BeautifulSoup）：解析出有价值的数据，存储下来，同时补充url到URL管理器。</p><h2 id="运行流程"><span class="post-title-index">2.2.</span><a href="#运行流程" class="headerlink" title="运行流程"></a> 运行流程</h2><p><img src="http://cdn.voidking.com//imgs/python-crawler-base/flow.jpg"></p><h1 id="URL管理器"><span class="post-title-index">3.</span><a href="#URL管理器" class="headerlink" title="URL管理器"></a> URL管理器</h1><h2 id="基本功能"><span class="post-title-index">3.1.</span><a href="#基本功能" class="headerlink" title="基本功能"></a> 基本功能</h2><ul><li>添加新的url到待爬取url集合中。</li><li>判断待添加的url是否在容器中（包括待爬取url集合和已爬取url集合）。</li><li>获取待爬取的url。</li><li>判断是否有待爬取的url。</li><li>将爬取完成的url从待爬取url集合移动到已爬取url集合。</li></ul><h2 id="存储方式"><span class="post-title-index">3.2.</span><a href="#存储方式" class="headerlink" title="存储方式"></a> 存储方式</h2><p>1、内存（python内存）<br>待爬取url集合：set()<br>已爬取url集合：set()</p><p>2、关系数据库（mysql）<br>urls(url, is_crawled)</p><p>3、缓存（redis）<br>待爬取url集合：set<br>已爬取url集合：set</p><p>大型互联网公司，由于缓存数据库的高性能，一般把url存储在缓存数据库中。小型公司，一般把url存储在内存中，如果想要永久存储，则存储到关系数据库中。</p><h1 id="网页下载器（urllib）"><span class="post-title-index">4.</span><a href="#网页下载器（urllib）" class="headerlink" title="网页下载器（urllib）"></a> 网页下载器（urllib）</h1><p>将url对应的网页下载到本地，存储成一个文件或字符串。</p><h2 id="基本方法"><span class="post-title-index">4.1.</span><a href="#基本方法" class="headerlink" title="基本方法"></a> 基本方法</h2><p>新建baidu.py，内容如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import urllib<span class="selector-class">.request</span></span><br><span class="line"></span><br><span class="line">response = urllib<span class="selector-class">.request</span><span class="selector-class">.urlopen</span>(<span class="string">&#x27;http://www.baidu.com&#x27;</span>)</span><br><span class="line">buff = response<span class="selector-class">.read</span>()</span><br><span class="line"><span class="selector-tag">html</span> = buff<span class="selector-class">.decode</span>(<span class="string">&quot;utf8&quot;</span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(html)</span></span></span><br></pre></td></tr></table></figure><p>命令行中执行<code>python baidu.py</code>，则可以打印出获取到的页面。</p><h2 id="构造Request"><span class="post-title-index">4.2.</span><a href="#构造Request" class="headerlink" title="构造Request"></a> 构造Request</h2><p>上面的代码，可以修改为：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import urllib<span class="selector-class">.request</span></span><br><span class="line"></span><br><span class="line">request = urllib<span class="selector-class">.request</span><span class="selector-class">.Request</span>(<span class="string">&#x27;http://www.baidu.com&#x27;</span>)</span><br><span class="line">response = urllib<span class="selector-class">.request</span><span class="selector-class">.urlopen</span>(request)</span><br><span class="line">buff = response<span class="selector-class">.read</span>()</span><br><span class="line"><span class="selector-tag">html</span> = buff<span class="selector-class">.decode</span>(<span class="string">&quot;utf8&quot;</span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(html)</span></span></span><br></pre></td></tr></table></figure><h2 id="携带参数"><span class="post-title-index">4.3.</span><a href="#携带参数" class="headerlink" title="携带参数"></a> 携带参数</h2><p>新建baidu2.py，内容如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import urllib<span class="selector-class">.request</span></span><br><span class="line">import urllib<span class="selector-class">.parse</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com&#x27;</span></span><br><span class="line">values = &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;voidking&#x27;</span>,<span class="string">&#x27;language&#x27;</span>: <span class="string">&#x27;Python&#x27;</span>&#125;</span><br><span class="line">data = urllib<span class="selector-class">.parse</span><span class="selector-class">.urlencode</span>(values)<span class="selector-class">.encode</span>(encoding=<span class="string">&#x27;utf-8&#x27;</span>,errors=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">headers = &#123; <span class="string">&#x27;User-Agent&#x27;</span> : <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0&#x27;</span> &#125;</span><br><span class="line">request = urllib<span class="selector-class">.request</span><span class="selector-class">.Request</span>(url=url, data=data,headers=headers,method=<span class="string">&#x27;GET&#x27;</span>)</span><br><span class="line">response = urllib<span class="selector-class">.request</span><span class="selector-class">.urlopen</span>(request)</span><br><span class="line">buff = response<span class="selector-class">.read</span>()</span><br><span class="line"><span class="selector-tag">html</span> = buff<span class="selector-class">.decode</span>(<span class="string">&quot;utf8&quot;</span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(html)</span></span></span><br></pre></td></tr></table></figure><h2 id="使用Fiddler监听数据"><span class="post-title-index">4.4.</span><a href="#使用Fiddler监听数据" class="headerlink" title="使用Fiddler监听数据"></a> 使用Fiddler监听数据</h2><p>我们想要查看一下，我们的请求是否真的携带了参数，所以需要使用fiddler。<br>打开fiddler之后，却意外发现，上面的代码会报错504，无论是baidu.py还是baidu2.py。<br><img src="http://cdn.voidking.com//imgs/python-crawler-base/error504.jpg"><br>虽然python有报错，但是在fiddler中，我们可以看到请求信息，确实携带了参数。<br><img src="http://cdn.voidking.com//imgs/python-crawler-base/result.jpg"></p><p>经过查找资料，发现python以前版本的Request都不支持代理环境下访问https。但是，最近的版本应该支持了才对。那么，最简单的办法，就是换一个使用http协议的url来爬取，比如，换成<code>http://www.csdn.net</code>。结果，依然报错，只不过变成了400错误。<br><img src="http://cdn.voidking.com//imgs/python-crawler-base/error400.jpg"></p><p>然而，然而，然而。。。神转折出现了！！！<br>当我把url换成<code>http://www.csdn.net/</code>后，请求成功！没错，就是在网址后面多加了一个斜杠<code>/</code>。同理，把<code>http://www.baidu.com</code>改成<code>http://www.baidu.com/</code>，请求也成功了！神奇！！！</p><h2 id="添加处理器"><span class="post-title-index">4.5.</span><a href="#添加处理器" class="headerlink" title="添加处理器"></a> 添加处理器</h2><p><img src="http://cdn.voidking.com//imgs/python-crawler-base/handler.jpg"></p><figure class="highlight vbscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import urllib.<span class="built_in">request</span></span><br><span class="line">import http.cookiejar</span><br><span class="line"></span><br><span class="line"># 创建cookie容器</span><br><span class="line">cj = http.cookiejar.CookieJar()</span><br><span class="line"># 创建opener</span><br><span class="line">opener = urllib.<span class="built_in">request</span>.build_opener(urllib.<span class="built_in">request</span>.HTTPCookieProcessor(cj))</span><br><span class="line"># 给urllib.<span class="built_in">request</span>安装opener</span><br><span class="line">urllib.<span class="built_in">request</span>.install_opener(opener)</span><br><span class="line"></span><br><span class="line"># 请求</span><br><span class="line"><span class="built_in">request</span> = urllib.<span class="built_in">request</span>.<span class="built_in">Request</span>(<span class="comment">&#x27;http://www.baidu.com/&#x27;)</span></span><br><span class="line"><span class="built_in">response</span> = urllib.<span class="built_in">request</span>.urlopen(<span class="built_in">request</span>)</span><br><span class="line">buff = <span class="built_in">response</span>.read()</span><br><span class="line">html = buff.decode(<span class="string">&quot;utf8&quot;</span>)</span><br><span class="line">pr<span class="built_in">int</span>(html)</span><br><span class="line">pr<span class="built_in">int</span>(cj)</span><br></pre></td></tr></table></figure><h1 id="网页解析器（BeautifulSoup）"><span class="post-title-index">5.</span><a href="#网页解析器（BeautifulSoup）" class="headerlink" title="网页解析器（BeautifulSoup）"></a> 网页解析器（BeautifulSoup）</h1><p>从网页中提取出有价值的数据和新的url列表。</p><h2 id="解析器选择"><span class="post-title-index">5.1.</span><a href="#解析器选择" class="headerlink" title="解析器选择"></a> 解析器选择</h2><p>为了实现解析器，可以选择使用正则表达式、html.parser、BeautifulSoup、lxml等，这里我们选择BeautifulSoup。<br>其中，正则表达式基于模糊匹配，而另外三种则是基于DOM结构化解析。</p><h2 id="BeautifulSoup"><span class="post-title-index">5.2.</span><a href="#BeautifulSoup" class="headerlink" title="BeautifulSoup"></a> BeautifulSoup</h2><h3 id="安装测试"><span class="post-title-index">5.2.1.</span><a href="#安装测试" class="headerlink" title="安装测试"></a> 安装测试</h3><p>1、安装，在命令行下执行<code>pip install beautifulsoup4</code>。<br>2、测试</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import bs4</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(bs4)</span></span></span><br></pre></td></tr></table></figure><h3 id="使用说明"><span class="post-title-index">5.2.2.</span><a href="#使用说明" class="headerlink" title="使用说明"></a> 使用说明</h3><p><img src="http://cdn.voidking.com//imgs/python-crawler-base/beautifulsoup.jpg"><br><img src="http://cdn.voidking.com//imgs/python-crawler-base/beautifulsoup2.jpg"></p><h3 id="基本用法"><span class="post-title-index">5.2.3.</span><a href="#基本用法" class="headerlink" title="基本用法"></a> 基本用法</h3><p>1、创建BeautifulSoup对象</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import bs4</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line"></span><br><span class="line"># 根据html网页字符串创建BeautifulSoup对象</span><br><span class="line">html_doc = &quot;&quot;&quot;</span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span><span class="tag">&lt;<span class="name">head</span>&gt;</span><span class="tag">&lt;<span class="name">title</span>&gt;</span>The Dormouse&#x27;s story<span class="tag">&lt;/<span class="name">title</span>&gt;</span><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;title&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">b</span>&gt;</span>The Dormouse&#x27;s story<span class="tag">&lt;/<span class="name">b</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;story&quot;</span>&gt;</span>Once upon a time there were three little sisters; and their names were</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/elsie&quot;</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link1&quot;</span>&gt;</span>Elsie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>,</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/lacie&quot;</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link2&quot;</span>&gt;</span>Lacie<span class="tag">&lt;/<span class="name">a</span>&gt;</span> and</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;http://example.com/tillie&quot;</span> <span class="attr">class</span>=<span class="string">&quot;sister&quot;</span> <span class="attr">id</span>=<span class="string">&quot;link3&quot;</span>&gt;</span>Tillie<span class="tag">&lt;/<span class="name">a</span>&gt;</span>;</span><br><span class="line">and they lived at the bottom of a well.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">&quot;story&quot;</span>&gt;</span>...<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">soup = BeautifulSoup(html_doc)</span><br><span class="line">print(soup.prettify())</span><br></pre></td></tr></table></figure><p>2、访问节点</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">print</span><span class="params">(soup.title)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(soup.title.name)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(soup.title.string)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(soup.title.parent.name)</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(soup.p)</span></span></span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(soup.p[<span class="string">&#x27;class&#x27;</span>])</span></span></span><br></pre></td></tr></table></figure><p>3、指定tag、class或id</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(soup.find_all(<span class="string">&#x27;a&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(soup.<span class="built_in">find</span>(<span class="string">&#x27;a&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(soup.<span class="built_in">find</span>(<span class="attribute">class_</span>=<span class="string">&#x27;title&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(soup.<span class="built_in">find</span>(<span class="attribute">id</span>=<span class="string">&quot;link3&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(soup.<span class="built_in">find</span>(<span class="string">&#x27;p&#x27;</span>,<span class="attribute">class_</span>=<span class="string">&#x27;title&#x27;</span>))</span><br></pre></td></tr></table></figure><p>4、从文档中找到所有<code>&lt;a&gt;</code>标签的链接</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> soup.find_all(<span class="string">&#x27;a&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(link.<span class="built_in">get</span>(<span class="string">&#x27;href&#x27;</span>))</span><br></pre></td></tr></table></figure><p><img src="http://cdn.voidking.com//imgs/python-crawler-base/warning.jpg"><br>出现了警告，根据提示，我们在创建BeautifulSoup对象时，指定解析器即可。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">soup</span> = BeautifulSoup(html_doc,<span class="string">&#x27;html.parser&#x27;</span>)</span><br></pre></td></tr></table></figure><p>5、从文档中获取所有文字内容</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">print</span><span class="params">(soup.get_text()</span></span>)</span><br></pre></td></tr></table></figure><p>6、正则匹配</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">link_node = soup.find(<span class="string">&#x27;a&#x27;</span>,href=re.<span class="built_in">compile</span>(<span class="string">r&#x27;til&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(link_node)</span><br></pre></td></tr></table></figure><h1 id="后记"><span class="post-title-index">6.</span><a href="#后记" class="headerlink" title="后记"></a> 后记</h1><p>python爬虫基础知识，至此足够，接下来，在实战中学习更高级的知识。</p><h1 id="书签"><span class="post-title-index">7.</span><a href="#书签" class="headerlink" title="书签"></a> 书签</h1><p>Python开发简单爬虫<br><a target="_blank" rel="noopener" href="http://www.imooc.com/learn/563">http://www.imooc.com/learn/563</a></p><p>The Python Standard Library<br><a target="_blank" rel="noopener" href="https://docs.python.org/3/library/index.html">https://docs.python.org/3/library/index.html</a></p><p>Beautiful Soup 4.2.0 文档<br><a target="_blank" rel="noopener" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html">https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html</a></p><p>为什么python适合写爬虫？<br><a target="_blank" rel="noopener" href="http://www.cnblogs.com/benzone/p/5854084.html">http://www.cnblogs.com/benzone/p/5854084.html</a></p><p>如何学习Python爬虫[入门篇]？<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/21479334?refer=passer">https://zhuanlan.zhihu.com/p/21479334?refer=passer</a></p><p>你需要这些：Python3.x爬虫学习资料整理<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/24358829?refer=passer">https://zhuanlan.zhihu.com/p/24358829?refer=passer</a></p><p>如何入门 Python 爬虫？<br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/20899988">https://www.zhihu.com/question/20899988</a></p><p>Python3.X 抓取网络资源<br><a target="_blank" rel="noopener" href="http://www.open-open.com/lib/view/open1396062681294.html">http://www.open-open.com/lib/view/open1396062681294.html</a></p><p>python网络请求和”HTTP Error 504:Fiddler - Receive Failure”<br><a target="_blank" rel="noopener" href="http://blog.csdn.net/guoguo527/article/details/50709244">http://blog.csdn.net/guoguo527/article/details/50709244</a></p><p>怎么使用Fiddler抓取自己写的爬虫的包？<br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/52614615">https://www.zhihu.com/question/52614615</a></p><p>fiddler对python脚本抓取https包时发生了错误?<br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/42104344?sort=created">https://www.zhihu.com/question/42104344?sort=created</a></p><p>HTTPS和HTTP的区别<br><a target="_blank" rel="noopener" href="http://blog.csdn.net/whatday/article/details/38147103">http://blog.csdn.net/whatday/article/details/38147103</a></p></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> 好好学习的郝</li><li class="post-copyright-link"> <strong>原文链接：</strong> <a href="https://www.voidking.com/dev-python-crawler-base/" title="Python爬虫基础">https://www.voidking.com/dev-python-crawler-base/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本文采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议，转载请注明出处！源站会即时更新知识点并修正错误，欢迎访问~</li><li> <img width="200" height="200" src="/images/avatar.jpg"><p style="text-align:center;margin-bottom:0">微信公众号同步更新，欢迎关注~</p></li></ul></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/python/" rel="tag"># python</a> <a href="/tags/%E7%88%AC%E8%99%AB/" rel="tag"># 爬虫</a></div><div class="post-nav"><div class="post-nav-item"><a href="/dev-python-module/" rel="prev" title="Python模块"><i class="fa fa-chevron-left"></i> Python模块</a></div><div class="post-nav-item"> <a href="/dev-python-crawler-baidu-baike/" rel="next" title="Python抓取百度百科数据">Python抓取百度百科数据<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><div class="footer-ads" style="margin-top:10px"><ins class="adsbygoogle" style="display:block" data-ad-format="autorelaxed" data-ad-client="ca-pub-3284447971731414" data-ad-slot="9697986181"></ins><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3284447971731414" crossorigin="anonymous"></script><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div><div class="comments" id="gitalk-container"></div><script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-text">1. 前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%88%AC%E8%99%AB%E6%9E%B6%E6%9E%84"><span class="nav-text">2. 爬虫架构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84%E7%BB%84%E6%88%90"><span class="nav-text">2.1. 架构组成</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="nav-text">2.2. 运行流程</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#URL%E7%AE%A1%E7%90%86%E5%99%A8"><span class="nav-text">3. URL管理器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E5%8A%9F%E8%83%BD"><span class="nav-text">3.1. 基本功能</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F"><span class="nav-text">3.2. 存储方式</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BD%91%E9%A1%B5%E4%B8%8B%E8%BD%BD%E5%99%A8%EF%BC%88urllib%EF%BC%89"><span class="nav-text">4. 网页下载器（urllib）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95"><span class="nav-text">4.1. 基本方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9E%84%E9%80%A0Request"><span class="nav-text">4.2. 构造Request</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%90%BA%E5%B8%A6%E5%8F%82%E6%95%B0"><span class="nav-text">4.3. 携带参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8Fiddler%E7%9B%91%E5%90%AC%E6%95%B0%E6%8D%AE"><span class="nav-text">4.4. 使用Fiddler监听数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%BB%E5%8A%A0%E5%A4%84%E7%90%86%E5%99%A8"><span class="nav-text">4.5. 添加处理器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BD%91%E9%A1%B5%E8%A7%A3%E6%9E%90%E5%99%A8%EF%BC%88BeautifulSoup%EF%BC%89"><span class="nav-text">5. 网页解析器（BeautifulSoup）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%A3%E6%9E%90%E5%99%A8%E9%80%89%E6%8B%A9"><span class="nav-text">5.1. 解析器选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BeautifulSoup"><span class="nav-text">5.2. BeautifulSoup</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85%E6%B5%8B%E8%AF%95"><span class="nav-text">5.2.1. 安装测试</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"><span class="nav-text">5.2.2. 使用说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95"><span class="nav-text">5.2.3. 基本用法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%90%8E%E8%AE%B0"><span class="nav-text">6. 后记</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B9%A6%E7%AD%BE"><span class="nav-text">7. 书签</span></a></li></ol></div></div><div class="sidecar-ads" style="margin-top:10px"><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="好好学习的郝" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">好好学习的郝</p><div class="site-description" itemprop="description">一个计算机技术爱好者与学习者</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">682</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">30</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">247</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="mailto:voidking@qq.com" title="E-Mail → mailto:voidking@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://github.com/voidking" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;voidking" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i> GitHub</a></span><span class="links-of-author-item"><a href="http://weibo.com/voidking" title="Weibo → http:&#x2F;&#x2F;weibo.com&#x2F;voidking" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i> Weibo</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/voidking" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;voidking" rel="noopener" target="_blank"><i class="fa fa-fw fa-quora"></i> Zhihu</a></span></div></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright"> &copy; 2014 – <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">好好学习的郝</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="footer-beian"> <a href="http://beian.miit.gov.cn/" target="_blank">苏ICP备14021030号</a>&nbsp;|&nbsp; <img src="/images/beian.png" alt=""> <a target="_blank" href="http://www.beian.gov.cn/">苏公网安备 32032202000223号</a></div></div></footer></div><script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="/lib/canvas-nest/canvas-nest.min.js"></script><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/gitalk/1.7.2/gitalk.min.css"><script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/gitalk/1.7.2/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '5a238b8c32b1e4dd2156',
      clientSecret: 'bfb5d518626f6fdc7da0351d1e0cd37ab75c6361',
      repo: 'gitalk-comments',
      owner: 'voidking',
      admin: ['voidking'],
      id: '814401e475a344bc970908628c9ef5b8',
      title: 'Python爬虫基础',
      body: '欢迎留言，互相交流学习~',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script></body></html>