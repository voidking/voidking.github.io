<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:new URL("https://www.voidking.com").hostname,root:"/",scheme:"Gemini",version:"7.7.1",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{appID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1,cdn:{enable:!0,url:"//cdn.jsdelivr.net/gh/voidking/voidking.github.io/search.xml"}},path:"search.xml",motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}}}</script><meta name="description" content="spark-on-k8s-operator简介 spark-on-k8s-operator: Kubernetes operator for managing the lifecycle of Apache Spark applications on Kubernetes.The Kubernetes Operator for Apache Spark aims to make specifyin"><meta property="og:type" content="article"><meta property="og:title" content="K8S中安装配置Spark"><meta property="og:url" content="https://www.voidking.com/dev-k8s-spark/index.html"><meta property="og:site_name" content="好好学习的郝"><meta property="og:description" content="spark-on-k8s-operator简介 spark-on-k8s-operator: Kubernetes operator for managing the lifecycle of Apache Spark applications on Kubernetes.The Kubernetes Operator for Apache Spark aims to make specifyin"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.voidking.com/@/imgs/k8s-spark/resource.jpg?imageView2/0/w/800"><meta property="og:image" content="https://cdn.voidking.com/@/imgs/k8s-spark/result.jpg?imageView2/0/w/800"><meta property="og:image" content="https://cdn.voidking.com/@/imgs/k8s-spark/spark-hive.jpg?imageView2/0/w/800"><meta property="article:published_time" content="2022-09-14T20:00:00.000Z"><meta property="article:modified_time" content="2022-09-17T17:00:00.000Z"><meta property="article:author" content="好好学习的郝"><meta property="article:tag" content="k8s"><meta property="article:tag" content="helm"><meta property="article:tag" content="hive"><meta property="article:tag" content="spark"><meta property="article:tag" content="operator"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.voidking.com/@/imgs/k8s-spark/resource.jpg?imageView2/0/w/800"><link rel="canonical" href="https://www.voidking.com/dev-k8s-spark/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0}</script><title>K8S中安装配置Spark | 好好学习的郝</title><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b759ac2a7fa45129e3ef060bf68259f0";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="好好学习的郝" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-meta"><div><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">好好学习的郝</span><span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">好好学习，天天向上！</h1></div><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="site-search"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="搜索..." spellcheck="false" type="text" id="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"></div></div><div class="search-pop-overlay"></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div> <a href="https://github.com/voidking" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content"><div class="posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.voidking.com/dev-k8s-spark/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="好好学习的郝"><meta itemprop="description" content="学而不思则罔，思而不学则殆！"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="好好学习的郝"></span><header class="post-header"><h2 class="post-title" itemprop="name headline"> K8S中安装配置Spark</h2><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2022-09-14 20:00:00" itemprop="dateCreated datePublished" datetime="2022-09-14T20:00:00+00:00">2022-09-14</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2022-09-17 17:00:00" itemprop="dateModified" datetime="2022-09-17T17:00:00+00:00">2022-09-17</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/engineering/" itemprop="url" rel="index"><span itemprop="name">engineering</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/engineering/k8s/" itemprop="url" rel="index"><span itemprop="name">k8s</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/engineering/cloudnative/" itemprop="url" rel="index"><span itemprop="name">cloudnative</span></a></span> ， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/engineering/bigdata/" itemprop="url" rel="index"><span itemprop="name">bigdata</span></a></span></span><span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span id="busuanzi_value_page_pv"></span></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="spark-on-k8s-operator简介"><a href="#spark-on-k8s-operator简介" class="headerlink" title="spark-on-k8s-operator简介"></a>spark-on-k8s-operator简介</h1><blockquote><p>spark-on-k8s-operator: Kubernetes operator for managing the lifecycle of Apache Spark applications on Kubernetes.<br>The Kubernetes Operator for Apache Spark aims to make specifying and running Spark applications as easy and idiomatic as running other workloads on Kubernetes. It uses Kubernetes custom resources for specifying, running, and surfacing status of Spark applications.</p></blockquote><p><a target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator">spark-on-k8s-operator</a>工作流程：<br>1、提交sparkApplication的请求到api-server<br>2、把sparkApplication的CRD持久化到etcd<br>3、operator订阅发现有sparkApplication，获取后通过submission 4、runner提交spark-submit过程，请求给到api-server后生成对应的driver/executor pod<br>5、spark pod monitor会监控到application执行的状态（所以通过sparkctl可以通过list、status看到）<br>mutating adminission webhook建svc，可以查看spark web ui</p><p>简而言之，spark-on-k8s-operator改变了传统的spark任务运行方式，能够提高资源利用率和节省资源。用户提交CRD之后，k8s才会创建运行spark任务需要的pod，从而能够利用整个k8s集群的资源。任务跑完之后，pod会被回收，从而节省资源。</p><p>参考文档：</p><ul><li><a target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator">spark-on-k8s-operator</a></li><li><a target="_blank" rel="noopener" href="https://blog.csdn.net/w8998036/article/details/122217230">spark operator部署安装</a></li><li><a target="_blank" rel="noopener" href="https://daimajiaoliu.com/daima/4ed5ef8f61003fc">spark-on-kubernetes-operator环境搭建</a></li><li><a target="_blank" rel="noopener" href="https://www.slideshare.net/databricks/apache-spark-on-k8s-best-practice-and-performance-in-the-cloud">Apache Spark on K8S Best Practice and Performance in the Cloud</a></li><li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/PWlTRDyZXk9YWPYQkes2Bg">苹果工程师分享如何运维超大规模Spark on Kubernetes集群</a></li></ul><span id="more"></span><h1 id="安装spark-on-k8s-operator"><a href="#安装spark-on-k8s-operator" class="headerlink" title="安装spark-on-k8s-operator"></a>安装spark-on-k8s-operator</h1><p>1、安装operator</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator</span><br><span class="line">helm install my-release spark-operator/spark-operator --namespace spark-operator --create-namespace</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/GoogleCloudPlatform/spark-on-k8s-operator.git</span><br><span class="line"><span class="built_in">cd</span> spark-on-k8s-operator/charts/spark-operator-chart</span><br><span class="line">helm install my-release . --namespace spark-operator --create-namespace</span><br></pre></td></tr></table></figure><p>2、镜像拉取报错处理<br>拉取镜像 <code>ghcr.io/googlecloudplatform/spark-operator:v1beta2-1.3.7-3.1.1</code> 时报错ErrImagePull，这是因为ghcr.io被墙了，需要一些技巧进行下载。<br>方法一：科学上网下载镜像到本地，然后上传镜像到内部镜像仓库，修改yaml使用内部镜像仓库。<br>方法二：利用GitHub Actions下载ghcr.io的镜像，上传到Docker Hub，详情参考<a target="_blank" rel="noopener" href="https://github.com/togettoyou/hub-mirror">togettoyou/hub-mirror</a></p><p>这里使用方法一，修改镜像为内部镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker pull ghcr.io/googlecloudplatform/spark-operator:v1beta2-1.3.7-3.1.1</span><br><span class="line">docker tag ghcr.io/googlecloudplatform/spark-operator:v1beta2-1.3.7-3.1.1 harbor.voidking.com/ghcr.io/googlecloudplatform/spark-operator:v1beta2-1.3.7-3.1.1</span><br><span class="line">docker login harbor.voidking.com</span><br><span class="line">docker push harbor.voidking.com/ghcr.io/googlecloudplatform/spark-operator:v1beta2-1.3.7-3.1.1</span><br></pre></td></tr></table></figure><p>3、替换镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit deployment.apps/my-release-spark-operator -n spark-operator</span><br></pre></td></tr></table></figure><p>修改镜像为内部镜像地址。</p><h1 id="使用spark-on-k8s-operator"><a href="#使用spark-on-k8s-operator" class="headerlink" title="使用spark-on-k8s-operator"></a>使用spark-on-k8s-operator</h1><p>1、下载<a target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/examples/spark-pi.yaml">spark-on-k8s-operator/examples/spark-pi.yaml</a></p><p>2、修改镜像为内部镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker pull gcr.io/spark-operator/spark:v3.1.1</span><br><span class="line">docker tag gcr.io/spark-operator/spark:v3.1.1 harbor.voidking.com/gcr.io/spark-operator/spark:v3.1.1</span><br><span class="line">docker push harbor.voidking.com/gcr.io/spark-operator/spark:v3.1.1</span><br></pre></td></tr></table></figure><p>3、替换镜像<br>修改spark-pi.yaml中的镜像为内部镜像地址</p><p>4、生效yaml文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f spark-pi.yaml</span><br></pre></td></tr></table></figure><p>5、查看spark应用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl get sparkapplications spark-pi -o=yaml -n default</span><br><span class="line">kubectl describe sparkapplication spark-pi -n default</span><br></pre></td></tr></table></figure><p>报错：error looking up service account default/spark: serviceaccount “spark” not found.</p><p>官方文档中也给了说明，<code>spark</code>这个serviceaccount需要替换成有权限的serviceaccount，该serviceaccount有权创建、获取、列出和删除执行程序 pod，并为驱动程序创建 Kubernetes 无头服务。</p><p>注意：不能直接替换成<code>default</code>，否则spark-pi-driver执行时会报错权限不够。<br>可以选择给<code>default</code>授权，或者自己创建一个新的sa，这里我们选择后者。</p><p>6、创建sa<br>参考<a target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/manifest/spark-application-rbac/spark-application-rbac.yaml">spark-application-rbac.yaml</a>，修改为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">spark</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">spark-role</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;pods&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;*&quot;</span>]</span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;services&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;*&quot;</span>]</span><br><span class="line"><span class="bullet">-</span> <span class="attr">apiGroups:</span> [<span class="string">&quot;&quot;</span>]</span><br><span class="line">  <span class="attr">resources:</span> [<span class="string">&quot;configmaps&quot;</span>]</span><br><span class="line">  <span class="attr">verbs:</span> [<span class="string">&quot;*&quot;</span>]</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">spark-role-binding</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">spark</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">spark-role</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure><p>注意： configmaps 的管理权限也是必要的。</p><p>执行创建sa</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f spark-application-rbac.yaml</span><br></pre></td></tr></table></figure><p>如果创建的不是名为<code>spark</code>的sa，那么还需要修改spark-pi的spec yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit sparkapplication spark-pi -n default</span><br></pre></td></tr></table></figure><p>7、查看spark资源情况</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get all -n default | grep spark</span><br></pre></td></tr></table></figure><p><img src="https://cdn.voidking.com/@/imgs/k8s-spark/resource.jpg?imageView2/0/w/800"><br>以上，符合预期。如果出现Error，那么通过日志进行排查。</p><p>8、查看执行结果（查看日志）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs pod/spark-pi-driver -n default</span><br></pre></td></tr></table></figure><p><img src="https://cdn.voidking.com/@/imgs/k8s-spark/result.jpg?imageView2/0/w/800"><br>日志中会输出：Pi is roughly 3.145515727578638</p><h1 id="sparkapplication-yaml编写"><a href="#sparkapplication-yaml编写" class="headerlink" title="sparkapplication yaml编写"></a>sparkapplication yaml编写</h1><p>参考文档：</p><ul><li><a target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/tree/master/examples">spark-on-k8s-operator/examples</a></li><li><a target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md">User Guide</a></li></ul><h1 id="调用hive"><a href="#调用hive" class="headerlink" title="调用hive"></a>调用hive</h1><h2 id="hive基本操作"><a href="#hive基本操作" class="headerlink" title="hive基本操作"></a>hive基本操作</h2><p>1、登录hiveserver<br>kubectl exec进入到hive pod中，执行登录命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive </span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">beeline -u jdbc:hive2://localhost:10000 username password</span><br></pre></td></tr></table></figure><p>2、查看hive_client_test表内容</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> databases;</span><br><span class="line">use <span class="keyword">default</span>;</span><br><span class="line"><span class="keyword">show</span> tables;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> hive_client_test;</span><br></pre></td></tr></table></figure><h2 id="spark调用hive"><a href="#spark调用hive" class="headerlink" title="spark调用hive"></a>spark调用hive</h2><p>spark调用hive时，关于hive的配置，有两种配置方式：一种是写在代码中，一种是配置在环境变量中。<br>写在代码中的demo：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder \</span><br><span class="line">        .config(<span class="string">&quot;hive.metastore.uris&quot;</span>,<span class="string">&quot;thrift://hive-metastore.bigdata.svc:9083&quot;</span>) \</span><br><span class="line">        .appName(<span class="string">&quot;test&quot;</span>) \</span><br><span class="line">        .enableHiveSupport() \</span><br><span class="line">        .getOrCreate()</span><br><span class="line">read_df = spark.sql(<span class="string">&quot;select * from default.hive_client_test limit 1&quot;</span>)</span><br><span class="line">read_df.show()</span><br></pre></td></tr></table></figure><p>如果不使用config，那么默认读取环境变量中的配置：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark = SparkSession.builder\</span><br><span class="line">        .master(<span class="string">&quot;local[*]&quot;</span>) \</span><br><span class="line">        .appName(<span class="string">&quot;test&quot;</span>) \</span><br><span class="line">        .enableHiveSupport() \</span><br><span class="line">        .getOrCreate()</span><br><span class="line">read_df=spark.sql(<span class="string">&quot;select * from default.hive_client_test limit 1&quot;</span>)</span><br><span class="line">read_df.show()</span><br></pre></td></tr></table></figure><p>hive.metastore.uris对应的环境变量是啥？</p><h2 id="sparkapplication定义"><a href="#sparkapplication定义" class="headerlink" title="sparkapplication定义"></a>sparkapplication定义</h2><p>参考文档：</p><ul><li><a target="_blank" rel="noopener" href="https://github.com/apache/spark/blob/master/examples/src/main/python/sql/hive.py">spark examples - hive.py</a></li><li><a target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/examples/spark-py-pi.yaml">spark-on-k8s-operator/examples/spark-py-pi.yaml</a></li></ul><p>这里比较友好的是，<code>gcr.io/spark-operator/spark-py:v3.1.1</code>镜像中包含所有的spark examples，可以比较方便地进行测试。</p><p>已知k8s集群中存在hive，hive-metastore的svc为<code>hive-metastore.bigdata.svc</code>。</p><p>1、修改hive.py，内容为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">A simple example demonstrating Spark SQL Hive integration.</span></span><br><span class="line"><span class="string">Run with:</span></span><br><span class="line"><span class="string">  ./bin/spark-submit examples/src/main/python/sql/hive.py</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># $example on:spark_hive$</span></span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> abspath</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line"><span class="comment"># $example off:spark_hive$</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># $example on:spark_hive$</span></span><br><span class="line">    <span class="comment"># warehouse_location points to the default location for managed databases and tables</span></span><br><span class="line">    warehouse_location = abspath(<span class="string">&#x27;spark-warehouse&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    spark = SparkSession \</span><br><span class="line">        .builder \</span><br><span class="line">        .config(<span class="string">&quot;hive.metastore.uris&quot;</span>,<span class="string">&quot;thrift://hive-metastore.bigdata.svc:9083&quot;</span>) \</span><br><span class="line">        .appName(<span class="string">&quot;Python Spark SQL Hive integration example&quot;</span>) \</span><br><span class="line">        .config(<span class="string">&quot;spark.sql.warehouse.dir&quot;</span>, warehouse_location) \</span><br><span class="line">        .enableHiveSupport() \</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># spark is an existing SparkSession</span></span><br><span class="line">    spark.sql(<span class="string">&quot;CREATE TABLE IF NOT EXISTS src (key INT, value STRING) USING hive&quot;</span>)</span><br><span class="line">    spark.sql(<span class="string">&quot;LOAD DATA LOCAL INPATH &#x27;/opt/spark/examples/src/main/resources/kv1.txt&#x27; INTO TABLE src&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Queries are expressed in HiveQL</span></span><br><span class="line">    spark.sql(<span class="string">&quot;SELECT * FROM src&quot;</span>).show()</span><br><span class="line">    <span class="comment"># +---+-------+</span></span><br><span class="line">    <span class="comment"># |key|  value|</span></span><br><span class="line">    <span class="comment"># +---+-------+</span></span><br><span class="line">    <span class="comment"># |238|val_238|</span></span><br><span class="line">    <span class="comment"># | 86| val_86|</span></span><br><span class="line">    <span class="comment"># |311|val_311|</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Aggregation queries are also supported.</span></span><br><span class="line">    spark.sql(<span class="string">&quot;SELECT COUNT(*) FROM src&quot;</span>).show()</span><br><span class="line">    <span class="comment"># +--------+</span></span><br><span class="line">    <span class="comment"># |count(1)|</span></span><br><span class="line">    <span class="comment"># +--------+</span></span><br><span class="line">    <span class="comment"># |    500 |</span></span><br><span class="line">    <span class="comment"># +--------+</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># The results of SQL queries are themselves DataFrames and support all normal functions.</span></span><br><span class="line">    sqlDF = spark.sql(<span class="string">&quot;SELECT key, value FROM src WHERE key &lt; 10 ORDER BY key&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># The items in DataFrames are of type Row, which allows you to access each column by ordinal.</span></span><br><span class="line">    stringsDS = sqlDF.rdd.<span class="built_in">map</span>(<span class="keyword">lambda</span> row: <span class="string">&quot;Key: %d, Value: %s&quot;</span> % (row.key, row.value))</span><br><span class="line">    <span class="keyword">for</span> record <span class="keyword">in</span> stringsDS.collect():</span><br><span class="line">        <span class="built_in">print</span>(record)</span><br><span class="line">    <span class="comment"># Key: 0, Value: val_0</span></span><br><span class="line">    <span class="comment"># Key: 0, Value: val_0</span></span><br><span class="line">    <span class="comment"># Key: 0, Value: val_0</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># You can also use DataFrames to create temporary views within a SparkSession.</span></span><br><span class="line">    Record = Row(<span class="string">&quot;key&quot;</span>, <span class="string">&quot;value&quot;</span>)</span><br><span class="line">    recordsDF = spark.createDataFrame([Record(i, <span class="string">&quot;val_&quot;</span> + <span class="built_in">str</span>(i)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">101</span>)])</span><br><span class="line">    recordsDF.createOrReplaceTempView(<span class="string">&quot;records&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Queries can then join DataFrame data with data stored in Hive.</span></span><br><span class="line">    spark.sql(<span class="string">&quot;SELECT * FROM records r JOIN src s ON r.key = s.key&quot;</span>).show()</span><br><span class="line">    <span class="comment"># +---+------+---+------+</span></span><br><span class="line">    <span class="comment"># |key| value|key| value|</span></span><br><span class="line">    <span class="comment"># +---+------+---+------+</span></span><br><span class="line">    <span class="comment"># |  2| val_2|  2| val_2|</span></span><br><span class="line">    <span class="comment"># |  4| val_4|  4| val_4|</span></span><br><span class="line">    <span class="comment"># |  5| val_5|  5| val_5|</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="comment"># $example off:spark_hive$</span></span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br></pre></td></tr></table></figure><p>2、docker commit新的镜像<br><code>harbor.voidking.com/gcrmirror/spark-operator/spark-py:v3.1.1.0</code></p><p>3、创建spark-hive.yaml，内容为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">&quot;sparkoperator.k8s.io/v1beta2&quot;</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">SparkApplication</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pyspark-hive</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">Python</span></span><br><span class="line">  <span class="attr">pythonVersion:</span> <span class="string">&quot;3&quot;</span></span><br><span class="line">  <span class="attr">mode:</span> <span class="string">cluster</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">&quot;harbor.voidking.com/gcrmirror/spark-operator/spark-py:v3.1.1.0&quot;</span></span><br><span class="line">  <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">  <span class="attr">mainApplicationFile:</span> <span class="string">local:///opt/spark/examples/src/main/python/sql/hive.py</span></span><br><span class="line">  <span class="attr">sparkVersion:</span> <span class="string">&quot;3.1.1&quot;</span></span><br><span class="line">  <span class="attr">restartPolicy:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">OnFailure</span></span><br><span class="line">    <span class="attr">onFailureRetries:</span> <span class="number">3</span></span><br><span class="line">    <span class="attr">onFailureRetryInterval:</span> <span class="number">10</span></span><br><span class="line">    <span class="attr">onSubmissionFailureRetries:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">onSubmissionFailureRetryInterval:</span> <span class="number">20</span></span><br><span class="line">  <span class="attr">driver:</span></span><br><span class="line">    <span class="attr">cores:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">coreLimit:</span> <span class="string">&quot;1200m&quot;</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">&quot;512m&quot;</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="number">3.1</span><span class="number">.1</span><span class="number">.0</span></span><br><span class="line">    <span class="attr">serviceAccount:</span> <span class="string">spark</span></span><br><span class="line">  <span class="attr">executor:</span></span><br><span class="line">    <span class="attr">cores:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">instances:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">memory:</span> <span class="string">&quot;512m&quot;</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">      <span class="attr">version:</span> <span class="number">3.1</span><span class="number">.1</span><span class="number">.0</span></span><br></pre></td></tr></table></figure><p>4、创建sparkapplication</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f spark-hive.yaml</span><br></pre></td></tr></table></figure><p>5、查看结果</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl get all | grep hive</span><br><span class="line">kubectl logs pod/pyspark-hive-driver</span><br></pre></td></tr></table></figure><p><img src="https://cdn.voidking.com/@/imgs/k8s-spark/spark-hive.jpg?imageView2/0/w/800"></p></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> 好好学习的郝</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://www.voidking.com/dev-k8s-spark/" title="K8S中安装配置Spark">https://www.voidking.com/dev-k8s-spark/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！源站会及时更新知识点及修正错误，阅读体验也更好。欢迎分享，欢迎收藏~</li></ul></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/k8s/" rel="tag"># k8s</a> <a href="/tags/helm/" rel="tag"># helm</a> <a href="/tags/hive/" rel="tag"># hive</a> <a href="/tags/spark/" rel="tag"># spark</a> <a href="/tags/operator/" rel="tag"># operator</a></div><div class="post-nav"><div class="post-nav-item"><a href="/dev-linux-clash/" rel="prev" title="Linux中安装配置Clash"><i class="fa fa-chevron-left"></i> Linux中安装配置Clash</a></div><div class="post-nav-item"> <a href="/dev-kubeadm-k8s-cert-expired/" rel="next" title="kubeadm安装的K8S集群证书过期问题">kubeadm安装的K8S集群证书过期问题<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div><div class="comments"><div id="lv-container" data-id="city" data-uid="MTAyMC8zODU3Mi8xNTEwMA=="></div></div><script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#spark-on-k8s-operator%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">spark-on-k8s-operator简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%89%E8%A3%85spark-on-k8s-operator"><span class="nav-number">2.</span> <span class="nav-text">安装spark-on-k8s-operator</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8spark-on-k8s-operator"><span class="nav-number">3.</span> <span class="nav-text">使用spark-on-k8s-operator</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#sparkapplication-yaml%E7%BC%96%E5%86%99"><span class="nav-number">4.</span> <span class="nav-text">sparkapplication yaml编写</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%B0%83%E7%94%A8hive"><span class="nav-number">5.</span> <span class="nav-text">调用hive</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#hive%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="nav-number">5.1.</span> <span class="nav-text">hive基本操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#spark%E8%B0%83%E7%94%A8hive"><span class="nav-number">5.2.</span> <span class="nav-text">spark调用hive</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sparkapplication%E5%AE%9A%E4%B9%89"><span class="nav-number">5.3.</span> <span class="nav-text">sparkapplication定义</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="好好学习的郝" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">好好学习的郝</p><div class="site-description" itemprop="description">学而不思则罔，思而不学则殆！</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">645</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">30</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">242</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="mailto:voidking@qq.com" title="E-Mail → mailto:voidking@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i> E-Mail</a></span><span class="links-of-author-item"><a href="https://github.com/voidking" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;voidking" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i> GitHub</a></span><span class="links-of-author-item"><a href="http://weibo.com/voidking" title="Weibo → http:&#x2F;&#x2F;weibo.com&#x2F;voidking" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i> Weibo</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/voidking" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;voidking" rel="noopener" target="_blank"><i class="fa fa-fw fa-quora"></i> Zhihu</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="_xduxciwe4ao"></div><script type="text/javascript">(window.slotbydup=window.slotbydup||[]).push({id:"u6920911",container:"_xduxciwe4ao",async:!0})</script><script type="text/javascript" src="//cpro.baidustatic.com/cpro/ui/cm.js" async="async" defer="defer"></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3284447971731414" crossorigin="anonymous"></script><div class="copyright"> &copy; 2014 – <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">好好学习的郝</span></div><div class="busuanzi-count"><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span class="post-meta-item" id="busuanzi_container_site_uv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-user"></i></span><span class="site-uv" title="总访客量"><span id="busuanzi_value_site_uv"></span></span></span> <span class="post-meta-divider">|</span><span class="post-meta-item" id="busuanzi_container_site_pv" style="display:none"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span><span class="site-pv" title="总访问量"><span id="busuanzi_value_site_pv"></span></span></span></div><div class="footer-beian"> <a href="http://beian.miit.gov.cn/" target="_blank">苏ICP备14021030号</a>&nbsp;|&nbsp; <img src="/images/beian.png" alt=""> <a target="_blank" href="http://www.beian.gov.cn/">苏公网安备 32032202000223号</a></div></div></footer><div id="needsharebutton-float"><span class="btn"><i class="fa fa-share-alt" aria-hidden="true"></i></span></div></div><script color="0,0,255" opacity="0.5" zindex="-1" count="99" src="/lib/canvas-nest/canvas-nest.min.js"></script><script src="/lib/anime.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css"><script src="/lib/needsharebutton/needsharebutton.js"></script><script>pbOptions={iconStyle:"box",boxForm:"horizontal",position:"bottomCenter",networks:"Weibo,Wechat,Douban,QQZone,Twitter,Facebook"},new needShareButton("#needsharebutton-postbottom",pbOptions),flOptions={iconStyle:"box",boxForm:"horizontal",position:"topRight",networks:"Weibo,Wechat,Douban,QQZone,Twitter,Facebook"},new needShareButton("#needsharebutton-float",flOptions)</script><script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  // window.livereOptions = {
  //   refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  // };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script></body></html>